{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeafdc46",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46de7a03439c39d1a4a601d07fc185ed",
     "grade": false,
     "grade_id": "cell-38d651dfc5f90eea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "\n",
    "The focus of this notebook is on interpretability. You will use a Decision Tree model and a Support Vector Machine to look at the most predictive features for predicting diabetes. Here, the features will be words in the text documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef5b45",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d61ecf2d89e8c03f6eb4f3ad45acbb6",
     "grade": false,
     "grade_id": "cell-3358622ccd23afb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Pipeline task overview: Predicting presence of diabetes from text\n",
    "\n",
    "\n",
    "\n",
    "Recall from your previous courses that these tasks can typically be described by the following components: \n",
    "\n",
    " 1. Data collection - <font color='green'>Done</font>\n",
    " 2. Data cleaning / transformation - <font color='magenta'>You will do some in assignment 3 c</font>\n",
    " 3. Dataset splitting <font color='green'>Done</font>\n",
    " 4. Model training <font color='magenta'>You will do</font>\n",
    " 5. Model evaluation <font color='magenta'>You will do</font>\n",
    " 6. Repeat 1-5 to perform model selection <font color='magenta'>You will do</font>\n",
    " 7. Presenation of findings (Visualization) <font color='green'>Not required</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a419f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "340e48a7f61be1f81b4b1158f140ac89",
     "grade": false,
     "grade_id": "cell-7723d00db91f2fff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import data_cleaners as dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d71fa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "deaccf09084f3a5b7b0f62797d5535cd",
     "grade": false,
     "grade_id": "cell-86edc065c23283c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font color='magenta'>Task One</font>\n",
    "\n",
    "First we'll load in the raw data. We are going to be using basic sklearn packages, rather than PyTorch for this notebook, so you can code everything up in the notebook itself.\n",
    "\n",
    "In the first task, we will use the CountVectorizer object to build the vocabulary and the bag of words vectors for each document. The shape of the Numpy array bow_vecs will be (1045, 15003). You can check your implementation before you submit by ensuring that you get 192 1s in the first document.\n",
    "```python\n",
    "assert bow_vecs[0].sum()==192\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be53ea",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cc8c53b6159db97a214eb8fec8a976c",
     "grade": false,
     "grade_id": "cell-18697814b92d49cc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This code loads in the raw X and y files. Use sklearn's CountVectorizer to convert the collection of text documents \n",
    "# to a matrix of token presence/absence. \n",
    "# Ensure that the CountVectorizer object converts all characters to lowercase and removes the stopwords before tokenizing.\n",
    "# NOTE: we are only interested in binary values (True/False) rather than integer counts of words in a document.\n",
    "\n",
    "# CountVectorizer object will give you a vocabulary which is a dictionary. The key in the dictionary is a unique word \n",
    "# and each value is the index of that word in the bag of words vectors.\n",
    "# For example, the value for the key  'gauze' is 5944. That means for each document the 5944th value of the vector\n",
    "# associated with that document will be 1 if this document contains the word  'gauze' and 0 otherwise. \n",
    "\n",
    "X, y = dc.get_raw_data()\n",
    "bow_vecs = None\n",
    "vocab = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "index_to_word = {v:k for k,v in vocab.items()} # reverse lookup of word from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd923ed7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "939bdb86ac42915ddc64b32920a53fa7",
     "grade": true,
     "grade_id": "cell-0d56e5465427bd62",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a6714",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1994bcd881aceaff3400d826a438af5",
     "grade": false,
     "grade_id": "cell-fcb660c3567ac7e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font color='magenta'>Task Two</font>\n",
    "\n",
    "\n",
    "Use a DecisionTreeClassifier (set random_state to 12345 for the autograder) and find the best max_depth hyperparameter which maximizes the average precision and is in the range [5,10).\n",
    "\n",
    "Note that the expected format for this answer is a dictionary with max_depth in string format as the key and average precision as the value (sample format shown below).\n",
    "```\n",
    "{'5': 0.11111111111111111,\n",
    " '6': 0.21111111111111111,\n",
    " '7': 0.31111111111111111,\n",
    " '8': 0.41111111111111111,\n",
    " '9': 0.21212121212121212}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97498729",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfa3083f7af85fea4a6bf4402afd3831",
     "grade": false,
     "grade_id": "cell-39f9a41a2a0d6cef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_best(X_train,y_train,X_val,y_val):\n",
    "    score_dict = {}\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return score_dict\n",
    "\n",
    "X_train = bow_vecs[:900]\n",
    "y_train = y.iloc[:900]\n",
    "X_val = bow_vecs[900:1000]\n",
    "y_val = y.iloc[900:1000]\n",
    "\n",
    "params = get_best(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97de16",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d6650afd75d0e03fd309e73cf600717",
     "grade": true,
     "grade_id": "cell-c519fb24d55fea24",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad72d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f37aa8315a85a972c9acf37b60a5082f",
     "grade": false,
     "grade_id": "cell-c221acbcc79779cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font color='magenta'>Task Three A</font>\n",
    "\n",
    "When the model is trained with the best value of max_depth, find the five most predictive features of that model.\n",
    "\n",
    "Note that the expected format for this answer is a list of tuples, each tuple containing the feature name and the importance (sample format shown below).\n",
    "\n",
    "```\n",
    "[('confused', 0.11223344556677889),\n",
    " ('cut', 0.09111111111111111),\n",
    " ('noninfectious', 0.08222222222222222),\n",
    " ('zyloprim', 0.07111111111111111),\n",
    " ('bloody', 0.05111111111111111)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8feb6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c95310ae1fdbe43385a0e91eabc84f18",
     "grade": false,
     "grade_id": "cell-c8bc21821991e7e5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_five_best_features(maxdepth, X_train, y_train):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return None\n",
    "\n",
    "best_maxdepth = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "best_features = get_five_best_features(best_maxdepth, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9af18d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0e071c0ba7cf7f4840b356b62a2bd89",
     "grade": true,
     "grade_id": "cell-2172b26bf0add7fe",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d719c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8227f2f11a19ad062cc62f852983354f",
     "grade": false,
     "grade_id": "cell-9fd63c704d28e3e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font color='magenta'>Task Three B</font>\n",
    "\n",
    "Enter your thoughts on these features: do they make sense to you in light of the health content from this week? What questions do you have after looking at them?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f239322",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff2b52a947976dd9001bf8dd2e7f9d36",
     "grade": true,
     "grade_id": "cell-d1b3ae26a5c0e429",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f2f20",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97866867b181621b609063c5dc6851c7",
     "grade": false,
     "grade_id": "cell-75b408af30b2262d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Does this Decision Tree model perform better or worse, on average, than the models you explored in notebook 3_a?\n",
    "\n",
    "Set relative performance to \"better\" or \"worse\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61faaf4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a66d7f5f39c4e49a282751b9983b66a4",
     "grade": false,
     "grade_id": "cell-bf610b0a39531382",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "relative_performance_3_a = \"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d44cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9298f4c14f0518f0c2116aabc2164a3",
     "grade": true,
     "grade_id": "cell-ced04116966e4d4c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78798f9d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72f8dbc078ac0fde7180f8dde85b0955",
     "grade": false,
     "grade_id": "cell-8097cd4732f13601",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Does this Decision Tree model perform better or worse, on average, than the models you explored in notebook 3_b?\n",
    "\n",
    "Set relative performance to \"better\" or \"worse\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494983e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0f62c8ecfaab0fafc951bec1fc6d68e",
     "grade": false,
     "grade_id": "cell-aaafa872e23c0bf6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "relative_performance_3_b = \"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38485b1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15c51d6e3fc7c5eccdded2b07b3ecc22",
     "grade": true,
     "grade_id": "cell-4327680c6c8a6708",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded3c585",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ed8fdfa434d360be65686bf08ee4c53",
     "grade": false,
     "grade_id": "cell-542be24af12bd434",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Does this Decision Tree model perform better or worse, on average, than the models you explored in notebook 3_c?\n",
    "\n",
    "Set relative performance to \"better\" or \"worse\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19351933",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "275c8daf19cc4793da70dea8c6b80458",
     "grade": false,
     "grade_id": "cell-dea789abdaa49162",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "relative_performance_3_c = \"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc54bf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0b25ab7c961cc784e947b6d4f179bf1",
     "grade": true,
     "grade_id": "cell-da5262ecdcc030e6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28604e8a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dfa62588704a67a139dee51c2055ccb",
     "grade": false,
     "grade_id": "cell-5824e3a0ef031f11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font color='magenta'>Task Four</font>\n",
    "\n",
    "Using Recursive Feature Elimination and an SVM with a linear kernel, C=.001 and random_state=1234.\n",
    "\n",
    "Return the list of top 5 features. Note that the expected format for this answer is a numpy array of feature names (sample format shown below).\n",
    "```\n",
    "array(['confused', 'cut', 'hemoglobin', 'noninfectious', 'zyloprim'],\n",
    "      dtype=object)\n",
    "```\n",
    "Set the step to 0.7 or greater but less than 1 to speed up the computation. **Note: do not set step to 1, as it will make the computation extremely slow.** Refer to the <a href='https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html'>documentation</a> for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd4457",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aee3c231fa9a8c6c539d8e4491adf3f4",
     "grade": false,
     "grade_id": "cell-ee4ac67f96d907fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_5_features = []\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b94638",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4916742511e1cf0040d9021ace6c6f77",
     "grade": true,
     "grade_id": "cell-b64c95be9b1de00b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
