{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199fb313",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcdf09cf006b412a86a4834e6dc03742",
     "grade": false,
     "grade_id": "cell-278f5618611e0048",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Glucose Prediction \n",
    "\n",
    "\n",
    "This assignment's focus is on predicting blood glucose. There are four parts to the assignment:\n",
    "\n",
    "\n",
    "   1. Data cleaning\n",
    " \n",
    "   2. Population level model\n",
    " \n",
    "   3. Improving model training\n",
    " \n",
    "   4. Transfer learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84702358",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "321ade8ba7d727d931d8d75443f08261",
     "grade": false,
     "grade_id": "cell-1079251d7f842572",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Pipeline task overview: Forecasting glucose\n",
    "\n",
    "Recall from your previous courses that these tasks can typically be described by the following components: \n",
    "\n",
    " 1. Data collection - <font color='green'>Done</font>\n",
    " 2. Data cleaning / transformation - <font color='magenta'>You will do in 2a</font>\n",
    " 3. Dataset splitting <font color='green'> - Done </font>\n",
    " 4. Model training <font color='magenta'> - You will do in 2b, 2c and 2d</font>\n",
    " 5. Model evaluation <font color='magenta'> - You will do in 2b, 2c and 2d</font>\n",
    " 6. Repeat 1-5 to perform model selection <font color='magenta'> - You will do in 2b, 2c and 2d</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d3d671",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c94b0908b51af499ba9498c5751d191a",
     "grade": false,
     "grade_id": "cell-ae9dca601ba2f785",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Population level models\n",
    "\n",
    "In this notebook you will be using our cleaned and transformed data to train and evaluate an LSTM model for glucose prediction. This dataset was created following the same steps you completed in notebook 2a.  In this notebook you will train the model on the entire dataset. In the next notebook you will train each model N times - once per person in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ebe730",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81497425c9e5d13dae5ae90afe524240",
     "grade": false,
     "grade_id": "cell-1532402e1330ad0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import data_cleaners as dc\n",
    "import find_best_hyperparameters as fbh\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0fee51",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c33904303512fee21876de0110cb3c2e",
     "grade": false,
     "grade_id": "cell-c292643461554ec6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = dc.Diabetes()\n",
    "\n",
    "X = data.X\n",
    "y = data.y\n",
    "\n",
    "pid_to_indices = {}\n",
    "for pid in X['patient_id'].unique().tolist():\n",
    "    X_df = X[X['patient_id'] == pid]\n",
    "    pid_to_indices[pid] = X_df.index\n",
    "\n",
    "splits = dc.TrainSplits(X, y, combine=True, pid_to_indices=pid_to_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc2023",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d67fe8bde3527c8cfb2da910a7873112",
     "grade": false,
     "grade_id": "cell-79f3461e96a7405c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font color='magenta'>Task One</font>\n",
    "\n",
    "\n",
    "##  LSTM\n",
    "\n",
    "You will implement the LSTM model from the following paper ([A Deep Learning Approach for Blood Glucose Prediction\n",
    "of Type 1 Diabetes](http://ceur-ws.org/Vol-2675/paper23.pdf)).  However, you can see from the function ```best_lstm_parameters_training_data``` that there are a fixed set of parameters we will evaluate your model with. So, you are encouraged to experiment with additional complexity, but for the purpose of passing the assignment you will need to stick to the structure provided. \n",
    "\n",
    "\n",
    "**You will not implement the Delta-LSTM mentioned in the paper, in the LSTM step simply use PyTorch's LSTM module https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html**\n",
    "\n",
    "The function ```best_lstm_parameters_training_data``` in the ```find_best_hyperparameters.py``` file looks for the best hyperparameters. Your task is to fill in the missing pieces in the function. You will be asked to write a custom training loop in PyTorch to find the best hyperparameters for a model. For each hyperparameter combination you will train the model for a certain number of epochs. Then you will evaluate this model on the validation set and save the result. After evaluating on each hyperparameter combination you can choose the one which maximizes performance.\n",
    "You will need to have a basic understanding of PyTorch and how to train a model in order to complete the task. **Good luck!**     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a89e70",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "913f4374a2332e80a9b47867505d2312",
     "grade": false,
     "grade_id": "cell-028a20a09caa746c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer size: 4\n",
      "Evaluating the performance ...\n",
      "Hidden Size: 4 Val Loss: 73.677139\n",
      "Hidden layer size: 8\n",
      "Evaluating the performance ...\n",
      "Hidden Size: 8 Val Loss: 43.040031\n",
      "Hidden layer size: 16\n",
      "Evaluating the performance ...\n",
      "Hidden Size: 16 Val Loss: 63.192327\n",
      "Hidden layer size: 32\n",
      "Evaluating the performance ...\n",
      "Hidden Size: 32 Val Loss: 52.619152\n",
      "Hidden layer size: 64\n",
      "Evaluating the performance ...\n",
      "Hidden Size: 64 Val Loss: 34.066485\n",
      "Hidden layer size: 128\n"
     ]
    }
   ],
   "source": [
    "# Your solution goes in best_lstm_parameters_training_data() in find_best_hyperparameters.py\n",
    "best_model, best_hidden_size, min_val_loss = fbh.best_lstm_parameters_training_data(splits.train_df_X,\n",
    "                                                    splits.train_df_y, splits.validate_df_X, splits.validate_df_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0d65fd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4072a552f9a26ae54301e15d3f32cfb6",
     "grade": true,
     "grade_id": "cell-8dc5989970dd82f6",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b34252",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27486e5a08922b7e8fd22649cee6b326",
     "grade": false,
     "grade_id": "cell-54950a000cf28c4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font color='magenta'>Task Two</font>\n",
    "\n",
    "Across these notebooks we want to see how each model is performing for each patient.\n",
    "\n",
    "You will implement code in `fbh.rmse_from_training_population_testing_individual_best_lstm(best_model, splits.data_dicts)` which will return a dictionary, `results_dict`, of the form: \n",
    "\n",
    "```python\n",
    "{\n",
    " patient_id : (rmse for 30 min interval, list containing rmse for 5,10,...,60 min intervals)\n",
    "}\n",
    "\n",
    "```\n",
    "For example, results should look like the following (note that the numbers below may not be correct)\n",
    "```python\n",
    "{1.0:(27.81,[26.07,26.74, ... , 29.17]),\n",
    " 2.0:(27.81,[26.07,26.74, ... , 29.17]),\n",
    " ...\n",
    " 10.0:(27.81,[26.07,26.74, ... , 29.17])}\n",
    "```\n",
    "\n",
    "\n",
    "This takes your best model from above as an argument.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184f15f9-dc58-4968-9814-8d2ff850033b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(best_model.forward(splits.data_dicts[1.0]))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m test \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[43msplits\u001b[49m\u001b[38;5;241m.\u001b[39mdata_dicts)\n\u001b[1;32m      5\u001b[0m test_df \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;241m1.0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m test_df \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'splits' is not defined"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# print(best_model.forward(splits.data_dicts[1.0]))\n",
    "test = copy.deepcopy(splits.data_dicts)\n",
    "\n",
    "test_df = test[1.0][0]\n",
    "test_df = test_df.drop(columns=['patient_id'])\n",
    "test[1.0][2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "925ad9e8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a98047b881004d8c7e9059575f539a4",
     "grade": false,
     "grade_id": "cell-fc6aa074625dd095",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'permute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# your code goes in rmse_from_training_population_testing_individual_best_lstm() in find_best_hyperparameters.py\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m \u001b[43mfbh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmse_from_training_population_testing_individual_best_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dicts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_dict)\n",
      "File \u001b[0;32m~/work/assignments/assignment2/find_best_hyperparameters.py:414\u001b[0m, in \u001b[0;36mrmse_from_training_population_testing_individual_best_lstm\u001b[0;34m(best_model, data_dicts)\u001b[0m\n\u001b[1;32m    412\u001b[0m df \u001b[38;5;241m=\u001b[39m data_dicts[k][\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    413\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 414\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    415\u001b[0m outputs \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mforward(inputs)\n\u001b[1;32m    416\u001b[0m results_dict[k] \u001b[38;5;241m=\u001b[39m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py:5907\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5901\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5902\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5903\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5904\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5905\u001b[0m ):\n\u001b[1;32m   5906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'permute'"
     ]
    }
   ],
   "source": [
    "# your code goes in rmse_from_training_population_testing_individual_best_lstm() in find_best_hyperparameters.py\n",
    "results_dict = fbh.rmse_from_training_population_testing_individual_best_lstm(best_model, splits.data_dicts)\n",
    "\n",
    "print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b58fa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "171fa7f18212c24255da3683908ad532",
     "grade": true,
     "grade_id": "cell-7c41aec6ff93ca3f",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
