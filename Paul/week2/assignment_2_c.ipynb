{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199fb313",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee0973f9549f1a8b0251d3800c790180",
     "grade": false,
     "grade_id": "cell-e8a12ec284154bff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Glucose Prediction \n",
    "\n",
    "\n",
    "This assignment's focus is on predicting blood glucose. There are four parts to the assignment:\n",
    "\n",
    "\n",
    "   1. Data cleaning\n",
    " \n",
    "   2. Population level model\n",
    " \n",
    "   3. Improving model training\n",
    " \n",
    "   4. Transfer learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6652e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1583e5e1bfa330f4c1afa37763a4d558",
     "grade": false,
     "grade_id": "cell-2f9835332ae7dab9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import data_cleaners as dc\n",
    "import find_best_hyperparameters as fbh\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385f36e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e064aa1c4db22dba365833ecb014cef3",
     "grade": false,
     "grade_id": "cell-b12433945b2364a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = dc.Diabetes()\n",
    "\n",
    "X = data.X\n",
    "y = data.y\n",
    "\n",
    "pid_to_indices = {}\n",
    "for pid in X['patient_id'].unique().tolist():\n",
    "    X_df = X[X['patient_id'] == pid]\n",
    "    pid_to_indices[pid] = X_df.index\n",
    "\n",
    "splits = dc.TrainSplits(X, y, combine=True, pid_to_indices=pid_to_indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7dc2023",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c177bce8dffaa6eca676d9adc4d4e06e",
     "grade": false,
     "grade_id": "cell-0526b5e071507ed0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font color='magenta'>Task One</font>\n",
    "\n",
    "## Loss curves. \n",
    "\n",
    "In this task you'll plot a curve of the training loss and validation loss for each epoch. \n",
    "\n",
    "You will modify `best_lstm_parameters_training_data_return_loss` so that it returns three things: \n",
    "\n",
    " - A list of the average training loss for each epoch\n",
    " - A list of the average validation loss for each epoch\n",
    " - The best LSTM model\n",
    "\n",
    "For example, the training and validation loss lists should like look the following (Note that the numbers below are just an example)\n",
    "```python\n",
    "loss_list = [127.85, 74.22, ... , 68.06, 63.13]\n",
    "```\n",
    "\n",
    "\n",
    "You then use the average training losses, and average validation losses to create the following plot:\n",
    "\n",
    "![Plot of training loss and validation loss for each epoch. Losses for both decrease on average over each epoch.](attachment:loss_curve.jpg)\n",
    "\n",
    "To generate this plot you will need to set the hidden size to 64. \n",
    "\n",
    "NOTE: In `best_lstm_parameters_training_data` you only evaluated your model after training for a certain number of epochs. Now, you will evaluate at each epoch. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95f549",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3a0024e044fe10a29dcbf584e1e2667",
     "grade": false,
     "grade_id": "cell-5e6244f0725f90d1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "hidden_size = None  #TODO\n",
    "training_loss, validation_loss, lstm_model_hs64 = fbh.best_lstm_parameters_training_data_return_loss(splits.train_df_X,\n",
    "                                                    splits.train_df_y, splits.validate_df_X, splits.validate_df_y, hidden_size)\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9eb9d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f357b1166773d87fa8518f3501e71f81",
     "grade": true,
     "grade_id": "cell-e03df5c6e7f86cfe",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden test are within this cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc081718",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This plot should match the one above. \n",
    "\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fac1ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3381f285382fda548970a6c2873ce802",
     "grade": false,
     "grade_id": "cell-02db19e2328b195b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font color='magenta'>Task Two A</font>\n",
    "\n",
    "Observe the plot above for signs of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7045f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e03f49d68b4ff53b8526a098e2a1a58c",
     "grade": false,
     "grade_id": "cell-e6f936b057f30047",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**QUESTION - Does this plot suggest overfitting to you? Explain your answer below.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9c9a3e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56469958cd1083bc9061793f1763a033",
     "grade": true,
     "grade_id": "cell-c1f1ca6bac6ff21e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc1f94",
   "metadata": {},
   "source": [
    "## <font color='magenta'>Task Two B</font>\n",
    "You may note that the loss is jumping around after a certain point, and that the validation loss begins to increase. \n",
    "To address these issues, you will add a learning rate scheduler to your code. To do so you will complete the function `best_lstm_parameters_training_data_with_lr`.  This function will also need to return the average training loss at each epoch and the average validation loss at each epoch, along with the trained model as we did in the above function. \n",
    "\n",
    "For example, the training and validation loss lists should look like the following (Note that numbers below are just an example)\n",
    "```python\n",
    "loss_list = [127.85, 74.22, ... , 68.06, 63.13]\n",
    "```\n",
    "After implementing these changes we encourage you to plot the losses and see if differences arise. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b826ecd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ca534a1da89fdf414d2cab309465942",
     "grade": false,
     "grade_id": "cell-0830beb52d7ef683",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_loss_lr,validation_loss_lr,lstm_model_lr_64 = fbh.best_lstm_parameters_training_data_with_lr(splits.train_df_X,\n",
    "                                                                        splits.train_df_y, splits.validate_df_X, \\\n",
    "                                                                        splits.validate_df_y, 64)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fb021",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1587355ee92566df05adbd103c72792",
     "grade": true,
     "grade_id": "cell-6c15400d4bed4a08",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden test are within this cell\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
