{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240ad4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data.\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79be4c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('jakub/DM2023_training_docs_and_labels.tsv', sep='\\t', \n",
    "                         header=None, encoding='ISO-8859-1')\n",
    "test_data = pd.read_csv('jakub/DM2023_test_docs.tsv', sep='\\t', \n",
    "                        header=None, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f814726e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soap Programming with Java (Transcend Techniqu...</td>\n",
       "      <td>H.3.5,D.3.2,I.7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Residue objects: a challenge to web browser se...</td>\n",
       "      <td>D.4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SimCon - a simulation and visualization enviro...</td>\n",
       "      <td>I.6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An on demand data integration model for biolog...</td>\n",
       "      <td>H.2.8,J.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Usability of Multimedia Interface Based on...</td>\n",
       "      <td>I.2.0,H.5.1,H.5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Multimedia indexing and retrieval: ever great ...</td>\n",
       "      <td>H.3.1,H.2.4,H.3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Error detection and concealment for video tran...</td>\n",
       "      <td>E.4,I.4.2,I.6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Comparison of empirical testing and walkthroug...</td>\n",
       "      <td>H.5.2,H.1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>On computational efficiency of the iterative m...</td>\n",
       "      <td>G.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Network Communities: Something Old, Something ...</td>\n",
       "      <td>H.5.3,H.1.2,I.2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       1                  2\n",
       "0      Soap Programming with Java (Transcend Techniqu...  H.3.5,D.3.2,I.7.2\n",
       "1      Residue objects: a challenge to web browser se...              D.4.6\n",
       "2      SimCon - a simulation and visualization enviro...              I.6.3\n",
       "3      An on demand data integration model for biolog...          H.2.8,J.3\n",
       "4      The Usability of Multimedia Interface Based on...  I.2.0,H.5.1,H.5.2\n",
       "...                                                  ...                ...\n",
       "99995  Multimedia indexing and retrieval: ever great ...  H.3.1,H.2.4,H.3.3\n",
       "99996  Error detection and concealment for video tran...    E.4,I.4.2,I.6.6\n",
       "99997  Comparison of empirical testing and walkthroug...        H.5.2,H.1.2\n",
       "99998  On computational efficiency of the iterative m...              G.1.5\n",
       "99999  Network Communities: Something Old, Something ...  H.5.3,H.1.2,I.2.1\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f261fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>963168.txt</td>\n",
       "      <td>An Analysis of the Imagine PA Public Sector ER...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1811004.txt</td>\n",
       "      <td>The tidy set: a minimal simplicial set for com...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192631.txt</td>\n",
       "      <td>Towards usability guidelines for multimedia sy...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1183872.txt</td>\n",
       "      <td>Relational Formalism for the Management of Spa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280491.txt</td>\n",
       "      <td>Continuous parallel-iterated RKN-type PC metho...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1201771.txt</td>\n",
       "      <td>Node similarity in the citation graph Publishe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1502692.txt</td>\n",
       "      <td>Intelligently creating and recommending reusab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>881912.txt</td>\n",
       "      <td>Computer-controlled orientation of multiple op...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>789070.txt</td>\n",
       "      <td>Labelled Markov Processes: Stronger and Faster...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1508799.txt</td>\n",
       "      <td>Spatial data analysis of finite strain data ac...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                                                  1   2\n",
       "0       963168.txt  An Analysis of the Imagine PA Public Sector ER... NaN\n",
       "1      1811004.txt  The tidy set: a minimal simplicial set for com... NaN\n",
       "2       192631.txt  Towards usability guidelines for multimedia sy... NaN\n",
       "3      1183872.txt  Relational Formalism for the Management of Spa... NaN\n",
       "4      1280491.txt  Continuous parallel-iterated RKN-type PC metho... NaN\n",
       "...            ...                                                ...  ..\n",
       "99995  1201771.txt  Node similarity in the citation graph Publishe... NaN\n",
       "99996  1502692.txt  Intelligently creating and recommending reusab... NaN\n",
       "99997   881912.txt  Computer-controlled orientation of multiple op... NaN\n",
       "99998   789070.txt  Labelled Markov Processes: Stronger and Faster... NaN\n",
       "99999  1508799.txt  Spatial data analysis of finite strain data ac... NaN\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30094fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['labels'] = train_data[2].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85d15d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa712f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fad43a501e04a0ea2c9083d9db6ead7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = set()\n",
    "for i in tqdm(train_data['labels']):\n",
    "    for j in i:\n",
    "        t.add(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04d71113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.0',\n",
       " 'A.1',\n",
       " 'A.2',\n",
       " 'A.m',\n",
       " 'B.0',\n",
       " 'B.1',\n",
       " 'B.1.0',\n",
       " 'B.1.1',\n",
       " 'B.1.2',\n",
       " 'B.1.3',\n",
       " 'B.1.4',\n",
       " 'B.1.5',\n",
       " 'B.1.m',\n",
       " 'B.2',\n",
       " 'B.2.0',\n",
       " 'B.2.1',\n",
       " 'B.2.2',\n",
       " 'B.2.3',\n",
       " 'B.2.4',\n",
       " 'B.2.m',\n",
       " 'B.3',\n",
       " 'B.3.0',\n",
       " 'B.3.1',\n",
       " 'B.3.2',\n",
       " 'B.3.3',\n",
       " 'B.3.4',\n",
       " 'B.3.m',\n",
       " 'B.4',\n",
       " 'B.4.0',\n",
       " 'B.4.1',\n",
       " 'B.4.2',\n",
       " 'B.4.3',\n",
       " 'B.4.4',\n",
       " 'B.4.5',\n",
       " 'B.4.m',\n",
       " 'B.5',\n",
       " 'B.5.0',\n",
       " 'B.5.1',\n",
       " 'B.5.2',\n",
       " 'B.5.3',\n",
       " 'B.5.m',\n",
       " 'B.6',\n",
       " 'B.6.0',\n",
       " 'B.6.1',\n",
       " 'B.6.2',\n",
       " 'B.6.3',\n",
       " 'B.6.m',\n",
       " 'B.7',\n",
       " 'B.7.0',\n",
       " 'B.7.1',\n",
       " 'B.7.2',\n",
       " 'B.7.3',\n",
       " 'B.7.m',\n",
       " 'B.8',\n",
       " 'B.8.0',\n",
       " 'B.8.1',\n",
       " 'B.8.2',\n",
       " 'B.8.m',\n",
       " 'B.m',\n",
       " 'C.0',\n",
       " 'C.1',\n",
       " 'C.1.0',\n",
       " 'C.1.1',\n",
       " 'C.1.2',\n",
       " 'C.1.3',\n",
       " 'C.1.4',\n",
       " 'C.1.m',\n",
       " 'C.2',\n",
       " 'C.2.0',\n",
       " 'C.2.1',\n",
       " 'C.2.2',\n",
       " 'C.2.3',\n",
       " 'C.2.4',\n",
       " 'C.2.5',\n",
       " 'C.2.6',\n",
       " 'C.2.m',\n",
       " 'C.3',\n",
       " 'C.4',\n",
       " 'C.5',\n",
       " 'C.5.0',\n",
       " 'C.5.1',\n",
       " 'C.5.2',\n",
       " 'C.5.3',\n",
       " 'C.5.4',\n",
       " 'C.5.5',\n",
       " 'C.5.m',\n",
       " 'C.m',\n",
       " 'D.0',\n",
       " 'D.1',\n",
       " 'D.1.0',\n",
       " 'D.1.1',\n",
       " 'D.1.2',\n",
       " 'D.1.3',\n",
       " 'D.1.4',\n",
       " 'D.1.5',\n",
       " 'D.1.6',\n",
       " 'D.1.7',\n",
       " 'D.1.m',\n",
       " 'D.2',\n",
       " 'D.2.0',\n",
       " 'D.2.1',\n",
       " 'D.2.10',\n",
       " 'D.2.11',\n",
       " 'D.2.12',\n",
       " 'D.2.13',\n",
       " 'D.2.2',\n",
       " 'D.2.3',\n",
       " 'D.2.4',\n",
       " 'D.2.5',\n",
       " 'D.2.6',\n",
       " 'D.2.7',\n",
       " 'D.2.8',\n",
       " 'D.2.9',\n",
       " 'D.2.m',\n",
       " 'D.3',\n",
       " 'D.3.0',\n",
       " 'D.3.1',\n",
       " 'D.3.2',\n",
       " 'D.3.3',\n",
       " 'D.3.4',\n",
       " 'D.3.m',\n",
       " 'D.4',\n",
       " 'D.4.0',\n",
       " 'D.4.1',\n",
       " 'D.4.2',\n",
       " 'D.4.3',\n",
       " 'D.4.4',\n",
       " 'D.4.5',\n",
       " 'D.4.6',\n",
       " 'D.4.7',\n",
       " 'D.4.8',\n",
       " 'D.4.9',\n",
       " 'D.4.m',\n",
       " 'D.m',\n",
       " 'E.0',\n",
       " 'E.1',\n",
       " 'E.2',\n",
       " 'E.3',\n",
       " 'E.4',\n",
       " 'E.5',\n",
       " 'E.m',\n",
       " 'F.0',\n",
       " 'F.1',\n",
       " 'F.1.0',\n",
       " 'F.1.1',\n",
       " 'F.1.2',\n",
       " 'F.1.3',\n",
       " 'F.1.m',\n",
       " 'F.2',\n",
       " 'F.2.0',\n",
       " 'F.2.1',\n",
       " 'F.2.2',\n",
       " 'F.2.3',\n",
       " 'F.2.m',\n",
       " 'F.3',\n",
       " 'F.3.0',\n",
       " 'F.3.1',\n",
       " 'F.3.2',\n",
       " 'F.3.3',\n",
       " 'F.3.m',\n",
       " 'F.4',\n",
       " 'F.4.0',\n",
       " 'F.4.1',\n",
       " 'F.4.2',\n",
       " 'F.4.3',\n",
       " 'F.4.m',\n",
       " 'F.m',\n",
       " 'G.0',\n",
       " 'G.1',\n",
       " 'G.1.0',\n",
       " 'G.1.1',\n",
       " 'G.1.10',\n",
       " 'G.1.2',\n",
       " 'G.1.3',\n",
       " 'G.1.4',\n",
       " 'G.1.5',\n",
       " 'G.1.6',\n",
       " 'G.1.7',\n",
       " 'G.1.8',\n",
       " 'G.1.9',\n",
       " 'G.1.m',\n",
       " 'G.2',\n",
       " 'G.2.0',\n",
       " 'G.2.1',\n",
       " 'G.2.2',\n",
       " 'G.2.3',\n",
       " 'G.2.m',\n",
       " 'G.3',\n",
       " 'G.4',\n",
       " 'G.m',\n",
       " 'H.0',\n",
       " 'H.1',\n",
       " 'H.1.0',\n",
       " 'H.1.1',\n",
       " 'H.1.2',\n",
       " 'H.1.m',\n",
       " 'H.2',\n",
       " 'H.2.0',\n",
       " 'H.2.1',\n",
       " 'H.2.2',\n",
       " 'H.2.3',\n",
       " 'H.2.4',\n",
       " 'H.2.5',\n",
       " 'H.2.6',\n",
       " 'H.2.7',\n",
       " 'H.2.8',\n",
       " 'H.2.m',\n",
       " 'H.3',\n",
       " 'H.3.0',\n",
       " 'H.3.1',\n",
       " 'H.3.2',\n",
       " 'H.3.3',\n",
       " 'H.3.4',\n",
       " 'H.3.5',\n",
       " 'H.3.6',\n",
       " 'H.3.7',\n",
       " 'H.3.m',\n",
       " 'H.4',\n",
       " 'H.4.0',\n",
       " 'H.4.1',\n",
       " 'H.4.2',\n",
       " 'H.4.3',\n",
       " 'H.4.m',\n",
       " 'H.5',\n",
       " 'H.5.0',\n",
       " 'H.5.1',\n",
       " 'H.5.2',\n",
       " 'H.5.3',\n",
       " 'H.5.4',\n",
       " 'H.5.5',\n",
       " 'H.5.m',\n",
       " 'H.m',\n",
       " 'I.0',\n",
       " 'I.1',\n",
       " 'I.1.0',\n",
       " 'I.1.1',\n",
       " 'I.1.2',\n",
       " 'I.1.3',\n",
       " 'I.1.4',\n",
       " 'I.1.m',\n",
       " 'I.2',\n",
       " 'I.2.0',\n",
       " 'I.2.1',\n",
       " 'I.2.10',\n",
       " 'I.2.11',\n",
       " 'I.2.2',\n",
       " 'I.2.3',\n",
       " 'I.2.4',\n",
       " 'I.2.5',\n",
       " 'I.2.6',\n",
       " 'I.2.7',\n",
       " 'I.2.8',\n",
       " 'I.2.9',\n",
       " 'I.2.m',\n",
       " 'I.3',\n",
       " 'I.3.0',\n",
       " 'I.3.1',\n",
       " 'I.3.2',\n",
       " 'I.3.3',\n",
       " 'I.3.4',\n",
       " 'I.3.5',\n",
       " 'I.3.6',\n",
       " 'I.3.7',\n",
       " 'I.3.8',\n",
       " 'I.3.m',\n",
       " 'I.4',\n",
       " 'I.4.0',\n",
       " 'I.4.1',\n",
       " 'I.4.10',\n",
       " 'I.4.2',\n",
       " 'I.4.3',\n",
       " 'I.4.4',\n",
       " 'I.4.5',\n",
       " 'I.4.6',\n",
       " 'I.4.7',\n",
       " 'I.4.8',\n",
       " 'I.4.9',\n",
       " 'I.4.m',\n",
       " 'I.5',\n",
       " 'I.5.0',\n",
       " 'I.5.1',\n",
       " 'I.5.2',\n",
       " 'I.5.3',\n",
       " 'I.5.4',\n",
       " 'I.5.5',\n",
       " 'I.5.m',\n",
       " 'I.6',\n",
       " 'I.6.0',\n",
       " 'I.6.1',\n",
       " 'I.6.2',\n",
       " 'I.6.3',\n",
       " 'I.6.4',\n",
       " 'I.6.5',\n",
       " 'I.6.6',\n",
       " 'I.6.7',\n",
       " 'I.6.8',\n",
       " 'I.6.m',\n",
       " 'I.7',\n",
       " 'I.7.0',\n",
       " 'I.7.1',\n",
       " 'I.7.2',\n",
       " 'I.7.3',\n",
       " 'I.7.4',\n",
       " 'I.7.5',\n",
       " 'I.7.m',\n",
       " 'I.m',\n",
       " 'J',\n",
       " 'J.0',\n",
       " 'J.1',\n",
       " 'J.2',\n",
       " 'J.3',\n",
       " 'J.4',\n",
       " 'J.5',\n",
       " 'J.6',\n",
       " 'J.7',\n",
       " 'J.m',\n",
       " 'K.0',\n",
       " 'K.1',\n",
       " 'K.2',\n",
       " 'K.3',\n",
       " 'K.3.0',\n",
       " 'K.3.1',\n",
       " 'K.3.2',\n",
       " 'K.3.m',\n",
       " 'K.4',\n",
       " 'K.4.0',\n",
       " 'K.4.1',\n",
       " 'K.4.2',\n",
       " 'K.4.3',\n",
       " 'K.4.4',\n",
       " 'K.4.m',\n",
       " 'K.5',\n",
       " 'K.5.0',\n",
       " 'K.5.1',\n",
       " 'K.5.2',\n",
       " 'K.5.m',\n",
       " 'K.6',\n",
       " 'K.6.0',\n",
       " 'K.6.1',\n",
       " 'K.6.2',\n",
       " 'K.6.3',\n",
       " 'K.6.4',\n",
       " 'K.6.5',\n",
       " 'K.6.m',\n",
       " 'K.7',\n",
       " 'K.7.0',\n",
       " 'K.7.1',\n",
       " 'K.7.2',\n",
       " 'K.7.3',\n",
       " 'K.7.4',\n",
       " 'K.7.m',\n",
       " 'K.8',\n",
       " 'K.8.0',\n",
       " 'K.8.1',\n",
       " 'K.8.2',\n",
       " 'K.8.3',\n",
       " 'K.8.m',\n",
       " 'K.m'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac1e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train_data['labels'],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c03c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0716620e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (80000, 358) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Train a classifier (example: Logistic Regression)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m classifier \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m---> 29\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_enc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     32\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(X_test_tfidf)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[1;32m-> 1122\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1143\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1142\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m-> 1143\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1144\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n\u001b[0;32m   1145\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1193\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1194\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1198\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1199\u001b[0m         )\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1204\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (80000, 358) instead."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the data\n",
    "# data = pd.read_csv('DM2023_training_docs_and_labels.tsv', sep='\\t', header=None, names=['id', 'abstract', 'labels'])\n",
    "\n",
    "# Preprocess labels\n",
    "train_data['labels'] = train_data[2].apply(lambda x: x.split(','))\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data[1], train_data['labels'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Encode labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_enc = mlb.fit_transform(y_train)\n",
    "y_test_enc = mlb.transform(y_test)\n",
    "\n",
    "# Train a classifier (example: Logistic Regression)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_tfidf, y_train_enc)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test_enc, y_pred, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e269f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75220                                [I.5.5]\n",
       "48955                         [H.3.3, H.2.8]\n",
       "44966    [D.1.3, C.2.5, H.3.3, H.3.4, I.2.8]\n",
       "13568           [G.2.2, F.2.2, G.1.6, G.2.1]\n",
       "92727                         [K.3.m, K.6.1]\n",
       "                        ...                 \n",
       "6265                          [I.5.4, H.5.2]\n",
       "54886                                [H.5.2]\n",
       "76820                  [G.1.3, B.7.1, B.8.2]\n",
       "860                             [H.4.2, J.1]\n",
       "15795                  [I.2.4, F.3.3, F.4.1]\n",
       "Name: labels, Length: 80000, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8bace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
