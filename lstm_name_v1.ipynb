{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff3fbf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a17b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\OneDrive - NITT\\Custom_Download\\exported.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b262cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92e0b2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>name_g</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>8948</td>\n",
       "      <td>8948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>9031</td>\n",
       "      <td>9031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>8918</td>\n",
       "      <td>8918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>8962</td>\n",
       "      <td>8962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>9086</td>\n",
       "      <td>9086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>32221</td>\n",
       "      <td>32221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>32109</td>\n",
       "      <td>32109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>31517</td>\n",
       "      <td>31517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>31685</td>\n",
       "      <td>31685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>31915</td>\n",
       "      <td>31915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count  name_g\n",
       "year               \n",
       "1937   8948    8948\n",
       "1938   9031    9031\n",
       "1939   8918    8918\n",
       "1940   8962    8962\n",
       "1941   9086    9086\n",
       "...     ...     ...\n",
       "2018  32221   32221\n",
       "2019  32109   32109\n",
       "2020  31517   31517\n",
       "2021  31685   31685\n",
       "2022  31915   31915\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "780f9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode the categorical column 'name_g'\n",
    "label_encoder = LabelEncoder()\n",
    "df['name_g_encoded'] = label_encoder.fit_transform(df['name_g'])\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df[['year', 'name_g_encoded']]\n",
    "y = df['count']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401f3beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name_g_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>667916</th>\n",
       "      <td>1964</td>\n",
       "      <td>79366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739696</th>\n",
       "      <td>2019</td>\n",
       "      <td>80316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644430</th>\n",
       "      <td>2022</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707898</th>\n",
       "      <td>1965</td>\n",
       "      <td>35677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003653</th>\n",
       "      <td>1990</td>\n",
       "      <td>74777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>2016</td>\n",
       "      <td>38941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414414</th>\n",
       "      <td>1994</td>\n",
       "      <td>61869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>2001</td>\n",
       "      <td>97530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671155</th>\n",
       "      <td>1964</td>\n",
       "      <td>99274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>2001</td>\n",
       "      <td>7023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1396601 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  name_g_encoded\n",
       "667916   1964           79366\n",
       "1739696  2019           80316\n",
       "1644430  2022             354\n",
       "707898   1965           35677\n",
       "1003653  1990           74777\n",
       "...       ...             ...\n",
       "259178   2016           38941\n",
       "1414414  1994           61869\n",
       "131932   2001           97530\n",
       "671155   1964           99274\n",
       "121958   2001            7023\n",
       "\n",
       "[1396601 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83639a76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Input\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Sample DataFrame\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'year': [2000, 2000, 2000, 2000, 2000, 2019, 2019, 2019, 2019, 2019],\n",
    "        'count': [25957, 23085, 19968, 17998, 17712, 5, 5, 5, 5, 5],\n",
    "        'name_g': ['Emily_F', 'Hannah_F', 'Madison_F', 'Ashley_F', 'Sarah_F',\n",
    "                   'Zyheem_M', 'Zykel_M', 'Zyking_M', 'Zyn_M', 'Zyran_M']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert Year column to datetime and set it as the index\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index('year', inplace=True)\n",
    "\n",
    "# Normalize the count values\n",
    "scaler_count = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_count = scaler_count.fit_transform(df[['count']])\n",
    "\n",
    "# Encode the name_g column\n",
    "df['name_g_encoded'] = df['name_g'].astype('category').cat.codes\n",
    "\n",
    "# Normalize the encoded name values\n",
    "scaler_name = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_name = scaler_name.fit_transform(df[['name_g_encoded']])\n",
    "\n",
    "# Normalize the year values\n",
    "scaler_year = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_year = scaler_year.fit_transform(df[['year']])\n",
    "\n",
    "# Combine the scaled count, name, and year features\n",
    "scaled_data = np.concatenate([scaled_count, scaled_name, scaled_year], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "train_data, test_data = scaled_data[:train_size], scaled_data[train_size:]\n",
    "\n",
    "# Prepare data for LSTM model\n",
    "def create_dataset(data, time_steps):\n",
    "    X, y_count, y_name, y_year = [], [], [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps), :])\n",
    "        y_count.append(data[i + time_steps, 0])\n",
    "        y_name.append(data[i + time_steps, 1])\n",
    "        y_year.append(data[i + time_steps, 2])\n",
    "    return np.array(X), np.array(y_count), np.array(y_name), np.array(y_year)\n",
    "\n",
    "time_steps = 12  # Define the number of time steps\n",
    "X_train, y_train_count, y_train_name, y_train_year = create_dataset(train_data, time_steps)\n",
    "X_test, y_test_count, y_test_name, y_test_year = create_dataset(test_data, time_steps)\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "input_layer = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "lstm_layer = LSTM(units=50)(input_layer)\n",
    "dense_count = Dense(units=1, name='count')(lstm_layer)\n",
    "dense_name = Dense(units=1, name='name')(lstm_layer)\n",
    "dense_year = Dense(units=1, name='year')(lstm_layer)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=input_layer, outputs=[dense_count, dense_name, dense_year])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, [y_train_count, y_train_name, y_train_year], epochs=100, batch_size=32, validation_data=(X_test, [y_test_count, y_test_name, y_test_year]))\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, [y_test_count, y_test_name, y_test_year])\n",
    "print(\"Test Loss:\", loss)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b207ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\avitr\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.19.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b403682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myNEWenv)",
   "language": "python",
   "name": "mynewenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
