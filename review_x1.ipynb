{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Soil Viability for Sustainable Agriculture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this challenge is to train a model that classifies soils as viable or not for sustainable agriculture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° As part of an initiative to promote sustainable agriculture worldwide, experiments were made at different locations.\n",
    "\n",
    "Each experiment consisted in an analysis of the soil.  \n",
    "The results of these analysis are our features.\n",
    "\n",
    "After the analysis, a small agriculture project was launched at the location:    \n",
    "- If the project was successful, the soil was labeled as viable.  \n",
    "- On the other hand if the project failed, the soil was labeled as not-viable.  \n",
    "\n",
    "The viability of the soil is our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Small test projects were used for data collection, but the ambition is to launch projects of much larger scale.  \n",
    "\n",
    "The costs and time investment on these large scale projects are extremely high.  \n",
    "\n",
    "üéØ To be valuable, our model should be right at least 90% of the time when it identifies a viable soil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a description of the fields:\n",
    "- **id**: Unique identification number of the experiment\n",
    "- **scientist**: Name of the scientist responsible for the experiment\n",
    "- **measure_index**: Engineered measure of soil characteristics\n",
    "- **measure_moisture**: Moisture level of the soil\n",
    "- **measure_temperature**: Temperature of the soil, in Celsius degrees\n",
    "- **measure_chemicals**: Indice of chemicals presence in the soil\n",
    "- **measure_biodiversity**: Indice of biodiversity in the soil\n",
    "- **measure_flora**: Indice of diversity of flora in the soil\n",
    "- **main_element**: Symbol of the main chemical element found in the soil\n",
    "- **past_agriculture**: Indicates the presence of past agriculture on the soil\n",
    "- **soil_condition**: Overall indicator of the soil fertility\n",
    "- **datetime_start**: Timestamp of experiment's start \n",
    "- **datetime_end**: Timestamp of experiment's end\n",
    "- **target**: Viability of the soil  \n",
    "    - 1: means the soil was viable, i.e. the test project was a success  \n",
    "    - 0: means the soil was not viable, i.e. the test project was a failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C5 - Pr√©parer les donn√©es en vue de l'apprentissage afin que celles-ci soient nettoy√©es*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Load the csv provided at this URL: https://wagon-public-datasets.s3.amazonaws.com/certification/soils_viability/soils_viability_train.csv.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:40.398126Z",
     "start_time": "2021-09-09T15:39:40.377328Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>scientist</th>\n",
       "      <th>measure_index</th>\n",
       "      <th>measure_moisture</th>\n",
       "      <th>measure_temperature</th>\n",
       "      <th>measure_chemicals</th>\n",
       "      <th>measure_biodiversity</th>\n",
       "      <th>measure_flora</th>\n",
       "      <th>main_element</th>\n",
       "      <th>past_agriculture</th>\n",
       "      <th>soil_condition</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_end</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>493</td>\n",
       "      <td>Kathryn Owens</td>\n",
       "      <td>1.875085</td>\n",
       "      <td>24.442232</td>\n",
       "      <td>18.510316</td>\n",
       "      <td>5.715697</td>\n",
       "      <td>521.074105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Na</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>2017-06-27 16:53:42</td>\n",
       "      <td>2017-06-27 20:05:36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2340</td>\n",
       "      <td>Andrea Pratt</td>\n",
       "      <td>7.658911</td>\n",
       "      <td>30.121175</td>\n",
       "      <td>17.050250</td>\n",
       "      <td>1.973804</td>\n",
       "      <td>314.443474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ca</td>\n",
       "      <td>no</td>\n",
       "      <td>rich</td>\n",
       "      <td>2018-12-10 07:06:56</td>\n",
       "      <td>2018-12-10 11:43:29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5434</td>\n",
       "      <td>Kaitlyn Jackson</td>\n",
       "      <td>18.000212</td>\n",
       "      <td>34.188025</td>\n",
       "      <td>17.157393</td>\n",
       "      <td>3.658506</td>\n",
       "      <td>361.796180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Al</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-10-04 18:45:29</td>\n",
       "      <td>2018-10-04 23:20:38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2304</td>\n",
       "      <td>Brett Rosario</td>\n",
       "      <td>4.056764</td>\n",
       "      <td>37.462768</td>\n",
       "      <td>13.275961</td>\n",
       "      <td>6.666983</td>\n",
       "      <td>402.016494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ca</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-10-03 08:03:36</td>\n",
       "      <td>2018-10-03 10:56:40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1911</td>\n",
       "      <td>Craig Thompson</td>\n",
       "      <td>53.271676</td>\n",
       "      <td>31.425482</td>\n",
       "      <td>17.433458</td>\n",
       "      <td>1.940748</td>\n",
       "      <td>978.383654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Si</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>2018-07-20 09:27:34</td>\n",
       "      <td>2018-07-20 13:48:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4733</td>\n",
       "      <td>Stacy Elliott</td>\n",
       "      <td>5.446522</td>\n",
       "      <td>31.946289</td>\n",
       "      <td>14.820124</td>\n",
       "      <td>1.531663</td>\n",
       "      <td>775.368114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ca</td>\n",
       "      <td>yes</td>\n",
       "      <td>rich</td>\n",
       "      <td>2017-08-06 14:23:51</td>\n",
       "      <td>2017-08-06 19:20:46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1597</td>\n",
       "      <td>Scott Morris</td>\n",
       "      <td>4.986124</td>\n",
       "      <td>28.368372</td>\n",
       "      <td>19.055275</td>\n",
       "      <td>1.095355</td>\n",
       "      <td>806.166614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Si</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>2018-03-19 10:47:24</td>\n",
       "      <td>2018-03-19 12:12:49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1258</td>\n",
       "      <td>Denise Duffy</td>\n",
       "      <td>19.539513</td>\n",
       "      <td>39.871162</td>\n",
       "      <td>16.362313</td>\n",
       "      <td>0.488977</td>\n",
       "      <td>388.962889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Na</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-09-14 10:32:44</td>\n",
       "      <td>2018-09-14 13:14:49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6526</td>\n",
       "      <td>Casey Rivera</td>\n",
       "      <td>45.656502</td>\n",
       "      <td>33.024977</td>\n",
       "      <td>15.167387</td>\n",
       "      <td>1.579964</td>\n",
       "      <td>405.198078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-08-15 06:06:40</td>\n",
       "      <td>2018-08-15 10:15:31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>331</td>\n",
       "      <td>Christopher Sullivan</td>\n",
       "      <td>20.629855</td>\n",
       "      <td>38.786551</td>\n",
       "      <td>16.189421</td>\n",
       "      <td>3.075686</td>\n",
       "      <td>528.724173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-03-04 02:13:01</td>\n",
       "      <td>2018-03-04 03:23:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8930</td>\n",
       "      <td>Alexandra Escobar</td>\n",
       "      <td>1.829298</td>\n",
       "      <td>27.879553</td>\n",
       "      <td>13.799630</td>\n",
       "      <td>0.654677</td>\n",
       "      <td>581.532113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Si</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-11-07 08:19:14</td>\n",
       "      <td>2018-11-07 09:53:55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5446</td>\n",
       "      <td>Christopher Garcia</td>\n",
       "      <td>20.664878</td>\n",
       "      <td>18.716775</td>\n",
       "      <td>20.517609</td>\n",
       "      <td>0.667021</td>\n",
       "      <td>378.576203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Na</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>2018-12-22 05:07:18</td>\n",
       "      <td>2018-12-22 07:18:54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>344</td>\n",
       "      <td>Ronnie Bradshaw</td>\n",
       "      <td>23.210142</td>\n",
       "      <td>46.035505</td>\n",
       "      <td>19.777019</td>\n",
       "      <td>2.870648</td>\n",
       "      <td>211.201244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-01-18 16:33:53</td>\n",
       "      <td>2018-01-18 19:08:49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4494</td>\n",
       "      <td>Alan Wood</td>\n",
       "      <td>48.732732</td>\n",
       "      <td>23.351928</td>\n",
       "      <td>17.153110</td>\n",
       "      <td>3.363983</td>\n",
       "      <td>816.254947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poor</td>\n",
       "      <td>2017-08-07 16:06:24</td>\n",
       "      <td>2017-08-07 18:38:48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9264</td>\n",
       "      <td>Matthew Casey</td>\n",
       "      <td>4.155507</td>\n",
       "      <td>36.761459</td>\n",
       "      <td>20.300944</td>\n",
       "      <td>1.500225</td>\n",
       "      <td>1181.783523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Na</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>2017-11-09 02:32:32</td>\n",
       "      <td>2017-11-09 07:02:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7020</td>\n",
       "      <td>Erin Alvarez</td>\n",
       "      <td>20.561856</td>\n",
       "      <td>45.843531</td>\n",
       "      <td>18.565287</td>\n",
       "      <td>8.056528</td>\n",
       "      <td>564.605047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Na</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>2018-06-30 21:20:40</td>\n",
       "      <td>2018-06-30 22:25:26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5545</td>\n",
       "      <td>Joshua Chandler</td>\n",
       "      <td>24.956048</td>\n",
       "      <td>29.991609</td>\n",
       "      <td>18.687492</td>\n",
       "      <td>1.622977</td>\n",
       "      <td>907.324802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Al</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-01-22 15:13:39</td>\n",
       "      <td>2018-01-22 16:54:07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7677</td>\n",
       "      <td>Trevor Green</td>\n",
       "      <td>44.435801</td>\n",
       "      <td>25.146919</td>\n",
       "      <td>17.812419</td>\n",
       "      <td>5.259613</td>\n",
       "      <td>288.498419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-04-01 17:23:31</td>\n",
       "      <td>2018-04-01 21:18:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8671</td>\n",
       "      <td>Julie Weaver</td>\n",
       "      <td>71.505253</td>\n",
       "      <td>17.055479</td>\n",
       "      <td>15.875124</td>\n",
       "      <td>2.646964</td>\n",
       "      <td>776.283392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>2017-12-24 20:14:26</td>\n",
       "      <td>2017-12-24 21:16:39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6047</td>\n",
       "      <td>Eileen Taylor</td>\n",
       "      <td>36.646794</td>\n",
       "      <td>33.616622</td>\n",
       "      <td>18.616787</td>\n",
       "      <td>5.189759</td>\n",
       "      <td>365.759900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Na</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-11-04 11:21:08</td>\n",
       "      <td>2018-11-04 13:24:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             scientist  measure_index  measure_moisture  \\\n",
       "0    493         Kathryn Owens       1.875085         24.442232   \n",
       "1   2340          Andrea Pratt       7.658911         30.121175   \n",
       "2   5434       Kaitlyn Jackson      18.000212         34.188025   \n",
       "3   2304         Brett Rosario       4.056764         37.462768   \n",
       "4   1911        Craig Thompson      53.271676         31.425482   \n",
       "5   4733         Stacy Elliott       5.446522         31.946289   \n",
       "6   1597          Scott Morris       4.986124         28.368372   \n",
       "7   1258          Denise Duffy      19.539513         39.871162   \n",
       "8   6526          Casey Rivera      45.656502         33.024977   \n",
       "9    331  Christopher Sullivan      20.629855         38.786551   \n",
       "10  8930     Alexandra Escobar       1.829298         27.879553   \n",
       "11  5446    Christopher Garcia      20.664878         18.716775   \n",
       "12   344       Ronnie Bradshaw      23.210142         46.035505   \n",
       "13  4494             Alan Wood      48.732732         23.351928   \n",
       "14  9264         Matthew Casey       4.155507         36.761459   \n",
       "15  7020          Erin Alvarez      20.561856         45.843531   \n",
       "16  5545       Joshua Chandler      24.956048         29.991609   \n",
       "17  7677          Trevor Green      44.435801         25.146919   \n",
       "18  8671          Julie Weaver      71.505253         17.055479   \n",
       "19  6047         Eileen Taylor      36.646794         33.616622   \n",
       "\n",
       "    measure_temperature  measure_chemicals  measure_biodiversity  \\\n",
       "0             18.510316           5.715697            521.074105   \n",
       "1             17.050250           1.973804            314.443474   \n",
       "2             17.157393           3.658506            361.796180   \n",
       "3             13.275961           6.666983            402.016494   \n",
       "4             17.433458           1.940748            978.383654   \n",
       "5             14.820124           1.531663            775.368114   \n",
       "6             19.055275           1.095355            806.166614   \n",
       "7             16.362313           0.488977            388.962889   \n",
       "8             15.167387           1.579964            405.198078   \n",
       "9             16.189421           3.075686            528.724173   \n",
       "10            13.799630           0.654677            581.532113   \n",
       "11            20.517609           0.667021            378.576203   \n",
       "12            19.777019           2.870648            211.201244   \n",
       "13            17.153110           3.363983            816.254947   \n",
       "14            20.300944           1.500225           1181.783523   \n",
       "15            18.565287           8.056528            564.605047   \n",
       "16            18.687492           1.622977            907.324802   \n",
       "17            17.812419           5.259613            288.498419   \n",
       "18            15.875124           2.646964            776.283392   \n",
       "19            18.616787           5.189759            365.759900   \n",
       "\n",
       "    measure_flora main_element past_agriculture soil_condition  \\\n",
       "0             NaN           Na              yes         normal   \n",
       "1             NaN           Ca               no           rich   \n",
       "2             NaN           Al              yes         normal   \n",
       "3             NaN           Ca               no         normal   \n",
       "4             NaN           Si               no           poor   \n",
       "5             NaN           Ca              yes           rich   \n",
       "6             NaN           Si              yes           poor   \n",
       "7             NaN           Na              yes         normal   \n",
       "8             NaN            C               no         normal   \n",
       "9             NaN           Ca              NaN         normal   \n",
       "10            NaN           Si              yes         normal   \n",
       "11            NaN           Na               no           poor   \n",
       "12            NaN           Ca              NaN         normal   \n",
       "13            NaN            C              NaN           poor   \n",
       "14            NaN           Na              NaN         normal   \n",
       "15            NaN           Na               no           poor   \n",
       "16            NaN           Al              NaN         normal   \n",
       "17            NaN            O               no         normal   \n",
       "18            NaN           Ca              NaN         normal   \n",
       "19            NaN           Na               no         normal   \n",
       "\n",
       "         datetime_start         datetime_end  target  \n",
       "0   2017-06-27 16:53:42  2017-06-27 20:05:36       1  \n",
       "1   2018-12-10 07:06:56  2018-12-10 11:43:29       1  \n",
       "2   2018-10-04 18:45:29  2018-10-04 23:20:38       0  \n",
       "3   2018-10-03 08:03:36  2018-10-03 10:56:40       0  \n",
       "4   2018-07-20 09:27:34  2018-07-20 13:48:30       0  \n",
       "5   2017-08-06 14:23:51  2017-08-06 19:20:46       1  \n",
       "6   2018-03-19 10:47:24  2018-03-19 12:12:49       0  \n",
       "7   2018-09-14 10:32:44  2018-09-14 13:14:49       1  \n",
       "8   2018-08-15 06:06:40  2018-08-15 10:15:31       0  \n",
       "9   2018-03-04 02:13:01  2018-03-04 03:23:59       1  \n",
       "10  2018-11-07 08:19:14  2018-11-07 09:53:55       0  \n",
       "11  2018-12-22 05:07:18  2018-12-22 07:18:54       1  \n",
       "12  2018-01-18 16:33:53  2018-01-18 19:08:49       0  \n",
       "13  2017-08-07 16:06:24  2017-08-07 18:38:48       0  \n",
       "14  2017-11-09 02:32:32  2017-11-09 07:02:11       1  \n",
       "15  2018-06-30 21:20:40  2018-06-30 22:25:26       0  \n",
       "16  2018-01-22 15:13:39  2018-01-22 16:54:07       0  \n",
       "17  2018-04-01 17:23:31  2018-04-01 21:18:55       1  \n",
       "18  2017-12-24 20:14:26  2017-12-24 21:16:39       0  \n",
       "19  2018-11-04 11:21:08  2018-11-04 13:24:00       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/certification/soils_viability/soils_viability_train.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8302, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T15:16:16.968282Z",
     "start_time": "2021-08-26T15:16:16.912761Z"
    }
   },
   "source": [
    "**üìù Clean the dataset and store the resulting dataset in the `data` variable:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:40.500340Z",
     "start_time": "2021-09-09T15:39:40.463560Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\AppData\\Local\\Temp\\ipykernel_23636\\3178461456.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(df[column].median(), inplace=True)\n",
      "C:\\Users\\avitr\\AppData\\Local\\Temp\\ipykernel_23636\\3178461456.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(df[column].median(), inplace=True)\n",
      "C:\\Users\\avitr\\AppData\\Local\\Temp\\ipykernel_23636\\3178461456.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(df[column].median(), inplace=True)\n",
      "C:\\Users\\avitr\\AppData\\Local\\Temp\\ipykernel_23636\\3178461456.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(df[column].median(), inplace=True)\n",
      "C:\\Users\\avitr\\AppData\\Local\\Temp\\ipykernel_23636\\3178461456.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['past_agriculture'].fillna(df['past_agriculture'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>scientist</th>\n",
       "      <th>measure_index</th>\n",
       "      <th>measure_moisture</th>\n",
       "      <th>measure_temperature</th>\n",
       "      <th>measure_chemicals</th>\n",
       "      <th>measure_biodiversity</th>\n",
       "      <th>main_element</th>\n",
       "      <th>past_agriculture</th>\n",
       "      <th>soil_condition</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_end</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>493</td>\n",
       "      <td>Kathryn Owens</td>\n",
       "      <td>1.875085</td>\n",
       "      <td>24.442232</td>\n",
       "      <td>18.510316</td>\n",
       "      <td>5.715697</td>\n",
       "      <td>521.074105</td>\n",
       "      <td>Na</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>2017-06-27 16:53:42</td>\n",
       "      <td>2017-06-27 20:05:36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2340</td>\n",
       "      <td>Andrea Pratt</td>\n",
       "      <td>7.658911</td>\n",
       "      <td>30.121175</td>\n",
       "      <td>17.050250</td>\n",
       "      <td>1.973804</td>\n",
       "      <td>314.443474</td>\n",
       "      <td>Ca</td>\n",
       "      <td>no</td>\n",
       "      <td>rich</td>\n",
       "      <td>2018-12-10 07:06:56</td>\n",
       "      <td>2018-12-10 11:43:29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5434</td>\n",
       "      <td>Kaitlyn Jackson</td>\n",
       "      <td>18.000212</td>\n",
       "      <td>34.188025</td>\n",
       "      <td>17.157393</td>\n",
       "      <td>3.658506</td>\n",
       "      <td>361.796180</td>\n",
       "      <td>Al</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-10-04 18:45:29</td>\n",
       "      <td>2018-10-04 23:20:38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2304</td>\n",
       "      <td>Brett Rosario</td>\n",
       "      <td>4.056764</td>\n",
       "      <td>37.462768</td>\n",
       "      <td>13.275961</td>\n",
       "      <td>6.666983</td>\n",
       "      <td>402.016494</td>\n",
       "      <td>Ca</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-10-03 08:03:36</td>\n",
       "      <td>2018-10-03 10:56:40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1911</td>\n",
       "      <td>Craig Thompson</td>\n",
       "      <td>53.271676</td>\n",
       "      <td>31.425482</td>\n",
       "      <td>17.433458</td>\n",
       "      <td>1.940748</td>\n",
       "      <td>978.383654</td>\n",
       "      <td>Si</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>2018-07-20 09:27:34</td>\n",
       "      <td>2018-07-20 13:48:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8297</th>\n",
       "      <td>6275</td>\n",
       "      <td>James Carter</td>\n",
       "      <td>6.616369</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>17.283441</td>\n",
       "      <td>7.693774</td>\n",
       "      <td>683.214251</td>\n",
       "      <td>Al</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>2017-04-23 04:10:57</td>\n",
       "      <td>2017-04-23 06:11:58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8298</th>\n",
       "      <td>9851</td>\n",
       "      <td>Benjamin Rodriguez</td>\n",
       "      <td>23.578767</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>18.456903</td>\n",
       "      <td>1.009824</td>\n",
       "      <td>313.740816</td>\n",
       "      <td>O</td>\n",
       "      <td>no</td>\n",
       "      <td>rich</td>\n",
       "      <td>2017-07-21 16:57:54</td>\n",
       "      <td>2017-07-21 20:30:17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8299</th>\n",
       "      <td>1453</td>\n",
       "      <td>Colin Baxter</td>\n",
       "      <td>9.967761</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>14.949271</td>\n",
       "      <td>3.484480</td>\n",
       "      <td>370.533784</td>\n",
       "      <td>O</td>\n",
       "      <td>no</td>\n",
       "      <td>rich</td>\n",
       "      <td>2017-01-07 04:00:02</td>\n",
       "      <td>2017-01-07 06:26:16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8300</th>\n",
       "      <td>4265</td>\n",
       "      <td>Christina Ortega</td>\n",
       "      <td>5.195543</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>21.811990</td>\n",
       "      <td>2.261112</td>\n",
       "      <td>403.970941</td>\n",
       "      <td>Si</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>2018-12-12 10:12:04</td>\n",
       "      <td>2018-12-12 13:02:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>8906</td>\n",
       "      <td>Shawn Campbell</td>\n",
       "      <td>4.525789</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>19.170774</td>\n",
       "      <td>1.409303</td>\n",
       "      <td>452.556674</td>\n",
       "      <td>K</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>2017-05-02 03:18:48</td>\n",
       "      <td>2017-05-02 08:05:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8302 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           scientist  measure_index  measure_moisture  \\\n",
       "0      493       Kathryn Owens       1.875085         24.442232   \n",
       "1     2340        Andrea Pratt       7.658911         30.121175   \n",
       "2     5434     Kaitlyn Jackson      18.000212         34.188025   \n",
       "3     2304       Brett Rosario       4.056764         37.462768   \n",
       "4     1911      Craig Thompson      53.271676         31.425482   \n",
       "...    ...                 ...            ...               ...   \n",
       "8297  6275        James Carter       6.616369        999.000000   \n",
       "8298  9851  Benjamin Rodriguez      23.578767        999.000000   \n",
       "8299  1453        Colin Baxter       9.967761        999.000000   \n",
       "8300  4265    Christina Ortega       5.195543        999.000000   \n",
       "8301  8906      Shawn Campbell       4.525789        999.000000   \n",
       "\n",
       "      measure_temperature  measure_chemicals  measure_biodiversity  \\\n",
       "0               18.510316           5.715697            521.074105   \n",
       "1               17.050250           1.973804            314.443474   \n",
       "2               17.157393           3.658506            361.796180   \n",
       "3               13.275961           6.666983            402.016494   \n",
       "4               17.433458           1.940748            978.383654   \n",
       "...                   ...                ...                   ...   \n",
       "8297            17.283441           7.693774            683.214251   \n",
       "8298            18.456903           1.009824            313.740816   \n",
       "8299            14.949271           3.484480            370.533784   \n",
       "8300            21.811990           2.261112            403.970941   \n",
       "8301            19.170774           1.409303            452.556674   \n",
       "\n",
       "     main_element past_agriculture soil_condition      datetime_start  \\\n",
       "0              Na              yes         normal 2017-06-27 16:53:42   \n",
       "1              Ca               no           rich 2018-12-10 07:06:56   \n",
       "2              Al              yes         normal 2018-10-04 18:45:29   \n",
       "3              Ca               no         normal 2018-10-03 08:03:36   \n",
       "4              Si               no           poor 2018-07-20 09:27:34   \n",
       "...           ...              ...            ...                 ...   \n",
       "8297           Al               no           poor 2017-04-23 04:10:57   \n",
       "8298            O               no           rich 2017-07-21 16:57:54   \n",
       "8299            O               no           rich 2017-01-07 04:00:02   \n",
       "8300           Si               no           poor 2018-12-12 10:12:04   \n",
       "8301            K               no         normal 2017-05-02 03:18:48   \n",
       "\n",
       "            datetime_end  target  \n",
       "0    2017-06-27 20:05:36       1  \n",
       "1    2018-12-10 11:43:29       1  \n",
       "2    2018-10-04 23:20:38       0  \n",
       "3    2018-10-03 10:56:40       0  \n",
       "4    2018-07-20 13:48:30       0  \n",
       "...                  ...     ...  \n",
       "8297 2017-04-23 06:11:58       0  \n",
       "8298 2017-07-21 20:30:17       1  \n",
       "8299 2017-01-07 06:26:16       1  \n",
       "8300 2018-12-12 13:02:11       0  \n",
       "8301 2017-05-02 08:05:03       1  \n",
       "\n",
       "[8302 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns='measure_flora', inplace=True)\n",
    "columns_to_fill = ['measure_moisture', 'measure_temperature', 'measure_chemicals', 'measure_biodiversity']\n",
    "for column in columns_to_fill:\n",
    "    df[column].fillna(df[column].median(), inplace=True)\n",
    "df['past_agriculture'].fillna(df['past_agriculture'].mode()[0], inplace=True)\n",
    "df['datetime_start'] = pd.to_datetime(df['datetime_start'])\n",
    "df['datetime_end'] = pd.to_datetime(df['datetime_end'])\n",
    "\n",
    "data = df\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save your results\n",
    "\n",
    "Run the cell below to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbresult\n",
      "  Downloading nbresult-0.0.9-py3-none-any.whl (4.3 kB)\n",
      "Installing collected packages: nbresult\n",
      "Successfully installed nbresult-0.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install nbresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\genericpath.py:42\u001b[0m, in \u001b[0;36misdir\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'D:\\\\tests'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbresult\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChallengeResult\n\u001b[0;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m ChallengeResult(\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_cleaning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     columns\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m      5\u001b[0m     shape\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m      6\u001b[0m     samples\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m7000\u001b[39m:,:]\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nbresult\\__init__.py:45\u001b[0m, in \u001b[0;36mChallengeResult.write\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write down values from initialize to result.pickle\"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     tests_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_locate_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mgetsizeof(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10_000\u001b[39m:\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCheck the arguments of your ChallengeResult\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, one is way too big.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nbresult\\__init__.py:30\u001b[0m, in \u001b[0;36mChallengeResult._locate_tests\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_locate_tests\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     28\u001b[0m     cwd \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtests\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     31\u001b[0m         cwd \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(cwd)\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m cwd \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39msep:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\genericpath.py:42\u001b[0m, in \u001b[0;36misdir\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return true if the pathname refers to an existing directory.\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "results = ChallengeResult(\n",
    "    \"data_cleaning\",\n",
    "    columns=data.columns,\n",
    "    shape=data.shape,\n",
    "    samples=data.loc[7000:,:]\n",
    ")\n",
    "results.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target, Baseline & Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C9 - Entra√Æner un mod√®le d'apprentissage supervis√© pour optimiser une fonction de pr√©diction √† partir d'exemples annot√©es (50%)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T09:51:04.532853Z",
     "start_time": "2021-08-26T09:51:04.520413Z"
    }
   },
   "source": [
    "**üìù Check the number of target classes and their repartition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes_repartition = data['target'].value_counts(normalize=True)\n",
    "\n",
    "print(target_classes_repartition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:41.810088Z",
     "start_time": "2021-09-09T15:39:41.778859Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "target_counts = data['target'].value_counts()\n",
    "print(target_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Is the dataset balanced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> Ratio being close to 1 (Balance: 0.991) the dataset is balanced, thats means we are safe to proceed to the training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Recall our initial requirement:\n",
    "\n",
    "**\"To be valuable, our model should be right at least 90% of the time when it predicts a viable soil.\"**\n",
    "\n",
    "üìù Store the name of the metric we should use for this purpose in a variable `metric` from the list proposed by [Scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:41.877982Z",
     "start_time": "2021-09-09T15:39:41.862118Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "metric = \"precision\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Compute the baseline score and store the result as a floating number in the `baseline_score` variable.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:41.825750Z",
     "start_time": "2021-09-09T15:39:41.812050Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "baseline_score = max(data['target'].value_counts(normalize=True))\n",
    "baseline_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Store the target in a variable named `y`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:41.857148Z",
     "start_time": "2021-09-09T15:39:41.827800Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save your results\n",
    "\n",
    "Run the cell below to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ChallengeResult(\n",
    "    \"baseline\",\n",
    "    metric=metric,\n",
    "    baseline=baseline_score\n",
    ")\n",
    "results.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:41.935151Z",
     "start_time": "2021-09-09T15:39:41.880164Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Store the features in a DataFrame `X`.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:41.954123Z",
     "start_time": "2021-09-09T15:39:41.937063Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X = data.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Two features in there are useless.\n",
    "\n",
    "- `id`: serves a technical need and does not carry any information.  \n",
    "- `scientist`: almost all experiments were conducted by different scientists, we assume they all followed the same protocol for the experiment.\n",
    "\n",
    "**üìù Drop these two features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:41.973910Z",
     "start_time": "2021-09-09T15:39:41.955889Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X = X.drop(['id', 'scientist'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Create variables to store feature names according to their types.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T15:23:40.164290Z",
     "start_time": "2021-08-26T15:23:40.149621Z"
    }
   },
   "source": [
    "- `feat_num`: list of numerical features' name\n",
    "- `feat_cat` list of categorical features' name\n",
    "- `feat_time` list of time features' name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:41.994679Z",
     "start_time": "2021-09-09T15:39:41.976174Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "feat_num = ['measure_index', 'measure_moisture', 'measure_temperature', 'measure_chemicals', 'measure_biodiversity']\n",
    "feat_cat = ['main_element', 'past_agriculture', 'soil_condition']\n",
    "feat_time = ['datetime_start', 'datetime_end']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° We will ignore date-like features for the basic preprocessing.\n",
    "\n",
    "**üìù Create `X_basic` that contains only numerical and categorical features.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:42.025512Z",
     "start_time": "2021-09-09T15:39:41.997100Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_basic = X[feat_num + feat_cat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save your results\n",
    "\n",
    "Run the cell below to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:42.054493Z",
     "start_time": "2021-09-09T15:39:42.027906Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    \"features\",\n",
    "    columns=X.columns,\n",
    "    shape=X.shape,\n",
    "    target=y.ndim\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C6 - Transformer les donn√©es d'entr√©e afin de satisfaire les contraintes inh√©rentes au mod√®le (Preprocessing)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:42.067672Z",
     "start_time": "2021-09-09T15:39:42.056478Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Scale and Encode your features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a ColumnTransformer that:\n",
    "- Scale the numerical features between $0$ and $1$\n",
    "- Encode the categorical features\n",
    "\n",
    "Store it in a variable `preprocessing_basic`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:42.112025Z",
     "start_time": "2021-09-09T15:39:42.094352Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "preprocessing_basic = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), feat_num),  # Mise √† l'√©chelle des caract√©ristiques num√©riques\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), feat_cat)  # Encodage des caract√©ristiques cat√©gorielles\n",
    "    ],\n",
    "    remainder='drop'  # Ignorer les autres colonnes non sp√©cifi√©es dans transformers\n",
    ")\n",
    "\n",
    "# Affichage du transformateur\n",
    "preprocessing_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C9 - Entra√Æner un mod√®le d'apprentissage supervis√© pour optimiser une fonction de pr√©diction √† partir d'exemples annot√©es (50%)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Cross-validate a linear model on `X_basic` to see how it compares to your baseline.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside a pipeline, apply the basic preprocessing, then use a basic **linear** model with **no penalty**.\n",
    "\n",
    "Cross-validate your pipeline and store the scores in `scores_linear` as a `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:42.202414Z",
     "start_time": "2021-09-09T15:39:42.190310Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Correction du pipeline avec LogisticRegression pour un probl√®me de classification\n",
    "pipeline_linear = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessing_basic),  # Pr√©traitement d√©fini pr√©c√©demment\n",
    "    ('linear_model', LogisticRegression(penalty='none', max_iter=1000))  # Mod√®le de classification lin√©aire\n",
    "])\n",
    "\n",
    "# R√©-application de la validation crois√©e avec la correction\n",
    "scores_linear = cross_val_score(pipeline_linear, X_basic, data['target'], cv=5, scoring='precision')\n",
    "\n",
    "print(scores_linear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ùì Does your model beat the baseline? Do you reach your goal?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> Yes, the model clearly beats the baseline. The model's accuracy scores are significantly higher than the proportion of the majority class, indicating a significant improvement over a naive prediction. The objective was for the model to be correct at least 90% of the time when it identifies soil as viable. Accuracy scores obtained with the linear model are below this target, falling between approximately 78% and 81% accuracy. Although the model outperforms the baseline and shows an ability to identify viable soils more accurately than chance, it does not reach the 90% accuracy target. Although the model is an improvement over a naive prediction, it does not reach the set goal of 90% accuracy for positive predictions. This suggests that further model improvements or the use of more advanced modeling techniques may be necessary to achieve this goal. You might consider exploring other models, adding or selecting features more strategically, or applying feature engineering techniques to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save your results\n",
    "\n",
    "Run the cell below to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:42.999830Z",
     "start_time": "2021-09-09T15:39:37.573Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "X_preproc=preprocessing_basic.fit_transform(X_basic)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_,X_val,y_,y_val = train_test_split(X_basic,y,test_size=0.3,random_state=10)\n",
    "pipe=pipeline_linear.fit(X_,y_)\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'basic_pipeline',\n",
    "    preproc=preprocessing_basic,\n",
    "    preproc_shape=X_preproc.shape,\n",
    "    pipe=pipeline_linear,\n",
    "    y=y_val,\n",
    "    y_pred=pipeline_linear.predict(X_val),\n",
    "    scores=scores_linear\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C7 - G√©n√©rer des donn√©es d'entr√©e afin de satisfaire les contraintes inh√©rentes au mod√®les (Feature Engineering)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° We are going to look more closely at the features and try to enhance our preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced `soil_condition` Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Check the possible values of the feature `soil_condition`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.001593Z",
     "start_time": "2021-09-09T15:39:37.585Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "soil_condition_values = data['soil_condition'].unique()\n",
    "soil_condition_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ùì Can you a better way to encode the `soil_condition` feature?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> yes, if we use ordinal encoding we can convert strings into numeric format which would help to rank labels (e.g. : 3 = 'rich', 2 = 'neutral', 1 = 'poor'). This helps to take into account the maximum information from the dataset during encoding when we have a lot of ordinal features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_condition_mapping = {'rich': 3, 'normal': 2, 'poor': 1}\n",
    "data['soil_condition_encoded'] = data['soil_condition'].map(soil_condition_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Select a transformer keeping a sense of the order of the values of `soil_condition` to encode that feature.**\n",
    "\n",
    "Encode `soil_condition` from `X` with that relevant encoder and store the result in `X_soil_condition_encoded` as a `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:04:46.326504Z",
     "start_time": "2021-09-08T08:04:46.300531Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['poor', 'normal', 'rich']])\n",
    "soil_condition = X['soil_condition'].values.reshape(-1, 1)\n",
    "X_soil_condition_encoded = ordinal_encoder.fit_transform(soil_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Make sure that it works properly.**\n",
    "\n",
    "Check the value counts for the feature `soil_condition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.004518Z",
     "start_time": "2021-09-09T15:39:37.597Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "value_counts_before = X['soil_condition'].value_counts()\n",
    "print(\"Value counts before transformation:\\n\", value_counts_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Check it again,  after transformation with the relevant encoder:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:04:46.386517Z",
     "start_time": "2021-09-08T08:04:46.363133Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "encoded_series = pd.Series(X_soil_condition_encoded.flatten())\n",
    "\n",
    "value_counts_after = encoded_series.value_counts().sort_index()\n",
    "print(\"Value counts after transformation:\\n\", value_counts_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Time Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí°  We want to extract two information from our time features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T15:39:59.268983Z",
     "start_time": "2021-08-26T15:39:59.246286Z"
    }
   },
   "source": [
    "üìÖ The `month` of the experiment's start\n",
    "\n",
    "‚è≥ The `duration` of the experiment in an appropriate unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Compute the `duration` of experiments, and look at the statistics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.008118Z",
     "start_time": "2021-09-09T15:39:37.616Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X['experiment_duration'] = (pd.to_datetime(X['datetime_end']) - pd.to_datetime(X['datetime_start']))\n",
    "duration = X['experiment_duration'].dt.total_seconds().describe()\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ùì What is the most accurate time unit to use to describe the `duration` feature?**\n",
    "\n",
    "**üìù Choose between `['days', 'hours', 'minutes', 'seconds']` and store your choice in the `duration_time_unit` variable:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "duration_time_unit = 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Create a `TimeFeaturesExtractor` class that transforms `datetime_start` and `datetime_end` into `month` and `duration`:**\n",
    "- `month` as a number from 1 to 12\n",
    "- `duration` as a float in the relevant `duration_time_unit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.010193Z",
     "start_time": "2021-09-09T15:39:37.627Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TimeFeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = pd.DataFrame()\n",
    "        X_transformed['month'] = pd.to_datetime(X['datetime_start']).dt.month\n",
    "        duration = (pd.to_datetime(X['datetime_end']) - pd.to_datetime(X['datetime_start'])).dt.total_seconds()\n",
    "        X_transformed['duration'] = duration\n",
    "        return X_transformed\n",
    "\n",
    "time_feature_extractor = TimeFeaturesExtractor()\n",
    "X_time_features = time_feature_extractor.transform(X.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Apply your `TimeFeaturesExtractor` to _100 rows_ of `X` and store the result in a DataFrame `X_time_features`**\n",
    "\n",
    "Double check that it has **2 columns**: `month` and `duration`, and **100 rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.011279Z",
     "start_time": "2021-09-09T15:39:37.632Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "print(X_time_features.shape)\n",
    "print(X_time_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cyclical Encoding & Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° We now have to encode and scale the extracted time features!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should scale the `duration` between 0 and 1.  \n",
    "\n",
    "However we need to build a **Cyclical Encoder** for the `month`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìùCreate a `CyclicalEncoder` class that transforms `month` into `month_cos` and `month_sin`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the equations:  \n",
    "\n",
    "$month\\_norm = 2\\pi\\frac{month}{12}$  \n",
    "$month\\_cos = \\cos({month\\_norm})$  \n",
    "$month\\_sin = \\sin({month\\_norm})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.012084Z",
     "start_time": "2021-09-09T15:39:37.640Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "class CyclicalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        X_encoded = pd.DataFrame()\n",
    "        month_norm = 2 * np.pi * X['month'] / 12\n",
    "        X_encoded['month_cos'] = np.cos(month_norm)\n",
    "        X_encoded['month_sin'] = np.sin(month_norm)\n",
    "        return X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Apply your `CyclicalEncoder` to `X_time_features` and store the result in a DataFrame `X_time_cyclical`.**\n",
    "\n",
    "Double check that it has **2 columns**: `month_cos` and `month_sin`, and **100 rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.012914Z",
     "start_time": "2021-09-09T15:39:37.646Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "cyclical_encoder = CyclicalEncoder()\n",
    "X_time_cyclical = cyclical_encoder.transform(X_time_features[['month']])\n",
    "print(X_time_cyclical.shape)\n",
    "print(X_time_cyclical.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Build a pipeline, that contains all the steps for time features.**\n",
    "\n",
    "Store it in a variable `preprocessing_time`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps**\n",
    "\n",
    "- Extraction of `month` and `duration` from  `datetime_start` and `datetime_end`  \n",
    "- Scaling of `duration` between 0 and 1\n",
    "- Cyclical encoding of `month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.013690Z",
     "start_time": "2021-09-09T15:39:37.652Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "preprocessing_time = Pipeline([\n",
    "    ('time_features_extractor', TimeFeaturesExtractor()),\n",
    "    ('feature_transform', ColumnTransformer([\n",
    "        ('duration_scaler', MinMaxScaler(), ['duration']),\n",
    "        ('cyclical_encoder', CyclicalEncoder(), ['month'])\n",
    "    ], remainder='drop'))\n",
    "])\n",
    "preprocessing_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save your results\n",
    "\n",
    "Run the cell below to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "results = ChallengeResult(\n",
    "    'feature_engineering',\n",
    "    x_soil_condition=X_soil_condition_encoded,\n",
    "    X_time_features=X_time_features,\n",
    "    X_time_cyclical= X_time_cyclical,\n",
    "    X_time=preprocessing_time.fit_transform(X)\n",
    ")\n",
    "results.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù  Build a full preprocessing pipeline and store it in `preprocessing_advanced`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are its steps, they should go in a parallel ColumnTransformer\n",
    "\n",
    "- Scale all numerical features between 0 and 1\n",
    "- Encode `main_element`  \n",
    "- Better encode `soil_condition`\n",
    "- Apply the `preprocessing_time` pipeline on `datetime_start` and `datetime_end`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.015494Z",
     "start_time": "2021-09-09T15:39:37.663Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "preprocessing_advanced = ColumnTransformer(\n",
    "    [\n",
    "        ('num', MinMaxScaler(), feat_num),\n",
    "        ('element', OneHotEncoder(handle_unknown='ignore'), ['main_element']),\n",
    "        ('soil', OrdinalEncoder(categories=[['poor', 'normal', 'rich']]), ['soil_condition']),\n",
    "        ('time', Pipeline([\n",
    "            ('time_features_extractor', TimeFeaturesExtractor()),            \n",
    "            ('cyclical_encoder', CyclicalEncoder()),\n",
    "            ('duration_scaler', MinMaxScaler(feature_range=(0, 1)))\n",
    "        ]), ['datetime_start', 'datetime_end'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C8 - Ma√Ætriser les diff√©rents algorithmes d'apprentissage afin d'apporter une r√©ponse adapt√©e √† une probl√©matique d'une organisation (entreprise, laboratoire, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Build a pipeline that uses `preprocessing_advanced` and then a _Regularized Linear_ model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validate your pipeline and store the scores in a list `scores_regularized`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['past_agriculture']= X['past_agriculture'].replace({'yes': 1,  'no':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['experiment_duration'] = X['experiment_duration'].apply(lambda x: x.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.018869Z",
     "start_time": "2021-09-09T15:39:37.683Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipeline_regularized = Pipeline([\n",
    "    ('preprocessing_advanced', preprocessing_advanced),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "scores_regularized = cross_val_score(pipeline_regularized, X, y, cv=5, scoring='neg_mean_squared_error', error_score='raise')\n",
    "scores_regularized = np.abs(scores_regularized)\n",
    "print(scores_regularized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save your results\n",
    "\n",
    "Run the cell below to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.020657Z",
     "start_time": "2021-09-09T15:39:37.693Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_,X_val,y_,y_val = train_test_split(X,y,test_size=0.3,random_state=7)\n",
    "pipe=pipeline_regularized.fit(X_,y_)\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'advanced_pipeline',\n",
    "    steps=str(pipeline_regularized.steps),\n",
    "    scores=scores_regularized,\n",
    "    y=y_val,\n",
    "    y_pred=pipeline_regularized.predict(X_val)\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C10 - Entra√Æner un mod√®le d'apprentissage non supervis√© pour d√©tecter des structures sous-jacentes √† partir de donn√©es non √©tiquet√©es*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Add a dimensional reduction step as the last step of your `preprocessing_advanced`. Make sure your dimensional reduction keeps _only 12 features_.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.023453Z",
     "start_time": "2021-09-09T15:39:37.712Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "preprocessing_advanced.steps.append(('dimensionality_reduction', PCA(n_components=12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Apply your `preprocessing_advanced` to `X` and store the result in the `X_preproc_adv` variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_preproc_adv = preprocessing_advanced.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save your results\n",
    "\n",
    "Run the cell below to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "results=ChallengeResult(\n",
    "    'unsupervised',\n",
    "    algorithm=preprocessing_advanced.steps[-1],\n",
    "    X_preproc_adv=X_preproc_adv\n",
    ")\n",
    "results.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Build a pipeline that uses `preprocessing_advanced` and then a _Ensemble_ model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store this pipeline in the variable `pipeline_ensemble`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validate your pipeline and store the scores in a list `scores_ensemble`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.024242Z",
     "start_time": "2021-09-09T15:39:37.720Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipeline_ensemble = Pipeline([\n",
    "    ('preprocessing', preprocessing_advanced),\n",
    "    ('ensemble_model', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "scores_ensemble = cross_val_score(pipeline_ensemble, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ùì Does this non-linear model satisfy the goal of the study?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Wait, did our feature engineering helps us ‚ùì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Build a pipeline that uses `preprocessing_basic` and the same Ensemble model as above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.026546Z",
     "start_time": "2021-09-09T15:39:37.737Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "pipeline_ensemble_basic = Pipeline([\n",
    "    ('preprocessing', preprocessing_basic),\n",
    "    ('ensemble_model', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "scores_ensemble_basic = cross_val_score(pipeline_ensemble_basic, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ùì What is your conclusion?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save your results\n",
    "\n",
    "Run the cell below to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_,X_val,y_,y_val=train_test_split(X,y,test_size=0.3,random_state=7)\n",
    "pipeline_ensemble.fit(X_,y_)\n",
    "y_pred=pipeline_ensemble.predict(X_val)\n",
    "\n",
    "results=ChallengeResult(\n",
    "    'ensemble',\n",
    "    steps=str(pipeline_ensemble.steps),\n",
    "    scores=scores_ensemble,\n",
    "    y=y_val,\n",
    "    y_pred=y_pred\n",
    ")\n",
    "results.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C11 - Am√©liorer les capacit√©s pr√©dictives d'un syst√®mes en s√©lectionnant un mod√®le diff√©rent ou en modifiant ses hyperparam√®tres en vue de corriger des erreurs (hyperparameter tuning)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° To improve the model as much as we can, it's time to grid search for optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Look at the hyperparameters of your estimator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.029350Z",
     "start_time": "2021-09-09T15:39:37.754Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Try to fine tune some hyperparameters to improve your model!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.030102Z",
     "start_time": "2021-09-09T15:39:37.760Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Store the _fitted_ grid search in the `search` variable:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Store the _cross-validated results_ of your grid search in the `cv_results` variable:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Store the _best model_ of your grid search in a variable `tuned_model`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.033730Z",
     "start_time": "2021-09-09T15:39:37.779Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save your results\n",
    "\n",
    "Run the cell below to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.035303Z",
     "start_time": "2021-09-09T15:39:37.788Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_,X_val,y_,y_val=train_test_split(X,y,test_size=0.3,random_state=10)\n",
    "tuned_model.fit(X_,y_)\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'model_tuning',\n",
    "    scores_ensemble=scores_ensemble,\n",
    "    scoring=search.scorer_,\n",
    "    params=search.best_params_,\n",
    "    cv_results=cv_results,\n",
    "    y=y_val,\n",
    "    y_pred=tuned_model.predict(X_val)\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Use your newly fine-tuned model to predict on a test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test provided at this url: \"https://wagon-public-datasets.s3.amazonaws.com/certification/soils_viability/soils_viability_test.csv\".\n",
    "\n",
    "Create `X_test` and `y_test`\n",
    "\n",
    "Use your fine-tuned model to predict on `X_test`\n",
    "\n",
    "Print a full classification report with your prediction and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/certification/soils_viability/soils_viability_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:39:43.036804Z",
     "start_time": "2021-09-09T15:39:37.800Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ùì Comment your results:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API \n",
    "\n",
    "Time to put a pipeline in production!\n",
    "\n",
    "üëâ Go back to the certification interface and follow the instructions about the API challenge.\n",
    "\n",
    "**This final part is independent from the above notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C12 - Mettre en production le mod√®le d'apprentissage supervis√© ou non supervis√© obtenu sous la forme d'une API*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246.297px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
