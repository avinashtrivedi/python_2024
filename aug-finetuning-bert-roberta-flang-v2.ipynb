{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T00:19:41.930077Z",
     "iopub.status.busy": "2024-02-21T00:19:41.929280Z",
     "iopub.status.idle": "2024-02-21T00:19:41.956271Z",
     "shell.execute_reply": "2024-02-21T00:19:41.955530Z",
     "shell.execute_reply.started": "2024-02-21T00:19:41.930039Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # Importing numpy for numerical operations and linear algebra\n",
    "import pandas as pd # Importing pandas for data processing and reading CSV files\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report,f1_score,accuracy_score\n",
    "# Suppressing UserWarning category warnings to avoid cluttering the notebook output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "# Additional imports for various functionalities\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "import torch # Importing PyTorch for building neural network models\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments # Importing components from the transformers library for BERT model\n",
    "from sklearn.model_selection import train_test_split # For splitting the dataset into training and validation sets\n",
    "\n",
    "# Importing ELMo related modules for embeddings\n",
    "#from allennlp.modules.elmo import Elmo, batch_to_ids \n",
    "from torch.utils.data import Dataset, DataLoader # For creating custom data handling classes and loading data\n",
    "from sklearn.metrics import accuracy_score, classification_report # For evaluating model performance\n",
    "from torch import nn, optim # For neural network components and optimizer\n",
    "from sklearn.metrics import precision_recall_fscore_support # For detailed model evaluation metrics\n",
    "\n",
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()\n",
    "\n",
    "\n",
    "\n",
    "# from huggingface_hub import login\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T00:19:41.958594Z",
     "iopub.status.busy": "2024-02-21T00:19:41.958232Z",
     "iopub.status.idle": "2024-02-21T00:19:41.970031Z",
     "shell.execute_reply": "2024-02-21T00:19:41.969361Z",
     "shell.execute_reply.started": "2024-02-21T00:19:41.958563Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the dataset from a CSV file\n",
    "# '/kaggle/input/sentiment-analysis-for-financial-news/all-data.csv' is the file path\n",
    "# 'encoding='unicode_escape' is used to handle any special characters in the data\n",
    "# 'names=['Sentiment', 'Text']' specifies the column names for the loaded DataFrame\n",
    "# data = pd.read_csv('/kaggle/input/sentiment-analysis-for-financial-news/all-data.csv', \n",
    "#                    encoding='unicode_escape',\n",
    "#                    names=['Sentiment', 'Text'])\n",
    "\n",
    "# # Displaying the first few rows of the DataFrame to check its structure and content\n",
    "# data.head()\n",
    "\n",
    "# /kaggle/input/augmented-financialphrasalbank/bert-base-uncased.csv\n",
    "# /kaggle/input/augmented-financialphrasalbank/Synonym-wordnet.csv + bert uncase is best\n",
    "# /kaggle/input/augmented-financialphrasalbank/roberta-base.csv\n",
    "# /kaggle/input/augmented-financialphrasalbank/flang-bert.csv\n",
    "\n",
    "# AugWordNet_BERT_FPB_finetuned_v1  Synonym-wordnet.csv + bert uncase is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased_bert-base-uncased\n",
      "bert-base-uncased_Synonym-wordnet\n",
      "bert-base-uncased_roberta-base\n",
      "bert-base-uncased_flang-bert\n",
      "finbert_bert-base-uncased\n",
      "finbert_Synonym-wordnet\n",
      "finbert_roberta-base\n",
      "finbert_flang-bert\n",
      "electra-base-discriminator_bert-base-uncased\n",
      "electra-base-discriminator_Synonym-wordnet\n",
      "electra-base-discriminator_roberta-base\n",
      "electra-base-discriminator_flang-bert\n",
      "FLANG-ELECTRA_bert-base-uncased\n",
      "FLANG-ELECTRA_Synonym-wordnet\n",
      "FLANG-ELECTRA_roberta-base\n",
      "FLANG-ELECTRA_flang-bert\n",
      "FLANG-BERT_bert-base-uncased\n",
      "FLANG-BERT_Synonym-wordnet\n",
      "FLANG-BERT_roberta-base\n",
      "FLANG-BERT_flang-bert\n"
     ]
    }
   ],
   "source": [
    "checkpoints = ['bert-base-uncased', 'ProsusAI/finbert', 'google/electra-base-discriminator', 'SALT-NLP/FLANG-ELECTRA', 'SALT-NLP/FLANG-BERT']\n",
    "augmentationed_files = ['bert-base-uncased.csv', 'Synonym-wordnet.csv', 'roberta-base.csv', 'flang-bert.csv']\n",
    "\n",
    "\n",
    "# Defining a preprocessing function for tokenizing and encoding sequences\n",
    "def preprocess_for_bert(data):\n",
    "    # Tokenizing and encoding the text data with padding and truncation to handle variable lengths\n",
    "    # 'max_length=512' sets the maximum length of the sequences\n",
    "    # 'return_tensors=\"pt\"' returns PyTorch tensors\n",
    "    return tokenizer(data['Text'].tolist(), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# Function to compute metrics for evaluation\n",
    "def compute_metrics(pred):\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    labels = pred.label_ids  # Actual labels\n",
    "    preds = pred.predictions.argmax(-1)  # Predictions from the model\n",
    "    # Calculating precision, recall, F1-score, and accuracy\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Defining a custom dataset class for handling the BERT-processed data\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    # Initialization with encodings and labels\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    # Method to get an item by index\n",
    "    def __getitem__(self, idx):\n",
    "        # Preparing each item by retrieving encoded data and corresponding label\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    # Method to get the total number of items in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "def get_prediction(model,tokenizer,text):\n",
    "    config = model.config\n",
    "    encoded_input = tokenizer([text], padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    # encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    # Print labels and scores\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "#     for i in range(scores.shape[0]):\n",
    "#         l = config.id2label[ranking[i]]\n",
    "#         s = scores[ranking[i]]\n",
    "#         print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "    return ranking[0]\n",
    "\n",
    "# Iterate over each checkpoint\n",
    "for checkpoint in checkpoints:\n",
    "    # Iterate over each augmentation file\n",
    "    for augmentation_file in augmentationed_files:\n",
    "        # Generate the filename based on the combination of checkpoint and augmentation file\n",
    "        filename = f\"{checkpoint.split('/')[-1]}_{augmentation_file.split('.')[0]}\"\n",
    "        data = pd.read_csv(f\"/kaggle/input/augmented-financialphrasalbank/{augmentation_file}\")\n",
    "        data.columns = ['index','Sentiment','Text']\n",
    "\n",
    "        # Assuming df is your DataFrame\n",
    "        # Replace 'df' with your actual DataFrame name\n",
    "\n",
    "        # Group by 'text' and aggregate labels into a list\n",
    "        grouped_df = data.groupby('Text')['Sentiment'].agg(list).reset_index()\n",
    "\n",
    "        # Filter rows where there are multiple labels\n",
    "        multiple_labels_df = grouped_df[grouped_df['Sentiment'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "        indx = data[data['Text'].isin(multiple_labels_df['Text'].values)].index\n",
    "        data = data[~data['index'].isin(indx)].reset_index(drop=True)\n",
    "\n",
    "        # Convert sentiment labels from textual to numerical format for easier processing\n",
    "        label_dict = {'negative': 0, 'neutral': 1, 'positive': 2}  # Mapping labels to numerical values\n",
    "        data['Sentiment'] = data['Sentiment'].replace(label_dict)  # Replacing text labels with corresponding numerical values\n",
    "\n",
    "        train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)  # 80% for training, 20% for validation\n",
    "        train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "        tokenizer = BertTokenizer.from_pretrained(checkpoint)  # Using the 'bert-base-uncased' pre-trained tokenizer \n",
    "\n",
    "        # Applying the preprocessing function to the training and validation data\n",
    "        train_encoded = preprocess_for_bert(train_data)\n",
    "        test_encoded = preprocess_for_bert(test_data)\n",
    "        val_encoded = preprocess_for_bert(val_data)\n",
    "\n",
    "        # Creating dataset objects for the training and validation datasets\n",
    "        train_dataset = SentimentDataset(train_encoded, train_data['Sentiment'].values)\n",
    "        val_dataset = SentimentDataset(val_encoded, val_data['Sentiment'].values)\n",
    "        test_dataset = SentimentDataset(test_encoded, test_data['Sentiment'].values)\n",
    "\n",
    "        # Loading a pre-trained BERT model specifically for sequence classification\n",
    "        # 'bert-base-uncased' is the model type, and 'num_labels=3' indicates three output labels (negative, neutral, positive)\n",
    "        model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
    "\n",
    "        # https://discuss.huggingface.co/t/early-stopping-training-using-validation-loss-as-the-metric-for-best-model/31378\n",
    "\n",
    "        # Defining various training parameters\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f'{filename}',               # Directory where the model predictions and checkpoints will be written\n",
    "            num_train_epochs=25,                   # Total number of training epochs\n",
    "            per_device_train_batch_size=64,       # Batch size per device during training\n",
    "            per_device_eval_batch_size=64,        # Batch size for evaluation\n",
    "            warmup_steps=1000,                     # Number of warmup steps for learning rate scheduler\n",
    "            weight_decay=0.01,                    # Weight decay if we apply some form of weight regularization\n",
    "            logging_dir='./logs',                 # Directory for storing logs\n",
    "            logging_steps=10,                     # How often to print logs\n",
    "            evaluation_strategy=\"epoch\",          # Evaluation is done at the end of each epoch\n",
    "            save_strategy=\"epoch\",\n",
    "        #     evaluation_strategy = IntervalStrategy.STEPS\n",
    "        #     eval_steps = 50, # Evaluation and Save happens every 50 steps\n",
    "            report_to=\"none\" ,                     # Disables the integration with any external reporting system\n",
    "            learning_rate= .0001,\n",
    "            save_total_limit=1,\n",
    "        #     optim=\"adamw_torch\",\n",
    "        #     gradient_accumulation_steps=4,\n",
    "            metric_for_best_model = 'f1',\n",
    "            load_best_model_at_end=True\n",
    "        )\n",
    "\n",
    "        # Initializing the Trainer with the model, training arguments, and datasets\n",
    "        trainer = Trainer(\n",
    "            model=model,                          # The pre-trained BERT model\n",
    "            args=training_args,                   # Training arguments defined above\n",
    "            train_dataset=train_dataset,          # Training dataset\n",
    "            eval_dataset=val_dataset,             # Validation dataset\n",
    "            callbacks = [EarlyStoppingCallback(early_stopping_patience=5)],\n",
    "            compute_metrics=compute_metrics       # Function for computing evaluation metrics\n",
    "        )\n",
    "\n",
    "        # Starting the training process\n",
    "        trainer.train()\n",
    "\n",
    "        # Evaluating the trained model on the validation dataset\n",
    "        evaluation_results = trainer.evaluate()\n",
    "\n",
    "        # Move the model to CPU if it's currently on GPU\n",
    "        model = model.to('cpu')\n",
    "\n",
    "        pred = []\n",
    "        for text in tqdm(test_data['Text']):\n",
    "            pred.append(get_prediction(model,tokenizer,text))\n",
    "\n",
    "        acc = accuracy_score(test_data['Sentiment'],pred)\n",
    "        f1 = f1_score(test_data['Sentiment'],pred,average='weighted')\n",
    "        trainer.push_to_hub(commit_message=f\"Acc{acc}, F1{f1} , Augmented with {augmentation_file}, finetuned on {checkpoint}\")\n",
    "        print(f\"*********** Augmented with {augmentation_file}, finetuned on {checkpoint} Completed.***************\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 622510,
     "sourceId": 1192499,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4391080,
     "sourceId": 7540712,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
