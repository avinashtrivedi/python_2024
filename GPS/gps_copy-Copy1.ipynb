{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923212e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install folium\n",
    "# pip install geopy\n",
    "# !pip install utm --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd18545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import utm\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "cols = ['uid','total_distance', 'average_speed', 'max_elevation', 'min_elevation', 'average_elevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3596447a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'doc1 (1).docx',\n",
       " 'gps_movement_map.html',\n",
       " 'trackdata_c1.csv',\n",
       " 'trackdata_c2.csv',\n",
       " 'trackdata_cx.csv',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0327d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('trackdata_c1.csv')\n",
    "df2 = pd.read_csv('trackdata_c2.csv')\n",
    "dfx = pd.read_csv('trackdata_cx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b848a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(train):\n",
    "    train['longitude_diff'] = train.groupby('uid').lon.diff().fillna(0)\n",
    "    train['latitude_diff'] = train.groupby('uid').lat.diff().fillna(0)\n",
    "    train['elevation_diff'] = train.groupby('uid').ele.diff().fillna(0)\n",
    "\n",
    "    train['UTMX'] = train.progress_apply(lambda x:utm.from_latlon(x['lat'], x['lon'])[0],axis=1)\n",
    "    train['UTMY'] = train.progress_apply(lambda x:utm.from_latlon(x['lat'], x['lon'])[1],axis=1)\n",
    "\n",
    "    # Function to calculate distance between two points\n",
    "    distance = lambda x_dif, y_dif: np.sqrt(x_dif**2 + y_dif**2)\n",
    "\n",
    "    # Differencing UTM coordinates\n",
    "    train['UTMX_diff'] = train.groupby('uid').UTMX.diff().fillna(0)\n",
    "    train['UTMY_diff'] = train.groupby('uid').UTMY.diff().fillna(0)\n",
    "\n",
    "\n",
    "    # Calculate step distance\n",
    "    train['distance'] = distance(train.UTMX_diff, train.UTMY_diff)\n",
    "\n",
    "    # Interquartile and range function\n",
    "    iqr = lambda x: np.percentile(x, 75) - np.percentile(x, 25)\n",
    "    range = lambda x: np.max(x) - np.min(x)\n",
    "    \n",
    "    # Drop the last 1 column: label\n",
    "    \n",
    "    if 'Target' and 'row_number' in train:\n",
    "        df_grouped = train.drop(['Target','row_number'],axis=1)\n",
    "    else:\n",
    "        df_grouped = train.drop(['row_number'],axis=1)\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    df_grouped = df_grouped.groupby('uid').aggregate([np.mean, np.min, np.max, np.std, iqr, range])\n",
    "\n",
    "    # Reduce multi-index\n",
    "    df_grouped.columns = ['_'.join(col).strip() for col in df_grouped.columns.values]\n",
    "\n",
    "    # Replace column name <lambda_0> to IQR and <lambda_1> to range \n",
    "    col_groupby2 = df_grouped.columns\n",
    "    col_groupby2 = [w.replace('<lambda_0>', 'IQR') for w in col_groupby2]\n",
    "    col_groupby2 = [w.replace('<lambda_1>', 'range') for w in col_groupby2]\n",
    "\n",
    "    # Update names of columns\n",
    "    df_grouped.columns = col_groupby2\n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbae31cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Target'] = 1 # fake\n",
    "df2['Target'] = 0 # real\n",
    "train_data = pd.concat([df1,df2])\n",
    "train_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72fa129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd9f91f83fc480f8ac5c12a92e975e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305525 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = get_features(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59eed73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd1f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_features(df_temp):\n",
    "\n",
    "#     uid = df_temp['uid'].unique()[0]\n",
    "#     # Calculate total distance traveled\n",
    "#     total_distance = 0.0\n",
    "#     for i in range(1, len(df_temp)):\n",
    "#         coord1 = (df_temp['lat'][i-1], df_temp['lon'][i-1])\n",
    "#         coord2 = (df_temp['lat'][i], df_temp['lon'][i])\n",
    "#         total_distance += geodesic(coord1, coord2).kilometers\n",
    "\n",
    "#     # Calculate average speed\n",
    "#     total_time_hours = (df_temp['row_number'].iloc[-1] - df_temp['row_number'].iloc[0]) / 3600.0\n",
    "#     average_speed = total_distance / total_time_hours\n",
    "\n",
    "#     # Maximum elevation\n",
    "#     max_elevation = df_temp['ele'].max()\n",
    "\n",
    "#     # Minimum elevation\n",
    "#     min_elevation = df_temp['ele'].min()\n",
    "\n",
    "#     # Average elevation\n",
    "#     average_elevation = df_temp['ele'].mean()\n",
    "\n",
    "#     return uid,total_distance, average_speed, max_elevation, min_elevation, average_elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3dc58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# for uid in tqdm(set(df1['uid'])):\n",
    "#     temp = df1[df1['uid']==uid]\n",
    "#     temp.reset_index(drop=True,inplace=True)\n",
    "#     features.append(get_features(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1_cleaned = pd.DataFrame(features,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# for uid in tqdm(set(df2['uid'])):\n",
    "#     temp = df2[df2['uid']==uid]\n",
    "#     temp.reset_index(drop=True,inplace=True)\n",
    "#     features.append(get_features(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_cleaned = pd.DataFrame(features,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8fd41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# for uid in tqdm(set(dfx['uid'])):\n",
    "#     temp = dfx[dfx['uid']==uid]\n",
    "#     temp.reset_index(drop=True,inplace=True)\n",
    "#     features.append(get_features(temp))\n",
    "# dfx_cleaned = pd.DataFrame(features,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1_cleaned['Target'] = 1 # fake/issue\n",
    "# df2_cleaned['Target'] = 0 # no issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.concat([df1_cleaned,df2_cleaned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d3b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81633259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e49a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['uid','Target'],axis=1)\n",
    "y = df_train['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543caf24",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a332b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,accuracy_score\n",
    "\n",
    "MLA = [\n",
    "    ensemble.RandomForestClassifier(n_jobs=-1, random_state = 0),\n",
    "    XGBClassifier(n_jobs=-1),\n",
    "]\n",
    "\n",
    "MLA_columns = ['MLA_names', 'MLA_parameters', 'MLA_Train_Accuracy_Mean','MLA_Test_Accuracy_Mean']\n",
    "\n",
    "def apply_models(X,y):\n",
    "    MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "#     MLA_Predict = y_test.copy()\n",
    "    row_index = 0\n",
    "    for alg in tqdm(MLA):\n",
    "        try:\n",
    "            MLA_name = alg.__class__.__name__\n",
    "            MLA_compare.loc[row_index, 'MLA_names'] = MLA_name\n",
    "            MLA_compare.loc[row_index, 'MLA_parameters'] = str(alg.get_params())\n",
    "            cv_results = model_selection.cross_validate(alg, X, y, cv=5, return_train_score = True)\n",
    "            MLA_compare.loc[row_index, 'MLA_Train_Accuracy_Mean'] = cv_results[\"train_score\"].mean()\n",
    "            MLA_compare.loc[row_index, 'MLA_Test_Accuracy_Mean'] = cv_results['test_score'].mean()\n",
    "            row_index += 1\n",
    "            print(\".\", end=\"\")\n",
    "        except:\n",
    "            print(type(alg).__name__)\n",
    "    MLA_compare.sort_values(by = 'MLA_Test_Accuracy_Mean', ascending = False, inplace = True)\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_models(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1043970",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc76ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dfx_cleaned.drop(['uid'],axis=1)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b21796",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = XGBClassifier(n_jobs=-1)\n",
    "alg.fit(X, y)\n",
    "y_pred = alg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fb3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CX_pred = pd.DataFrame({'uid':dfx_cleaned['uid'].tolist(),'Pred':y_pred})\n",
    "CX_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfff40",
   "metadata": {},
   "source": [
    "# Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "# pip install folium\n",
    "def draw(data):\n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    map_center = [data[\"lat\"][0], data[\"lon\"][0]]\n",
    "    mymap = folium.Map(location=map_center, zoom_start=10)\n",
    "    \n",
    "    # Add start marker\n",
    "    folium.Marker(location=[data[\"lat\"].values[0], data[\"lon\"].values[0]], icon=folium.Icon(color=\"green\"), popup=\"Start\").add_to(mymap)\n",
    "\n",
    "    # Add end marker\n",
    "    folium.Marker(location=[data[\"lat\"].values[-1], data[\"lon\"].values[-1]], icon=folium.Icon(color=\"red\"), popup=\"End\").add_to(mymap)\n",
    "\n",
    "    \n",
    "    for lat,long in zip(data['lat'],data['lon']):\n",
    "        folium.CircleMarker([lat,long],radius=5, color='red',fill=True).add_to(mymap)\n",
    "    display(mymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e80c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df1[df1['uid']==7]\n",
    "temp\n",
    "\n",
    "draw(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df1[df1['uid']==5]\n",
    "temp\n",
    "\n",
    "draw(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ee443",
   "metadata": {},
   "source": [
    "# Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431478db",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df2[df2['uid']==1]\n",
    "temp\n",
    "\n",
    "draw(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df2[df2['uid']==2]\n",
    "temp\n",
    "\n",
    "draw(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f02de1",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CX_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dfx[dfx['uid']==118] # incorrect prediciton\n",
    "temp\n",
    "\n",
    "draw(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3faae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dfx[dfx['uid']==418] # correct prediction\n",
    "temp\n",
    "\n",
    "draw(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fcd807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "using folium we can plot the interacgtive view so as to check if its having issue or not\n",
    "\n",
    "# Q3\n",
    "- add distance between actual start and end of gps location\n",
    "- Also, the beginning and end of the gps location as per scale on map\n",
    "\n",
    "# Q4\n",
    "\n",
    "- yes this data can be used for traffic analysis. first we need to find out the read gps traces and then overlap of their traces\n",
    "\n",
    "# Q5\n",
    "\n",
    "No, we need to perform feature engineering to create few features having enough potential to classified as issues/Not\n",
    "\n",
    "# Q6\n",
    "\n",
    "in the above machine learning models, we have performed prediciton of CX dataset\n",
    "\n",
    "# Q7\n",
    "\n",
    "- add distance between actual start and end of gps location\n",
    "- Also, the beginning and end of the gps location as per scale on map\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1561f8",
   "metadata": {},
   "source": [
    "# Future scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771899e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1192c73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d5fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(train):\n",
    "    train['longitude_diff'] = train.groupby('uid').lon.diff().fillna(0)\n",
    "    train['latitude_diff'] = train.groupby('uid').lat.diff().fillna(0)\n",
    "    train['elevation_diff'] = train.groupby('uid').ele.diff().fillna(0)\n",
    "\n",
    "    train['UTMX'] = train.progress_apply(lambda x:utm.from_latlon(x['lat'], x['lon'])[0],axis=1)\n",
    "    train['UTMY'] = train.progress_apply(lambda x:utm.from_latlon(x['lat'], x['lon'])[1],axis=1)\n",
    "\n",
    "    # Function to calculate distance between two points\n",
    "    distance = lambda x_dif, y_dif: np.sqrt(x_dif**2 + y_dif**2)\n",
    "\n",
    "    # Differencing UTM coordinates\n",
    "    train['UTMX_diff'] = train.groupby('uid').UTMX.diff().fillna(0)\n",
    "    train['UTMY_diff'] = train.groupby('uid').UTMY.diff().fillna(0)\n",
    "\n",
    "\n",
    "    # Calculate step distance\n",
    "    train['distance'] = distance(train.UTMX_diff, train.UTMY_diff)\n",
    "\n",
    "    # Interquartile and range function\n",
    "    iqr = lambda x: np.percentile(x, 75) - np.percentile(x, 25)\n",
    "    range = lambda x: np.max(x) - np.min(x)\n",
    "    \n",
    "    # Drop the last 1 column: label\n",
    "    \n",
    "    if 'Target' and 'row_number' in train:\n",
    "        df_grouped = train.drop(['Target','row_number'],axis=1)\n",
    "    else:\n",
    "        df_grouped = train.drop(['row_number'],axis=1)\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    df_grouped = df_grouped.groupby('uid').aggregate([np.mean, np.min, np.max, np.std, iqr, range])\n",
    "\n",
    "    # Reduce multi-index\n",
    "    df_grouped.columns = ['_'.join(col).strip() for col in df_grouped.columns.values]\n",
    "\n",
    "    # Replace column name <lambda_0> to IQR and <lambda_1> to range \n",
    "    col_groupby2 = df_grouped.columns\n",
    "    col_groupby2 = [w.replace('<lambda_0>', 'IQR') for w in col_groupby2]\n",
    "    col_groupby2 = [w.replace('<lambda_1>', 'range') for w in col_groupby2]\n",
    "\n",
    "    # Update names of columns\n",
    "    df_grouped.columns = col_groupby2\n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
