{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d3907c1",
   "metadata": {
    "id": "1d3907c1"
   },
   "source": [
    "##### all system call commands are modified to fit my system, please make necessary changes to correctly retrieve data from your local device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa06d3f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa06d3f6",
    "outputId": "baf497a3-f8f2-4e3b-ac4c-0936b21abdc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras sklearn matplotlib pandas pillow opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476a8e5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "476a8e5b",
    "outputId": "2baa663e-3727-4f29-a622-e0b02b1b5338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#importing required modules to create this project.\n",
    "import numpy as np  #basic exploration and assist.\n",
    "import pandas as pd #basic exploration and assist.\n",
    "import matplotlib.pyplot as plt #to plot graphs.\n",
    "import cv2 #to classify image and assist recognition.\n",
    "import tensorflow as tf\n",
    "from PIL import Image #to create image arrays etc.\n",
    "import os #to allow operating system calls.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from sklearn.model_selection import train_test_split #scikit learn to split, test and train the data.\n",
    "from tensorflow.keras.utils import to_categorical #to encode data to categories.\n",
    "from keras.models import Sequential, load_model #to create our model which is sequential.\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout #to add layers to our model for accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "SsMOEzU-tj37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsMOEzU-tj37",
    "outputId": "055b183f-2b20-4d43-93b7-63bc5f2851c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb https://packages.cloud.google.com/apt gcsfuse-jammy main\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2659  100  2659    0     0  17387      0 --:--:-- --:--:-- --:--:-- 17493\n",
      "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
      "OK\n",
      "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mhttps://packages.cloud.google.com/apt/dists/gcsfuse-jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
      "The following NEW packages will be installed:\n",
      "  gcsfuse\n",
      "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
      "Need to get 10.4 MB of archives.\n",
      "After this operation, 0 B of additional disk space will be used.\n",
      "Selecting previously unselected package gcsfuse.\n",
      "(Reading database ... 121752 files and directories currently installed.)\n",
      "Preparing to unpack .../gcsfuse_2.0.1_amd64.deb ...\n",
      "Unpacking gcsfuse (2.0.1) ...\n",
      "Setting up gcsfuse (2.0.1) ...\n"
     ]
    }
   ],
   "source": [
    "# Authenticate.\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Install Cloud Storage FUSE.\n",
    "!echo \"deb https://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "!apt -qq update && apt -qq install gcsfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5MmDEUTttmFw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MmDEUTttmFw",
    "outputId": "b6255af7-b3e8-44ab-ab04-dd27aeca0b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb https://packages.cloud.google.com/apt gcsfuse-jammy main\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
      "100  2659  100  2659    0     0  27746      0 --:--:-- --:--:-- --:--:-- 27989\n",
      "OK\n",
      "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mhttps://packages.cloud.google.com/apt/dists/gcsfuse-jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
      "gcsfuse is already the newest version (2.0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Authenticate.\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Install Cloud Storage FUSE.\n",
    "!echo \"deb https://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "!apt -qq update && apt -qq install gcsfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UW-4LKAatmFx",
   "metadata": {
    "id": "UW-4LKAatmFx"
   },
   "source": [
    "You can mount an entire bucket, or a path location within that bucket.\n",
    "The local path to mount it must exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2LgtiVRgtmFx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LgtiVRgtmFx",
    "outputId": "6774f038-0a28-4d07-d300-e08463b24f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":{\"seconds\":1713890548,\"nanos\":993401964},\"severity\":\"INFO\",\"message\":\"Start gcsfuse/2.0.1 (Go version go1.22.1) for app \\\"\\\" using mount point: /mnt/gs/my-bucket\\n\"}\n",
      "{\"timestamp\":{\"seconds\":1713890548,\"nanos\":993641695},\"severity\":\"INFO\",\"message\":\"GCSFuse mount command flags: {\\\"AppName\\\":\\\"\\\",\\\"Foreground\\\":false,\\\"ConfigFile\\\":\\\"\\\",\\\"MountOptions\\\":{},\\\"DirMode\\\":493,\\\"FileMode\\\":420,\\\"Uid\\\":-1,\\\"Gid\\\":-1,\\\"ImplicitDirs\\\":true,\\\"OnlyDir\\\":\\\"\\\",\\\"RenameDirLimit\\\":0,\\\"CustomEndpoint\\\":null,\\\"BillingProject\\\":\\\"\\\",\\\"KeyFile\\\":\\\"\\\",\\\"TokenUrl\\\":\\\"\\\",\\\"ReuseTokenFromUrl\\\":true,\\\"EgressBandwidthLimitBytesPerSecond\\\":-1,\\\"OpRateLimitHz\\\":-1,\\\"SequentialReadSizeMb\\\":200,\\\"MaxRetrySleep\\\":30000000000,\\\"StatCacheCapacity\\\":20460,\\\"StatCacheTTL\\\":60000000000,\\\"TypeCacheTTL\\\":60000000000,\\\"HttpClientTimeout\\\":0,\\\"MaxRetryDuration\\\":-1000000000,\\\"RetryMultiplier\\\":2,\\\"LocalFileCache\\\":false,\\\"TempDir\\\":\\\"\\\",\\\"ClientProtocol\\\":\\\"http1\\\",\\\"MaxConnsPerHost\\\":100,\\\"MaxIdleConnsPerHost\\\":100,\\\"EnableNonexistentTypeCache\\\":false,\\\"StackdriverExportInterval\\\":0,\\\"OtelCollectorAddress\\\":\\\"\\\",\\\"LogFile\\\":\\\"\\\",\\\"LogFormat\\\":\\\"json\\\",\\\"ExperimentalEnableJsonRead\\\":false,\\\"DebugFuseErrors\\\":true,\\\"DebugFuse\\\":false,\\\"DebugFS\\\":false,\\\"DebugGCS\\\":false,\\\"DebugHTTP\\\":false,\\\"DebugInvariants\\\":false,\\\"DebugMutex\\\":false}\"}\n",
      "{\"timestamp\":{\"seconds\":1713890548,\"nanos\":993755776},\"severity\":\"INFO\",\"message\":\"GCSFuse mount config flags: {\\\"CreateEmptyFile\\\":false,\\\"Severity\\\":\\\"INFO\\\",\\\"Format\\\":\\\"json\\\",\\\"FilePath\\\":\\\"\\\",\\\"LogRotateConfig\\\":{\\\"MaxFileSizeMB\\\":512,\\\"BackupFileCount\\\":10,\\\"Compress\\\":true},\\\"MaxSizeMB\\\":-1,\\\"CacheFileForRangeRead\\\":false,\\\"CacheDir\\\":\\\"\\\",\\\"TtlInSeconds\\\":-9223372036854775808,\\\"TypeCacheMaxSizeMB\\\":4,\\\"StatCacheMaxSizeMB\\\":-9223372036854775808,\\\"EnableEmptyManagedFolders\\\":false,\\\"ConnPoolSize\\\":1}\"}\n",
      "daemonize.Run: readFromProcess: sub-process: Error while mounting gcsfuse: mountWithArgs: mountWithStorageHandle: fs.NewServer: create file system: SetUpBucket: Error in iterating through objects: googleapi: Error 403: 220110690@psu.edu.sa does not have storage.objects.list access to the Google Cloud Storage bucket. Permission 'storage.objects.list' denied on resource (or it may not exist)., forbidden\n"
     ]
    }
   ],
   "source": [
    "# Mount a Cloud Storage bucket or location, without the gs:// prefix.\n",
    "mount_path = \"my-bucket\"  # or a location like \"my-bucket/path/to/mount\"\n",
    "local_path = f\"/mnt/gs/{mount_path}\"\n",
    "\n",
    "!mkdir -p {local_path}\n",
    "!gcsfuse --implicit-dirs {mount_path} {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0pEYFOFdtmFy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pEYFOFdtmFy",
    "outputId": "0d5147dc-9124-4dc4-e04a-2c22d0368474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n"
     ]
    }
   ],
   "source": [
    "# Then you can access it like a local path.\n",
    "!ls -lh {local_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ftpcyOVatj39",
   "metadata": {
    "id": "ftpcyOVatj39"
   },
   "source": [
    "You can mount an entire bucket, or a path location within that bucket.\n",
    "The local path to mount it must exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "g2YNzVsktj3-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2YNzVsktj3-",
    "outputId": "69945b80-6eec-4724-c42c-09210d836841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":{\"seconds\":1713890549,\"nanos\":626035573},\"severity\":\"INFO\",\"message\":\"Start gcsfuse/2.0.1 (Go version go1.22.1) for app \\\"\\\" using mount point: /mnt/gs/my-bucket\\n\"}\n",
      "{\"timestamp\":{\"seconds\":1713890549,\"nanos\":626300784},\"severity\":\"INFO\",\"message\":\"GCSFuse mount command flags: {\\\"AppName\\\":\\\"\\\",\\\"Foreground\\\":false,\\\"ConfigFile\\\":\\\"\\\",\\\"MountOptions\\\":{},\\\"DirMode\\\":493,\\\"FileMode\\\":420,\\\"Uid\\\":-1,\\\"Gid\\\":-1,\\\"ImplicitDirs\\\":true,\\\"OnlyDir\\\":\\\"\\\",\\\"RenameDirLimit\\\":0,\\\"CustomEndpoint\\\":null,\\\"BillingProject\\\":\\\"\\\",\\\"KeyFile\\\":\\\"\\\",\\\"TokenUrl\\\":\\\"\\\",\\\"ReuseTokenFromUrl\\\":true,\\\"EgressBandwidthLimitBytesPerSecond\\\":-1,\\\"OpRateLimitHz\\\":-1,\\\"SequentialReadSizeMb\\\":200,\\\"MaxRetrySleep\\\":30000000000,\\\"StatCacheCapacity\\\":20460,\\\"StatCacheTTL\\\":60000000000,\\\"TypeCacheTTL\\\":60000000000,\\\"HttpClientTimeout\\\":0,\\\"MaxRetryDuration\\\":-1000000000,\\\"RetryMultiplier\\\":2,\\\"LocalFileCache\\\":false,\\\"TempDir\\\":\\\"\\\",\\\"ClientProtocol\\\":\\\"http1\\\",\\\"MaxConnsPerHost\\\":100,\\\"MaxIdleConnsPerHost\\\":100,\\\"EnableNonexistentTypeCache\\\":false,\\\"StackdriverExportInterval\\\":0,\\\"OtelCollectorAddress\\\":\\\"\\\",\\\"LogFile\\\":\\\"\\\",\\\"LogFormat\\\":\\\"json\\\",\\\"ExperimentalEnableJsonRead\\\":false,\\\"DebugFuseErrors\\\":true,\\\"DebugFuse\\\":false,\\\"DebugFS\\\":false,\\\"DebugGCS\\\":false,\\\"DebugHTTP\\\":false,\\\"DebugInvariants\\\":false,\\\"DebugMutex\\\":false}\"}\n",
      "{\"timestamp\":{\"seconds\":1713890549,\"nanos\":626402631},\"severity\":\"INFO\",\"message\":\"GCSFuse mount config flags: {\\\"CreateEmptyFile\\\":false,\\\"Severity\\\":\\\"INFO\\\",\\\"Format\\\":\\\"json\\\",\\\"FilePath\\\":\\\"\\\",\\\"LogRotateConfig\\\":{\\\"MaxFileSizeMB\\\":512,\\\"BackupFileCount\\\":10,\\\"Compress\\\":true},\\\"MaxSizeMB\\\":-1,\\\"CacheFileForRangeRead\\\":false,\\\"CacheDir\\\":\\\"\\\",\\\"TtlInSeconds\\\":-9223372036854775808,\\\"TypeCacheMaxSizeMB\\\":4,\\\"StatCacheMaxSizeMB\\\":-9223372036854775808,\\\"EnableEmptyManagedFolders\\\":false,\\\"ConnPoolSize\\\":1}\"}\n",
      "daemonize.Run: readFromProcess: sub-process: Error while mounting gcsfuse: mountWithArgs: mountWithStorageHandle: fs.NewServer: create file system: SetUpBucket: Error in iterating through objects: googleapi: Error 403: 220110690@psu.edu.sa does not have storage.objects.list access to the Google Cloud Storage bucket. Permission 'storage.objects.list' denied on resource (or it may not exist)., forbidden\n"
     ]
    }
   ],
   "source": [
    "# Mount a Cloud Storage bucket or location, without the gs:// prefix.\n",
    "mount_path = \"my-bucket\"  # or a location like \"my-bucket/path/to/mount\"\n",
    "local_path = f\"/mnt/gs/{mount_path}\"\n",
    "\n",
    "!mkdir -p {local_path}\n",
    "!gcsfuse --implicit-dirs {mount_path} {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "xmG8FNeRtj3-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmG8FNeRtj3-",
    "outputId": "bcd36d79-73cd-41cd-842e-b09a0a6e75f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n"
     ]
    }
   ],
   "source": [
    "# Then you can access it like a local path.\n",
    "!ls -lh {local_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6182e5",
   "metadata": {
    "id": "7c6182e5"
   },
   "source": [
    "##### dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vbTwtpKvE20t",
   "metadata": {
    "id": "vbTwtpKvE20t"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "data_dir = './data'\n",
    "import os\n",
    "if not os.path.exists(data_dir):\n",
    "    !unzip \"/content/drive/MyDrive/dataset.zip\" -d \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64f65e22",
   "metadata": {
    "id": "64f65e22"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 24\n",
    "cur_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a8e061f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "3a8e061f",
    "outputId": "e938499f-fe73-49e0-9bfb-85acf889ac1e"
   },
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/content/dataset/Train/14 '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3128efe34402>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/dataset/Train/14 '"
     ]
    }
   ],
   "source": [
    "#retrieving the images and their labels and appending said items in previously initialised lists.\n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path, '/content/dataset/Train',str(i), ' ')\n",
    "    try:\n",
    "        images = os.listdir(path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to list directory {path}: {e}\")\n",
    "        continue\n",
    "    for a in images:\n",
    "      image_path = os.path.join(path, a)\n",
    "      image = Image.open(image_path)\n",
    "      image = image.resize((30,30))\n",
    "      image = np.array(image)\n",
    "      data.append(image)\n",
    "      labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65f264",
   "metadata": {
    "id": "5d65f264"
   },
   "outputs": [],
   "source": [
    "#converting lists into numpy arrays to feed model.\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(data.shape, labels.shape) #The shape of data obtained is (39209, 30, 30, 3) which means that there are 39,209 images of size 30×30 pixels and the last 3 means the data contains colored images (RGB value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f93c1",
   "metadata": {
    "id": "a03f93c1"
   },
   "outputs": [],
   "source": [
    "#splitting training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65bbf9",
   "metadata": {
    "id": "3c65bbf9"
   },
   "outputs": [],
   "source": [
    "#converting the labels into one-hot encoding of categories.\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_test = to_categorical(y_test, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c06e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de79183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical #to encode data to categories.\n",
    "from keras.models import Sequential, load_model #to create our model which is sequential.\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout #to add layers to our model for accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135baa31",
   "metadata": {
    "id": "135baa31"
   },
   "source": [
    "##### building CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa2ab148",
   "metadata": {
    "id": "fa2ab148"
   },
   "outputs": [],
   "source": [
    "#building the CNN model as CNN is best for image classification purposes.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu')) #2D convolution layer class that creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2))) #max pooling operation for 2D spatial data.\n",
    "model.add(Dropout(rate=0.25)) #applies dropout layer that randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten()) #flattens the input without affecting the batch size.\n",
    "model.add(Dense(256, activation='relu')) #regular densely-connected NN layer.\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7664a65f",
   "metadata": {
    "id": "7664a65f"
   },
   "source": [
    "##### training and validation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91832ffd",
   "metadata": {
    "id": "91832ffd"
   },
   "outputs": [],
   "source": [
    "#compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])#we compile the model with Adam optimizer which performs well and loss is “categorical_crossentropy” because we have multiple classes to categorise.\n",
    "epochs = 15 #we tried with batch size 32 and 64. our model performed better with 64 batch size and after 15 epochs the accuracy was stable.\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_test, y_test))\n",
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281ef1d",
   "metadata": {
    "id": "b281ef1d"
   },
   "outputs": [],
   "source": [
    "#with matplotlib, we plot the graph for accuracy and the loss.\n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08715aa2",
   "metadata": {
    "id": "08715aa2"
   },
   "source": [
    "##### teting model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227bce90",
   "metadata": {
    "id": "227bce90"
   },
   "outputs": [],
   "source": [
    "#testing accuracy on test dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = pd.read_csv('/Users/smriti/Downloads/Traffic sign classification/Test.csv')\n",
    "labels = y_test[\"ClassId\"].values\n",
    "imgs = \"/Users/smriti/Downloads/Traffic sign classification/\" + y_test[\"Path\"].values\n",
    "data=[]\n",
    "for img in imgs:\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((30,30))\n",
    "    data.append(np.array(image))\n",
    "X_test=np.array(data)\n",
    "predict_x=model.predict(X_test)\n",
    "classes_x=np.argmax(predict_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d885247",
   "metadata": {
    "id": "4d885247"
   },
   "outputs": [],
   "source": [
    "#accuracy with the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels, classes_x)) #our model got a 95% accuracy.\n",
    "model.save('traffic_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb1539",
   "metadata": {
    "id": "a9bb1539"
   },
   "outputs": [],
   "source": [
    "#imported required files for GUI. we are using tkinter as our core for the GUI.\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba2ba7",
   "metadata": {
    "id": "3aba2ba7"
   },
   "outputs": [],
   "source": [
    "#loading the trained model to classify sign via keras.\n",
    "from keras.models import load_model\n",
    "model = load_model('traffic_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac247b3",
   "metadata": {
    "id": "1ac247b3"
   },
   "outputs": [],
   "source": [
    "#creating dictionary to label all traffic sign classes.\n",
    "classes = { 1:'Speed limit (20km/h)',\n",
    "            2:'Speed limit (30km/h)',\n",
    "            3:'Speed limit (50km/h)',\n",
    "            4:'Speed limit (60km/h)',\n",
    "            5:'Speed limit (70km/h)',\n",
    "            6:'Speed limit (80km/h)',\n",
    "            7:'End of speed limit (80km/h)',\n",
    "            8:'Speed limit (100km/h)',\n",
    "            9:'Speed limit (120km/h)',\n",
    "            10:'No passing',\n",
    "            11:'No passing veh over 3.5 tons',\n",
    "            12:'Right-of-way at intersection',\n",
    "            13:'Priority road',\n",
    "            14:'Yield',\n",
    "            15:'Stop',\n",
    "            16:'No vehicles',\n",
    "            17:'Veh > 3.5 tons prohibited',\n",
    "            18:'No entry',\n",
    "            19:'General caution',\n",
    "            20:'Dangerous curve left',\n",
    "            21:'Dangerous curve right',\n",
    "            22:'Double curve',\n",
    "            23:'Bumpy road',\n",
    "            24:'Slippery road',\n",
    "            25:'Road narrows on the right',\n",
    "            26:'Road work',\n",
    "            27:'Traffic signals',\n",
    "            28:'Pedestrians',\n",
    "            29:'Children crossing',\n",
    "            30:'Bicycles crossing',\n",
    "            31:'Beware of ice/snow',\n",
    "            32:'Wild animals crossing',\n",
    "            33:'End speed + passing limits',\n",
    "            34:'Turn right ahead',\n",
    "            35:'Turn left ahead',\n",
    "            36:'Ahead only',\n",
    "            37:'Go straight or right',\n",
    "            38:'Go straight or left',\n",
    "            39:'Keep right',\n",
    "            40:'Keep left',\n",
    "            41:'Roundabout mandatory',\n",
    "            42:'End of no passing',\n",
    "            43:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56a325",
   "metadata": {
    "id": "9e56a325"
   },
   "source": [
    "##### Run this kernel to execute program model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ba32b",
   "metadata": {
    "id": "c95ba32b"
   },
   "outputs": [],
   "source": [
    "#initialising the GUI (creating windows, buttons and functions).\n",
    "#creating GUI main window first.\n",
    "top=tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('Traffic Sign Classification')\n",
    "top.configure(background='#CDCDCD')\n",
    "label=Label(top,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "sign_image = Label(top)\n",
    "#classify function to predict and classify the uploaded test image to give output.\n",
    "def classify(file_path):\n",
    "    global label_packed\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((30,30))\n",
    "    image = numpy.expand_dims(image, axis=0)\n",
    "    image = numpy.array(image)\n",
    "    predict_classes = model.predict([image])[0]\n",
    "    pred = np.argmax(predict_classes)\n",
    "    sign = classes[pred+1]\n",
    "    print(sign)\n",
    "    label.configure(foreground='black', text=sign)\n",
    "#creating classify button ui that gives output on click.\n",
    "def show_classify_button(file_path):\n",
    "    classify_b=Button(top,text=\"Classify Image\",command=lambda: classify(file_path),padx=10,pady=5)\n",
    "    classify_b.configure(background='black', foreground='black',font=('arial',14,'bold'))\n",
    "    classify_b.place(relx=0.79,rely=0.46)\n",
    "#uplaod function that lets test image from local device to be uploaded for classification.\n",
    "def upload_image():\n",
    "    try:\n",
    "        file_path=filedialog.askopenfilename()\n",
    "        uploaded=Image.open(file_path)\n",
    "        uploaded.thumbnail(((top.winfo_width()/0.1),(top.winfo_height()/0.1)))\n",
    "        im=ImageTk.PhotoImage(uploaded)\n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image=im\n",
    "        label.configure(text='')\n",
    "        show_classify_button(file_path)\n",
    "    except:\n",
    "        pass\n",
    "#upload button ui created that lets us upload test image for classification on click.\n",
    "upload=Button(top,text=\"Upload an image\",command=upload_image,padx=10,pady=5)\n",
    "upload.configure(background='black', foreground='black',font=('arial',14,'bold'))\n",
    "upload.pack(side=BOTTOM,pady=50)\n",
    "sign_image.pack(side=BOTTOM,expand=True)\n",
    "label.pack(side=BOTTOM,expand=True)\n",
    "#heading and loops\n",
    "heading = Label(top, text=\"Know Your Traffic Sign\",pady=20, font=('arial',20,'bold'))\n",
    "heading.configure(background='#CDCDCD',foreground='black')\n",
    "heading.pack()\n",
    "top.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7138a",
   "metadata": {
    "id": "c0f7138a"
   },
   "source": [
    "#### - Smriti Chaudhary, 1914123"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
