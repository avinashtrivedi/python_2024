{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install numpy==1.19.5\n",
    "#%pip install scipy==1.10.1\n",
    "#%pip install scikit-learn\n",
    "#%pip install pandas==1.4.4\n",
    "#%pip install contourpy==1.1.1\n",
    "#%pip install matplotlib==3.6\n",
    "#%pip install keras==2.5.0rc0 tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('as1-bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>882</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>-247</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>3444</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>2415</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1475</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1166</td>\n",
       "      <td>3</td>\n",
       "      <td>530</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>583</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>2850</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7841</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7842 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  marital  education default  balance housing loan  contact  \\\n",
       "0      33        1          2      no      882      no   no        1   \n",
       "1      42        0          1      no     -247     yes  yes        1   \n",
       "2      33        1          1      no     3444     yes   no        1   \n",
       "3      36        1          2      no     2415     yes   no        1   \n",
       "4      36        1          2      no        0     yes   no        1   \n",
       "...   ...      ...        ...     ...      ...     ...  ...      ...   \n",
       "7837   34        0          1      no     1475     yes   no        0   \n",
       "7838   53        1          2      no      583      no   no        0   \n",
       "7839   73        1          1      no     2850      no   no        0   \n",
       "7840   72        1          1      no     5715      no   no        0   \n",
       "7841   37        1          1      no     2971      no   no        0   \n",
       "\n",
       "      duration  campaign  pdays  previous  poutcome    y  \n",
       "0           39         1    151         3         0   no  \n",
       "1          519         1    166         1         2  yes  \n",
       "2          144         1     91         4         0  yes  \n",
       "3           73         1     86         4         2   no  \n",
       "4          140         1    143         3         0  yes  \n",
       "...        ...       ...    ...       ...       ...  ...  \n",
       "7837      1166         3    530        12         2   no  \n",
       "7838       226         1    184         4         1  yes  \n",
       "7839       300         1     40         8         0  yes  \n",
       "7840      1127         5    184         3         1  yes  \n",
       "7841       361         2    188        11         2   no  \n",
       "\n",
       "[7842 rows x 14 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\AppData\\Local\\Temp\\ipykernel_22448\\1015853388.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  training_y.replace(\"no\", 0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "training_y = training_data.pop('y')\n",
    "training_y.replace(\"yes\", 1, inplace=True)\n",
    "training_y.replace(\"no\", 0, inplace=True)\n",
    "training_x = training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6056\n",
       "1    1786\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = pd.get_dummies(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from category_encoders import BinaryEncoder\n",
    "\n",
    "#categorical_columns = [\"default\",\"housing\", \"loan\"]\n",
    "\n",
    "#encoder = BinaryEncoder(cols=categorical_columns)\n",
    "#training_x = encoder.fit_transform(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>balance</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_no</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_no</th>\n",
       "      <th>loan_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>882</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-247</td>\n",
       "      <td>1</td>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3444</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2415</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1475</td>\n",
       "      <td>0</td>\n",
       "      <td>1166</td>\n",
       "      <td>3</td>\n",
       "      <td>530</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2850</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5715</td>\n",
       "      <td>0</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7841</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2971</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7842 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  marital  education  balance  contact  duration  campaign  pdays  \\\n",
       "0      33        1          2      882        1        39         1    151   \n",
       "1      42        0          1     -247        1       519         1    166   \n",
       "2      33        1          1     3444        1       144         1     91   \n",
       "3      36        1          2     2415        1        73         1     86   \n",
       "4      36        1          2        0        1       140         1    143   \n",
       "...   ...      ...        ...      ...      ...       ...       ...    ...   \n",
       "7837   34        0          1     1475        0      1166         3    530   \n",
       "7838   53        1          2      583        0       226         1    184   \n",
       "7839   73        1          1     2850        0       300         1     40   \n",
       "7840   72        1          1     5715        0      1127         5    184   \n",
       "7841   37        1          1     2971        0       361         2    188   \n",
       "\n",
       "      previous  poutcome  default_no  default_yes  housing_no  housing_yes  \\\n",
       "0            3         0        True        False        True        False   \n",
       "1            1         2        True        False       False         True   \n",
       "2            4         0        True        False       False         True   \n",
       "3            4         2        True        False       False         True   \n",
       "4            3         0        True        False       False         True   \n",
       "...        ...       ...         ...          ...         ...          ...   \n",
       "7837        12         2        True        False       False         True   \n",
       "7838         4         1        True        False        True        False   \n",
       "7839         8         0        True        False        True        False   \n",
       "7840         3         1        True        False        True        False   \n",
       "7841        11         2        True        False        True        False   \n",
       "\n",
       "      loan_no  loan_yes  \n",
       "0        True     False  \n",
       "1       False      True  \n",
       "2        True     False  \n",
       "3        True     False  \n",
       "4        True     False  \n",
       "...       ...       ...  \n",
       "7837     True     False  \n",
       "7838     True     False  \n",
       "7839     True     False  \n",
       "7840     True     False  \n",
       "7841     True     False  \n",
       "\n",
       "[7842 rows x 16 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_x = training_x.to_numpy()\n",
    "arr_train_y = training_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7842, 16)\n",
      "(7842,)\n"
     ]
    }
   ],
   "source": [
    "print(arr_train_x.shape)\n",
    "print(arr_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_train_x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_x = arr_train_x.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  4.14199568e-01 -1.80316595e-01  1.17282612e-01\n",
      "   1.90544858e-01  5.89020045e-02  7.35720702e-04 -1.06095306e-01\n",
      "   3.39606397e-03 -1.97886497e-02  2.68322609e-02 -2.68322609e-02\n",
      "   1.86923847e-01 -1.86923847e-01  4.43265433e-03 -4.43265433e-03]\n",
      " [ 4.14199568e-01  1.00000000e+00 -1.36804068e-01  2.25149087e-02\n",
      "   2.17882693e-02  7.14165401e-03  7.43160656e-03  6.62740050e-03\n",
      "  -4.37036098e-03 -3.78876363e-02 -2.90028573e-03  2.90028573e-03\n",
      "  -5.08072929e-02  5.08072929e-02 -5.61433819e-02  5.61433819e-02]\n",
      " [-1.80316595e-01 -1.36804068e-01  1.00000000e+00  7.93080301e-02\n",
      "  -9.78062355e-02 -3.05495520e-03 -2.70956534e-02 -1.60156777e-01\n",
      "   9.88264566e-03  1.48603466e-02  1.06660297e-02 -1.06660297e-02\n",
      "   1.16913504e-01 -1.16913504e-01  3.07096433e-02 -3.07096433e-02]\n",
      " [ 1.17282612e-01  2.25149087e-02  7.93080301e-02  1.00000000e+00\n",
      "   4.62589922e-02  4.05501473e-02 -1.18735782e-02 -1.01847337e-01\n",
      "   1.70823043e-03  1.60099042e-02  4.52156993e-02 -4.52156993e-02\n",
      "   1.09378217e-01 -1.09378217e-01  8.35838175e-02 -8.35838175e-02]\n",
      " [ 1.90544858e-01  2.17882693e-02 -9.78062355e-02  4.62589922e-02\n",
      "   1.00000000e+00 -3.48097694e-03  1.09836285e-01 -1.27903366e-02\n",
      "   4.20977359e-02  4.03060303e-02  1.83149389e-02 -1.83149389e-02\n",
      "   7.80808724e-02 -7.80808724e-02  3.54205673e-02 -3.54205673e-02]\n",
      " [ 5.89020045e-02  7.14165401e-03 -3.05495520e-03  4.05501473e-02\n",
      "  -3.48097694e-03  1.00000000e+00 -9.43479852e-02 -9.57098796e-03\n",
      "  -1.77571854e-03  4.92171113e-02  6.05464654e-03 -6.05464654e-03\n",
      "   7.21148398e-02 -7.21148398e-02  3.49202301e-02 -3.49202301e-02]\n",
      " [ 7.35720702e-04  7.43160656e-03 -2.70956534e-02 -1.18735782e-02\n",
      "   1.09836285e-01 -9.43479852e-02  1.00000000e+00  6.35295859e-02\n",
      "   1.37043932e-01  1.07633749e-01  2.51347380e-03 -2.51347380e-03\n",
      "  -6.16312871e-02  6.16312871e-02 -8.47959295e-03  8.47959295e-03]\n",
      " [-1.06095306e-01  6.62740050e-03 -1.60156777e-01 -1.01847337e-01\n",
      "  -1.27903366e-02 -9.57098796e-03  6.35295859e-02  1.00000000e+00\n",
      "  -2.67082151e-02 -9.92843409e-02 -3.56432284e-02  3.56432284e-02\n",
      "  -3.49770831e-01  3.49770831e-01 -1.48613420e-02  1.48613420e-02]\n",
      " [ 3.39606397e-03 -4.37036098e-03  9.88264566e-03  1.70823043e-03\n",
      "   4.20977359e-02 -1.77571854e-03  1.37043932e-01 -2.67082151e-02\n",
      "   1.00000000e+00  9.17692324e-02 -1.26964124e-02  1.26964124e-02\n",
      "  -7.92158347e-03  7.92158347e-03 -1.41731864e-02  1.41731864e-02]\n",
      " [-1.97886497e-02 -3.78876363e-02  1.48603466e-02  1.60099042e-02\n",
      "   4.03060303e-02  4.92171113e-02  1.07633749e-01 -9.92843409e-02\n",
      "   9.17692324e-02  1.00000000e+00  1.99015328e-03 -1.99015328e-03\n",
      "   1.14060191e-01 -1.14060191e-01  4.07988641e-02 -4.07988641e-02]\n",
      " [ 2.68322609e-02 -2.90028573e-03  1.06660297e-02  4.52156993e-02\n",
      "   1.83149389e-02  6.05464654e-03  2.51347380e-03 -3.56432284e-02\n",
      "  -1.26964124e-02  1.99015328e-03  1.00000000e+00 -1.00000000e+00\n",
      "   2.10466621e-02 -2.10466621e-02  4.91516647e-02 -4.91516647e-02]\n",
      " [-2.68322609e-02  2.90028573e-03 -1.06660297e-02 -4.52156993e-02\n",
      "  -1.83149389e-02 -6.05464654e-03 -2.51347380e-03  3.56432284e-02\n",
      "   1.26964124e-02 -1.99015328e-03 -1.00000000e+00  1.00000000e+00\n",
      "  -2.10466621e-02  2.10466621e-02 -4.91516647e-02  4.91516647e-02]\n",
      " [ 1.86923847e-01 -5.08072929e-02  1.16913504e-01  1.09378217e-01\n",
      "   7.80808724e-02  7.21148398e-02 -6.16312871e-02 -3.49770831e-01\n",
      "  -7.92158347e-03  1.14060191e-01  2.10466621e-02 -2.10466621e-02\n",
      "   1.00000000e+00 -1.00000000e+00  1.04432086e-01 -1.04432086e-01]\n",
      " [-1.86923847e-01  5.08072929e-02 -1.16913504e-01 -1.09378217e-01\n",
      "  -7.80808724e-02 -7.21148398e-02  6.16312871e-02  3.49770831e-01\n",
      "   7.92158347e-03 -1.14060191e-01 -2.10466621e-02  2.10466621e-02\n",
      "  -1.00000000e+00  1.00000000e+00 -1.04432086e-01  1.04432086e-01]\n",
      " [ 4.43265433e-03 -5.61433819e-02  3.07096433e-02  8.35838175e-02\n",
      "   3.54205673e-02  3.49202301e-02 -8.47959295e-03 -1.48613420e-02\n",
      "  -1.41731864e-02  4.07988641e-02  4.91516647e-02 -4.91516647e-02\n",
      "   1.04432086e-01 -1.04432086e-01  1.00000000e+00 -1.00000000e+00]\n",
      " [-4.43265433e-03  5.61433819e-02 -3.07096433e-02 -8.35838175e-02\n",
      "  -3.54205673e-02 -3.49202301e-02  8.47959295e-03  1.48613420e-02\n",
      "   1.41731864e-02 -4.07988641e-02 -4.91516647e-02  4.91516647e-02\n",
      "  -1.04432086e-01  1.04432086e-01 -1.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = np.corrcoef(arr_train_x, rowvar=False)\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 11, 12, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "num_features = correlation_matrix.shape[0]\n",
    "features_to_remove = set()\n",
    "\n",
    "for i in range(num_features):\n",
    "    for j in range(i+1, num_features):\n",
    "        if abs(correlation_matrix[i, j]) > threshold:\n",
    "            features_to_remove.add(j)\n",
    "\n",
    "features_to_remove = list(features_to_remove)\n",
    "print(features_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  33    2  882 ...    0    1    1]\n",
      " [  42    1 -247 ...    2    1    0]\n",
      " [  33    1 3444 ...    0    1    1]\n",
      " ...\n",
      " [  73    1 2850 ...    0    1    1]\n",
      " [  72    1 5715 ...    1    1    1]\n",
      " [  37    1 2971 ...    2    1    1]]\n"
     ]
    }
   ],
   "source": [
    "reduced_data = np.delete(arr_train_x, features_to_remove, axis=1)\n",
    "print(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6273, 11)\n",
      "(1569, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    reduced_data, arr_train_y, test_size=0.2, random_state=2, shuffle=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 64)                768       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,841\n",
      "Trainable params: 3,617\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.6770 - accuracy: 0.6134 - val_loss: 0.5597 - val_accuracy: 0.7347\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7567 - val_loss: 0.5123 - val_accuracy: 0.7490\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7678 - val_loss: 0.4959 - val_accuracy: 0.7506\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7828 - val_loss: 0.4921 - val_accuracy: 0.7562\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7750 - val_loss: 0.4935 - val_accuracy: 0.7538\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7792 - val_loss: 0.4896 - val_accuracy: 0.7530\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7842 - val_loss: 0.4852 - val_accuracy: 0.7562\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7818 - val_loss: 0.4852 - val_accuracy: 0.7546\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7824 - val_loss: 0.4802 - val_accuracy: 0.7546\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7880 - val_loss: 0.4777 - val_accuracy: 0.7506\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7854 - val_loss: 0.4741 - val_accuracy: 0.7546\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7892 - val_loss: 0.4786 - val_accuracy: 0.7466\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7852 - val_loss: 0.4745 - val_accuracy: 0.7466\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7945 - val_loss: 0.4756 - val_accuracy: 0.7498\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7836 - val_loss: 0.4712 - val_accuracy: 0.7474\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7858 - val_loss: 0.4725 - val_accuracy: 0.7530\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7872 - val_loss: 0.4746 - val_accuracy: 0.7482\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7917 - val_loss: 0.4710 - val_accuracy: 0.7522\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7898 - val_loss: 0.4712 - val_accuracy: 0.7466\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7846 - val_loss: 0.4727 - val_accuracy: 0.7482\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7856 - val_loss: 0.4680 - val_accuracy: 0.7466\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7878 - val_loss: 0.4665 - val_accuracy: 0.7514\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7896 - val_loss: 0.4689 - val_accuracy: 0.7458\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7933 - val_loss: 0.4661 - val_accuracy: 0.7514\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7880 - val_loss: 0.4688 - val_accuracy: 0.7434\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7886 - val_loss: 0.4687 - val_accuracy: 0.7442\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7888 - val_loss: 0.4690 - val_accuracy: 0.7418\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.4650 - val_accuracy: 0.7442\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7860 - val_loss: 0.4696 - val_accuracy: 0.7458\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7967 - val_loss: 0.4732 - val_accuracy: 0.7466\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7906 - val_loss: 0.4673 - val_accuracy: 0.7434\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7870 - val_loss: 0.4650 - val_accuracy: 0.7466\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7870 - val_loss: 0.4651 - val_accuracy: 0.7458\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7896 - val_loss: 0.4647 - val_accuracy: 0.7426\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7836 - val_loss: 0.4638 - val_accuracy: 0.7410\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7953 - val_loss: 0.4657 - val_accuracy: 0.7506\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7941 - val_loss: 0.4650 - val_accuracy: 0.7474\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7917 - val_loss: 0.4652 - val_accuracy: 0.7418\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7896 - val_loss: 0.4680 - val_accuracy: 0.7442\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7910 - val_loss: 0.4660 - val_accuracy: 0.7458\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7937 - val_loss: 0.4651 - val_accuracy: 0.7426\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7872 - val_loss: 0.4629 - val_accuracy: 0.7442\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7927 - val_loss: 0.4626 - val_accuracy: 0.7514\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7945 - val_loss: 0.4638 - val_accuracy: 0.7482\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7860 - val_loss: 0.4608 - val_accuracy: 0.7490\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7917 - val_loss: 0.4601 - val_accuracy: 0.7498\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7963 - val_loss: 0.4640 - val_accuracy: 0.7498\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7921 - val_loss: 0.4597 - val_accuracy: 0.7586\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7953 - val_loss: 0.4684 - val_accuracy: 0.7482\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7955 - val_loss: 0.4621 - val_accuracy: 0.7442\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7850 - val_loss: 0.4671 - val_accuracy: 0.7418\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7836 - val_loss: 0.4654 - val_accuracy: 0.7434\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7884 - val_loss: 0.4616 - val_accuracy: 0.7474\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7933 - val_loss: 0.4618 - val_accuracy: 0.7482\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7892 - val_loss: 0.4665 - val_accuracy: 0.7466\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7846 - val_loss: 0.4649 - val_accuracy: 0.7434\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7919 - val_loss: 0.4624 - val_accuracy: 0.7474\n",
      "Epoch 58/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7908 - val_loss: 0.4626 - val_accuracy: 0.7442\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "# model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,841\n",
      "Trainable params: 3,617\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = keras.Sequential()\n",
    "\n",
    "# model.add(layers.InputLayer(input_shape=(11,))) # 16 Columns of input\n",
    "\n",
    "# model.add(layers.Dense(32, activation=\"relu\"))\n",
    "\n",
    "# model.add(layers.Dense(1, activation=\"sigmoid\")) # 0->1 floating\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.InputLayer(input_shape=(11,)))\n",
    "\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(16, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='sgd',\n",
    "#     metrics=['accuracy']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train, np.float32)\n",
    "X_train = tf.convert_to_tensor(X_train, np.float32)\n",
    "\n",
    "Y_train = tf.convert_to_tensor(Y_train, np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.6955 - accuracy: 0.6473 - val_loss: 0.5265 - val_accuracy: 0.7474\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7525 - val_loss: 0.5089 - val_accuracy: 0.7434\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7798 - val_loss: 0.5026 - val_accuracy: 0.7442\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7458\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7762 - val_loss: 0.4939 - val_accuracy: 0.7442\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7866 - val_loss: 0.5026 - val_accuracy: 0.7434\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7834 - val_loss: 0.4916 - val_accuracy: 0.7442\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7774 - val_loss: 0.4978 - val_accuracy: 0.7426\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7838 - val_loss: 0.4858 - val_accuracy: 0.7506\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7856 - val_loss: 0.4827 - val_accuracy: 0.7530\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7774 - val_loss: 0.4867 - val_accuracy: 0.7442\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7848 - val_loss: 0.4864 - val_accuracy: 0.7458\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7824 - val_loss: 0.4813 - val_accuracy: 0.7474\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7848 - val_loss: 0.4809 - val_accuracy: 0.7410\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.4791 - val_accuracy: 0.7498\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7856 - val_loss: 0.4778 - val_accuracy: 0.7466\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7820 - val_loss: 0.4761 - val_accuracy: 0.7514\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7894 - val_loss: 0.4717 - val_accuracy: 0.7530\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7900 - val_loss: 0.4719 - val_accuracy: 0.7506\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7890 - val_loss: 0.4746 - val_accuracy: 0.7522\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7959 - val_loss: 0.4704 - val_accuracy: 0.7514\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7892 - val_loss: 0.4767 - val_accuracy: 0.7482\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7852 - val_loss: 0.4708 - val_accuracy: 0.7474\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7910 - val_loss: 0.4710 - val_accuracy: 0.7498\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7848 - val_loss: 0.4701 - val_accuracy: 0.7442\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7935 - val_loss: 0.4699 - val_accuracy: 0.7466\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7872 - val_loss: 0.4744 - val_accuracy: 0.7442\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7870 - val_loss: 0.4673 - val_accuracy: 0.7514\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7916 - val_loss: 0.4669 - val_accuracy: 0.7490\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7914 - val_loss: 0.4662 - val_accuracy: 0.7546\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7880 - val_loss: 0.4682 - val_accuracy: 0.7434\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7923 - val_loss: 0.4717 - val_accuracy: 0.7442\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7878 - val_loss: 0.4687 - val_accuracy: 0.7538\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7929 - val_loss: 0.4669 - val_accuracy: 0.7506\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7864 - val_loss: 0.4670 - val_accuracy: 0.7530\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7904 - val_loss: 0.4632 - val_accuracy: 0.7530\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7890 - val_loss: 0.4660 - val_accuracy: 0.7474\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7878 - val_loss: 0.4650 - val_accuracy: 0.7530\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7868 - val_loss: 0.4649 - val_accuracy: 0.7466\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7892 - val_loss: 0.4647 - val_accuracy: 0.7466\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7953 - val_loss: 0.4649 - val_accuracy: 0.7586\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7846 - val_loss: 0.4657 - val_accuracy: 0.7514\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7937 - val_loss: 0.4629 - val_accuracy: 0.7554\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7888 - val_loss: 0.4664 - val_accuracy: 0.7506\n",
      "Epoch 45/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7914 - val_loss: 0.4631 - val_accuracy: 0.7530\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7896 - val_loss: 0.4663 - val_accuracy: 0.7410\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7927 - val_loss: 0.4670 - val_accuracy: 0.7466\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7892 - val_loss: 0.4630 - val_accuracy: 0.7458\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7906 - val_loss: 0.4597 - val_accuracy: 0.7466\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7951 - val_loss: 0.4678 - val_accuracy: 0.7538\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7914 - val_loss: 0.4672 - val_accuracy: 0.7506\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7931 - val_loss: 0.4580 - val_accuracy: 0.7530\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7910 - val_loss: 0.4648 - val_accuracy: 0.7490\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7850 - val_loss: 0.4634 - val_accuracy: 0.7474\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7916 - val_loss: 0.4651 - val_accuracy: 0.7466\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7949 - val_loss: 0.4635 - val_accuracy: 0.7538\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7949 - val_loss: 0.4657 - val_accuracy: 0.7482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7880 - val_loss: 0.4639 - val_accuracy: 0.7458\n",
      "Epoch 59/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7908 - val_loss: 0.4616 - val_accuracy: 0.7490\n",
      "Epoch 60/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7923 - val_loss: 0.4598 - val_accuracy: 0.7514\n",
      "Epoch 61/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7923 - val_loss: 0.4625 - val_accuracy: 0.7490\n",
      "Epoch 62/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7943 - val_loss: 0.4609 - val_accuracy: 0.7418\n"
     ]
    }
   ],
   "source": [
    "# Early stopping callback\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "172/172 [==============================] - 5s 5ms/step - loss: 105.3480 - accuracy: 0.7653\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 1s 8ms/step - loss: 9.9948 - accuracy: 0.7701\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 6.2464 - accuracy: 0.7723\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 4.4516 - accuracy: 0.7739\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 4.1672 - accuracy: 0.7735\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 2.8550 - accuracy: 0.7737\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 2.3918 - accuracy: 0.7737\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 1.7497 - accuracy: 0.7739\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 2.8217 - accuracy: 0.7741\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 3s 15ms/step - loss: 2.3345 - accuracy: 0.7746\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 3.9105 - accuracy: 0.7737\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 6.3502 - accuracy: 0.7750\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 1.4432 - accuracy: 0.7750\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.9389 - accuracy: 0.7739\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 1.0614 - accuracy: 0.7728\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.9211 - accuracy: 0.7745\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 2s 10ms/step - loss: 0.8441 - accuracy: 0.7743 0s - loss: 1.0567 \n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 2s 11ms/step - loss: 0.7926 - accuracy: 0.7743\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.7938 - accuracy: 0.7743\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 1.5011 - accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "model_training_history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(model_training_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'artist' from 'matplotlib' (C:\\Users\\avitr\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\pyplot.py:49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\colorbar.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, collections, cm, colors, contour, ticker\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmartist\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\collections.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_api, _path, artist, cbook, cm, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, docstring,\n\u001b[0;32m     21\u001b[0m                hatch \u001b[38;5;28;01mas\u001b[39;00m mhatch, lines \u001b[38;5;28;01mas\u001b[39;00m mlines, path \u001b[38;5;28;01mas\u001b[39;00m mpath, transforms)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# \"color\" is excluded; it is a compound setter, and its docstring differs\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# in LineCollection.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\lines.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, artist, cbook, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, docstring, rcParams\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Artist, allow_rasterization\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     _to_unmasked_float_array, ls_mapper, ls_mapper_r, STEP_LOOKUP_MAP)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'artist' from 'matplotlib' (C:\\Users\\avitr\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "acc = model_training_history.history['accuracy']\n",
    "loss = model_training_history.history['loss']\n",
    "ax1.plot(acc)\n",
    "ax2.plot(loss)\n",
    "ax1.set_ylabel('training accuracy')\n",
    "ax2.set_ylabel('training loss')\n",
    "ax2.set_xlabel('epochs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 954us/step - loss: 0.4234 - accuracy: 0.7725\n",
      "0.42338478565216064 0.7724665403366089\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 827us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1160   40]\n",
      " [ 317   52]]\n",
      "TP: 52\n",
      "FP: 40\n",
      "TN: 1160\n",
      "FN: 317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "print(confusion_matrix(Y_test, np.round(y_pred) ))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, np.round(y_pred) ).ravel()\n",
    "print(f\"TP: {tp}\")\n",
    "print(f\"FP: {fp}\")\n",
    "print(f\"TN: {tn}\")\n",
    "print(f\"FN: {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1576456 ],\n",
       "       [0.5002137 ],\n",
       "       [0.10005882],\n",
       "       ...,\n",
       "       [0.13652585],\n",
       "       [0.02723427],\n",
       "       [0.21761274]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'artist' from 'matplotlib' (C:\\Users\\avitr\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay\n\u001b[1;32m----> 2\u001b[0m a  \u001b[38;5;241m=\u001b[39m \u001b[43mConfusionMatrixDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:473\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.from_predictions\u001b[1;34m(cls, y_true, y_pred, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[0;32m    463\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\n\u001b[0;32m    464\u001b[0m     y_true,\n\u001b[0;32m    465\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m     normalize\u001b[38;5;241m=\u001b[39mnormalize,\n\u001b[0;32m    469\u001b[0m )\n\u001b[0;32m    471\u001b[0m disp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(confusion_matrix\u001b[38;5;241m=\u001b[39mcm, display_labels\u001b[38;5;241m=\u001b[39mdisplay_labels)\n\u001b[1;32m--> 473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticks_rotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxticks_rotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolorbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolorbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mim_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mim_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:133\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.plot\u001b[1;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot visualization.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    that contains all the information to plot the confusion matrix.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m check_matplotlib_support(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusionMatrixDisplay.plot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\pyplot.py:49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\colorbar.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, collections, cm, colors, contour, ticker\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmartist\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\collections.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_api, _path, artist, cbook, cm, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, docstring,\n\u001b[0;32m     21\u001b[0m                hatch \u001b[38;5;28;01mas\u001b[39;00m mhatch, lines \u001b[38;5;28;01mas\u001b[39;00m mlines, path \u001b[38;5;28;01mas\u001b[39;00m mpath, transforms)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# \"color\" is excluded; it is a compound setter, and its docstring differs\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# in LineCollection.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\lines.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, artist, cbook, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, docstring, rcParams\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Artist, allow_rasterization\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     _to_unmasked_float_array, ls_mapper, ls_mapper_r, STEP_LOOKUP_MAP)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'artist' from 'matplotlib' (C:\\Users\\avitr\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "a  = ConfusionMatrixDisplay.from_predictions(Y_test, np.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x210a1dd2e80>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, np.round(y_pred))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
