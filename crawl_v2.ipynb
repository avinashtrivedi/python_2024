{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21330802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e63de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.johnsonwilshire.com/\"\n",
    "def get_html(url):\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', url,headers = {'User-agent': 'your bot 0.1'})\n",
    "    soup = BeautifulSoup(response.data)\n",
    "    return soup,response.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f4e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "soup,status = get_html(url)\n",
    "for a_tag in soup.find_all('a', {'data-testid': 'linkElement'}):\n",
    "    href = a_tag.get('href')\n",
    "    if href:\n",
    "        links.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9865f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = []\n",
    "for link in links:\n",
    "    x = link.split('https://www.johnsonwilshire.com')\n",
    "    if x[0]=='' and x[1]!='':\n",
    "        all_links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd27e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda71b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fdcc695dce408182e2a4bff78aade3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "all_products = []\n",
    "for link in tqdm(all_links):\n",
    "    soup,status = get_html(link)\n",
    "    for div_tag in soup.find_all('div', {'data-hook': 'product-item-root'}):\n",
    "        data_slug = div_tag.get('data-slug')\n",
    "        all_products.append('https://www.johnsonwilshire.com/product-page/'+data_slug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72fe635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(url):\n",
    "    soup,status = get_html(url)\n",
    "    \n",
    "    if status!=200:\n",
    "        return [url] + [status]*4\n",
    "    \n",
    "    script_tag = soup.find('script', type='application/ld+json')\n",
    "    json_data = json.loads(script_tag.string)\n",
    "    image_urls = [image[\"contentUrl\"] for image in json_data[\"image\"] if image.get(\"representativeOfPage\")]\n",
    "    \n",
    "    image_link = '\\n'.join(image_urls)\n",
    "\n",
    "    # Extract the title\n",
    "    title_tag = soup.find('meta', {'name': 'twitter:title'})\n",
    "    title = title_tag['content'] if title_tag else ''\n",
    "\n",
    "    description_tag = soup.find('meta', {'name': 'twitter:description'})\n",
    "    description = description_tag['content'] if description_tag else ''\n",
    "    if description:\n",
    "        description = description.strip().replace('\\t',',')\n",
    "    \n",
    "    description = re.sub(r',,+', ',', description)\n",
    "    \n",
    "    info_section = soup.find_all('div', {'data-hook': 'info-section-description'})\n",
    "    titles = soup.find_all('h2', {'data-hook': 'info-section-title'})\n",
    " \n",
    "    desc = ''\n",
    "    for t,info in zip(titles,info_section):\n",
    "        desc += t.get_text(strip=True) + ': ' + info.get_text(separator=\",\",strip=True) + '\\n'\n",
    "    \n",
    "    desc = re.sub(r',,+', ',', desc)\n",
    "        \n",
    "    return url,image_link,title,description,desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db640de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([], columns=['url','image', 'title', 'Desc', 'Long Desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a66e9922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8785652c687d413ca2c501024455f0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.johnsonwilshire.com/product-page/green-heavy-duty-tarps\n",
      "https://www.johnsonwilshire.com/product-page/kevlar-sewn-6010k\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(all_products):\n",
    "    try:\n",
    "        url,image_link,title,description,desc = get_details(item)\n",
    "    except:\n",
    "        print(url)\n",
    "    df.loc[len(df)] = [url,image_link,title,description,desc]\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "582f617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f508d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfa = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5570b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(lambda x: x.split('|')[0].strip() if x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f2667dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_items1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e030e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean image url\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('all_items1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c17ea124",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x.split('.jpg')[0]+'.jpg' if '.jpg' in x else x.split('.png')[0]+'.png'\n",
    "\n",
    "df['image'] = df['image'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b99b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_items2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72245568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myNEWenv)",
   "language": "python",
   "name": "mynewenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
