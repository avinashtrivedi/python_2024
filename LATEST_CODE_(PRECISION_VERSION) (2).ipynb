{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fsGynB8OJgxQ",
   "metadata": {
    "id": "fsGynB8OJgxQ"
   },
   "source": [
    "**Import the required dependencies for the  project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "_4lQ-tSznWo9",
   "metadata": {
    "id": "_4lQ-tSznWo9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score,accuracy_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5VpdIZ2cJs_u",
   "metadata": {
    "id": "5VpdIZ2cJs_u"
   },
   "source": [
    "\n",
    "# **Dataset preparation steps**\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "1. ***Load the dataset required***\n",
    "   - The dataset is loaded from a CSV file named `final_data.csv` using the pandas library.\n",
    "   - The data is stored in a DataFrame named `data` for further processing.\n",
    "\n",
    "2. ***Filter the data where label is 0***\n",
    "   - The dataset is filtered to include only the rows where the 'Label' column is equal to 0.\n",
    "   - This filtered dataset is stored in a DataFrame named `filtered_data_0`.\n",
    "   - Filtering the data helps in focusing on a specific subset of the dataset for anomaly detection.\n",
    "\n",
    "3. ***Split the data into training set, evaluation set, and test set***\n",
    "   - The filtered data is split into three parts: training set, evaluation set, and test set.\n",
    "   - Training Set: 60% of the filtered data is used for training the autoencoder model.\n",
    "   - Evaluation Set: 20% of the remaining data is used for evaluating the model during training.\n",
    "   - Test Set: The final 20% of the data is used for testing the model after training.\n",
    "   - The `train_test_split` function from the scikit-learn library is used for splitting the data, ensuring reproducibility with a fixed random state (42).\n",
    "   - The label column and other non-feature columns are dropped from the training, evaluation, and test sets to prepare the data for training the model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa34ca4f",
   "metadata": {
    "id": "aa34ca4f"
   },
   "outputs": [],
   "source": [
    "# load your dataset\n",
    "data = pd.read_csv('D:\\OneDrive - NITT\\Custom_Download\\scaled_output1.csv')\n",
    "\n",
    "# filter the data where label is 0\n",
    "filtered_data_0 = data[data['Label'] == 0]\n",
    "\n",
    "#  split the data into train, eval, and test\n",
    "train_data, temp_data = train_test_split(filtered_data_0, test_size=0.1, random_state=42)  # 60% for training\n",
    "eval_data, test_data = train_test_split(temp_data, test_size=0.9, random_state=42)  # split the remaining 40% equally into 20% each\n",
    "\n",
    "# Drop the label column\n",
    "columns_to_drop = ['Label','Dport','SrcBytes','SrcLoad','SrcGap','DstGap','SIntPkt','SIntPktAct','DIntPktAct',\n",
    "                   'sMaxPktSz','dMaxPktSz','sMinPktSz','dMinPktSz','Dur','Trans','TotPkts','TotBytes','Load',\n",
    "                   'Loss','pLoss','pSrcLoss','pDstLoss','Rate','DIA']\n",
    "train_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "eval_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "test_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# save to CSV files\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "eval_data.to_csv('eval_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "429ca40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your dataset\n",
    "data = pd.read_csv('D:\\OneDrive - NITT\\Custom_Download\\scaled_output1.csv')\n",
    "\n",
    "# filter the data where label is 1\n",
    "filtered_data_1 = data[data['Label'] == 1]\n",
    "\n",
    "#  split the data into test 1, test 2, and test 3\n",
    "test1_data, temp_data = train_test_split(filtered_data_1, test_size=0.5, random_state=42)  # 50% for training\n",
    "test2_data, test3_data = train_test_split(temp_data, test_size=0.95, random_state=42)  # split the remaining 50% equally into 25% each\n",
    "\n",
    "#Drop the label column\n",
    "test1_data.drop(['Label','Dport','SrcBytes','SrcLoad','SrcGap','DstGap','SIntPkt','SIntPktAct','DIntPktAct','sMaxPktSz','dMaxPktSz','sMinPktSz','dMinPktSz','Dur','Trans','TotPkts','TotBytes','Load','Loss','pLoss','pSrcLoss','pDstLoss','Rate','DIA'], axis=1, inplace=True)\n",
    "test2_data.drop(['Label','Dport','SrcBytes','SrcLoad','SrcGap','DstGap','SIntPkt','SIntPktAct','DIntPktAct','sMaxPktSz','dMaxPktSz','sMinPktSz','dMinPktSz','Dur','Trans','TotPkts','TotBytes','Load','Loss','pLoss','pSrcLoss','pDstLoss','Rate','DIA'], axis=1, inplace=True)\n",
    "test3_data.drop(['Label','Dport','SrcBytes','SrcLoad','SrcGap','DstGap','SIntPkt','SIntPktAct','DIntPktAct','sMaxPktSz','dMaxPktSz','sMinPktSz','dMinPktSz','Dur','Trans','TotPkts','TotBytes','Load','Loss','pLoss','pSrcLoss','pDstLoss','Rate','DIA'], axis=1, inplace=True)\n",
    "\n",
    "# save to CSV files\n",
    "test1_data.to_csv('test1_data.csv', index=False)\n",
    "test2_data.to_csv('test2_data.csv', index=False)\n",
    "test3_data.to_csv('test3_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uKiBO7vELWfh",
   "metadata": {
    "id": "uKiBO7vELWfh"
   },
   "source": [
    "# **Define the Autoencoder**\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "***1. Input Layer:***\n",
    "   - The input layer for the autoencoder is defined with a shape that matches the number of features in the training data.\n",
    "   - This layer serves as the entry point for the data into the autoencoder model, accepting input data with the specified number of features.\n",
    "\n",
    "***2. Encoder Part:***\n",
    "\n",
    "   a. ***First Dense Layer***:\n",
    "      - A dense (fully connected) layer with 256 units is added.\n",
    "      - The ReLU (Rectified Linear Unit) activation function is used to introduce non-linearity into the model.\n",
    "      - This layer reduces the dimensionality of the input data, helping the model to learn important features.\n",
    "\n",
    "   b. ***Dropout Layer:***\n",
    "      - To prevent overfitting, a dropout layer is added after the first dense layer.\n",
    "      - This layer randomly drops 20% of the units during each training iteration, ensuring the model does not become too reliant on any single feature.\n",
    "\n",
    "   c. ***Second Dense Layer:***\n",
    "      - Another dense layer with 128 units is added.\n",
    "      - The ReLU activation function is used again to maintain non-linearity in the model.\n",
    "      - This layer further reduces the dimensionality of the data, allowing the model to capture more abstract features.\n",
    "\n",
    "   d. ***Dropout Layer:***\n",
    "      - A second dropout layer is added after the second dense layer.\n",
    "      - This layer also drops 20% of the units during training to further prevent overfitting and improve the generalization of the model.\n",
    "\n",
    "   e. ***Third Dense Layer:***\n",
    "      - A dense layer with 64 units is added.\n",
    "      - The ReLU activation function is used for non-linearity.\n",
    "      - This layer forms the bottleneck of the autoencoder, capturing the most important features of the input data in a lower-dimensional space.\n",
    "      - The bottleneck layer compresses the input data into a smaller representation, which is essential for the autoencoder to learn how to reconstruct the input data effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc84401f",
   "metadata": {
    "id": "bc84401f"
   },
   "outputs": [],
   "source": [
    "# Define the Autoencoder\n",
    "input_layer = Input(shape=(train_data.shape[1],))\n",
    "# Encoder part\n",
    "encoded = Dense(256, activation='relu')(input_layer)\n",
    "encoded = Dropout(0.2)(encoded)\n",
    "encoded = Dense(128, activation='relu')(encoded)\n",
    "encoded = Dropout(0.2)(encoded)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ciY-QG4NMNDG",
   "metadata": {
    "id": "ciY-QG4NMNDG"
   },
   "source": [
    "# ***Decoder Part***\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "***1. First Dense Layer***\n",
    "   - A dense (fully connected) layer with 128 units is added.\n",
    "   - The ReLU (Rectified Linear Unit) activation function is used to introduce non-linearity into the model.\n",
    "   - This layer starts the process of reconstructing the original input data from the encoded representation obtained from the encoder part of the autoencoder.\n",
    "\n",
    "2. ***Second Dense Layer:***\n",
    "   - Another dense layer with 256 units is added.\n",
    "   - The ReLU activation function is used again to maintain non-linearity in the model.\n",
    "   - This layer further reconstructs the input data by expanding the encoded representation, bringing it closer to the original input dimensions.\n",
    "\n",
    "3. ***Third Dense Layer:***\n",
    "   - A dense layer with the number of units matching the number of features in the training data is added.\n",
    "   - The sigmoid activation function is used to ensure the output values are in the range [0, 1], which is suitable for reconstruction tasks.\n",
    "   - This layer outputs the final reconstructed data, completing the reconstruction process and allowing the autoencoder to compare the output with the original input for learning and optimization.\n",
    "\n",
    "4. ***Model Compilation:***\n",
    "   - The autoencoder model is compiled using the Adam optimizer with a learning rate of 0.001.\n",
    "   - The loss function used is mean squared error, which measures the average of the squares of the errors between the original input and the reconstructed output.\n",
    "   - Accuracy is included as a metric to monitor the training process and evaluate the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f1c034",
   "metadata": {
    "id": "f5f1c034"
   },
   "outputs": [],
   "source": [
    "# Decoder part\n",
    "decoded = Dense(128, activation='relu')(encoded)\n",
    "decoded = Dense(256, activation='relu')(decoded)\n",
    "decoded = Dense(train_data.shape[1], activation='sigmoid')(decoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), metrics=['accuracy'], loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ELe15W0fNApw",
   "metadata": {
    "id": "ELe15W0fNApw"
   },
   "source": [
    "# **Cross-validation**\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "1. ***K-Fold Splitting:***\n",
    "   - The data is split into 5 folds using the KFold class from scikit-learn.\n",
    "   - Shuffling is enabled to ensure that the data is randomly divided into folds, which helps in reducing bias and improving the robustness of the model.\n",
    "   - A fixed random state (42) is used for reproducibility, ensuring that the splits are the same each time the code is run.\n",
    "\n",
    "2. ***Training and Validation:***\n",
    "   - For each fold, the autoencoder is trained on the training data (train_fold) and validated on the validation data (val_fold).\n",
    "   - This process helps in assessing the model's performance across different subsets of the data, providing a better estimate of its generalization capability.\n",
    "\n",
    "3. ***Number of Epochs:***\n",
    "   - The model is trained for 50 epochs in each fold.\n",
    "   - Increasing the number of epochs allows the model to learn and converge better by exposing it to the data multiple times.\n",
    "\n",
    "4. ***Batch Size:***\n",
    "   - Training is performed in batches of 32 samples.\n",
    "   - Using a batch size helps in efficiently utilizing computational resources by processing multiple samples together, which speeds up training and stabilizes learning.\n",
    "\n",
    "5. ***Shuffle:***\n",
    "   - The training data is shuffled during each epoch to avoid any bias that may arise from the order of samples.\n",
    "   - Shuffling ensures that the model does not learn any spurious patterns that may be present in the sequence of the training data.\n",
    "\n",
    "6. ***Validation Data:***\n",
    "   - Validation data (val_fold) is used to monitor the performance of the model during training.\n",
    "   - By evaluating the model on unseen validation data, it helps in preventing overfitting and provides insights into how well the model generalizes to new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb8e92b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acb8e92b",
    "outputId": "54951737-1157-41a6-a5a5-185b5ec8711e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "322/322 [==============================] - 3s 5ms/step - loss: 0.0078 - accuracy: 0.5202 - val_loss: 0.0017 - val_accuracy: 0.5271\n",
      "Epoch 2/50\n",
      "322/322 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 0.5854 - val_loss: 6.8331e-04 - val_accuracy: 0.7361\n",
      "Epoch 3/50\n",
      "322/322 [==============================] - 2s 5ms/step - loss: 8.5379e-04 - accuracy: 0.7679 - val_loss: 5.4681e-04 - val_accuracy: 0.8377\n",
      "Epoch 4/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 6.5064e-04 - accuracy: 0.8331 - val_loss: 3.8954e-04 - val_accuracy: 0.8840\n",
      "Epoch 5/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 5.0373e-04 - accuracy: 0.8717 - val_loss: 3.0950e-04 - val_accuracy: 0.8930\n",
      "Epoch 6/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 4.0324e-04 - accuracy: 0.8881 - val_loss: 2.8215e-04 - val_accuracy: 0.8957\n",
      "Epoch 7/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 3.4141e-04 - accuracy: 0.8907 - val_loss: 2.1167e-04 - val_accuracy: 0.8922\n",
      "Epoch 8/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 3.0468e-04 - accuracy: 0.8946 - val_loss: 1.6830e-04 - val_accuracy: 0.8941\n",
      "Epoch 9/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 2.7012e-04 - accuracy: 0.8959 - val_loss: 1.8690e-04 - val_accuracy: 0.8988\n",
      "Epoch 10/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 2.4863e-04 - accuracy: 0.8985 - val_loss: 1.7687e-04 - val_accuracy: 0.8980\n",
      "Epoch 11/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 2.4958e-04 - accuracy: 0.9000 - val_loss: 1.7359e-04 - val_accuracy: 0.8961\n",
      "Epoch 12/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 2.2282e-04 - accuracy: 0.9004 - val_loss: 1.8874e-04 - val_accuracy: 0.8922\n",
      "Epoch 13/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 2.0963e-04 - accuracy: 0.9036 - val_loss: 1.5544e-04 - val_accuracy: 0.9019\n",
      "Epoch 14/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.9847e-04 - accuracy: 0.9035 - val_loss: 1.5138e-04 - val_accuracy: 0.8941\n",
      "Epoch 15/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.9239e-04 - accuracy: 0.9045 - val_loss: 1.3620e-04 - val_accuracy: 0.9027\n",
      "Epoch 16/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.8177e-04 - accuracy: 0.9111 - val_loss: 1.2103e-04 - val_accuracy: 0.9148\n",
      "Epoch 17/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.8542e-04 - accuracy: 0.9141 - val_loss: 1.4399e-04 - val_accuracy: 0.9276\n",
      "Epoch 18/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.7628e-04 - accuracy: 0.9189 - val_loss: 9.8746e-05 - val_accuracy: 0.9148\n",
      "Epoch 19/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.7898e-04 - accuracy: 0.9199 - val_loss: 1.4640e-04 - val_accuracy: 0.9369\n",
      "Epoch 20/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.6925e-04 - accuracy: 0.9227 - val_loss: 1.2502e-04 - val_accuracy: 0.9155\n",
      "Epoch 21/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.7422e-04 - accuracy: 0.9235 - val_loss: 9.8416e-05 - val_accuracy: 0.9284\n",
      "Epoch 22/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.5464e-04 - accuracy: 0.9304 - val_loss: 1.2531e-04 - val_accuracy: 0.9428\n",
      "Epoch 23/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.5694e-04 - accuracy: 0.9307 - val_loss: 1.0146e-04 - val_accuracy: 0.9404\n",
      "Epoch 24/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.5659e-04 - accuracy: 0.9308 - val_loss: 1.0192e-04 - val_accuracy: 0.9389\n",
      "Epoch 25/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.5336e-04 - accuracy: 0.9359 - val_loss: 1.2013e-04 - val_accuracy: 0.9478\n",
      "Epoch 26/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.7030e-04 - accuracy: 0.9363 - val_loss: 9.6351e-05 - val_accuracy: 0.9525\n",
      "Epoch 27/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.4845e-04 - accuracy: 0.9401 - val_loss: 8.3617e-05 - val_accuracy: 0.9560\n",
      "Epoch 28/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.3895e-04 - accuracy: 0.9414 - val_loss: 8.4603e-05 - val_accuracy: 0.9576\n",
      "Epoch 29/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.4589e-04 - accuracy: 0.9412 - val_loss: 1.0556e-04 - val_accuracy: 0.9541\n",
      "Epoch 30/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.4258e-04 - accuracy: 0.9432 - val_loss: 8.6968e-05 - val_accuracy: 0.9611\n",
      "Epoch 31/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.5392e-04 - accuracy: 0.9434 - val_loss: 1.1155e-04 - val_accuracy: 0.9630\n",
      "Epoch 32/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.4380e-04 - accuracy: 0.9469 - val_loss: 1.1857e-04 - val_accuracy: 0.9583\n",
      "Epoch 33/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.3230e-04 - accuracy: 0.9466 - val_loss: 9.8901e-05 - val_accuracy: 0.9576\n",
      "Epoch 34/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.4178e-04 - accuracy: 0.9475 - val_loss: 9.1480e-05 - val_accuracy: 0.9525\n",
      "Epoch 35/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2988e-04 - accuracy: 0.9493 - val_loss: 7.8908e-05 - val_accuracy: 0.9657\n",
      "Epoch 36/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2608e-04 - accuracy: 0.9486 - val_loss: 8.5511e-05 - val_accuracy: 0.9692\n",
      "Epoch 37/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2297e-04 - accuracy: 0.9513 - val_loss: 8.3542e-05 - val_accuracy: 0.9638\n",
      "Epoch 38/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2399e-04 - accuracy: 0.9515 - val_loss: 1.1765e-04 - val_accuracy: 0.9681\n",
      "Epoch 39/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.4509e-04 - accuracy: 0.9420 - val_loss: 8.3341e-05 - val_accuracy: 0.9696\n",
      "Epoch 40/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2742e-04 - accuracy: 0.9511 - val_loss: 8.3555e-05 - val_accuracy: 0.9603\n",
      "Epoch 41/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.2180e-04 - accuracy: 0.9518 - val_loss: 8.5417e-05 - val_accuracy: 0.9681\n",
      "Epoch 42/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2589e-04 - accuracy: 0.9508 - val_loss: 7.6865e-05 - val_accuracy: 0.9661\n",
      "Epoch 43/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.2351e-04 - accuracy: 0.9510 - val_loss: 1.1021e-04 - val_accuracy: 0.9646\n",
      "Epoch 44/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.2002e-04 - accuracy: 0.9508 - val_loss: 1.1488e-04 - val_accuracy: 0.9475\n",
      "Epoch 45/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.3813e-04 - accuracy: 0.9482 - val_loss: 1.2477e-04 - val_accuracy: 0.9545\n",
      "Epoch 46/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1908e-04 - accuracy: 0.9532 - val_loss: 7.3979e-05 - val_accuracy: 0.9716\n",
      "Epoch 47/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.2334e-04 - accuracy: 0.9509 - val_loss: 8.2021e-05 - val_accuracy: 0.9603\n",
      "Epoch 48/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1578e-04 - accuracy: 0.9529 - val_loss: 7.4011e-05 - val_accuracy: 0.9630\n",
      "Epoch 49/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1451e-04 - accuracy: 0.9527 - val_loss: 7.3619e-05 - val_accuracy: 0.9696\n",
      "Epoch 50/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1369e-04 - accuracy: 0.9524 - val_loss: 7.3207e-05 - val_accuracy: 0.9657\n",
      "Epoch 1/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.2092e-04 - accuracy: 0.9521 - val_loss: 6.2625e-05 - val_accuracy: 0.9665\n",
      "Epoch 2/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1439e-04 - accuracy: 0.9509 - val_loss: 8.0306e-05 - val_accuracy: 0.9529\n",
      "Epoch 3/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1961e-04 - accuracy: 0.9484 - val_loss: 6.8380e-05 - val_accuracy: 0.9634\n",
      "Epoch 4/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2249e-04 - accuracy: 0.9491 - val_loss: 6.0061e-05 - val_accuracy: 0.9766\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1204e-04 - accuracy: 0.9542 - val_loss: 4.7521e-05 - val_accuracy: 0.9665\n",
      "Epoch 6/50\n",
      "322/322 [==============================] - 1s 5ms/step - loss: 1.2107e-04 - accuracy: 0.9509 - val_loss: 6.3553e-05 - val_accuracy: 0.9615\n",
      "Epoch 7/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2813e-04 - accuracy: 0.9498 - val_loss: 6.0198e-05 - val_accuracy: 0.9634\n",
      "Epoch 8/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2526e-04 - accuracy: 0.9487 - val_loss: 8.3510e-05 - val_accuracy: 0.9708\n",
      "Epoch 9/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.1537e-04 - accuracy: 0.9505 - val_loss: 5.6007e-05 - val_accuracy: 0.9615\n",
      "Epoch 10/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1647e-04 - accuracy: 0.9526 - val_loss: 6.1149e-05 - val_accuracy: 0.9568\n",
      "Epoch 11/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.1072e-04 - accuracy: 0.9503 - val_loss: 7.4565e-05 - val_accuracy: 0.9615\n",
      "Epoch 12/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.4914e-04 - accuracy: 0.9435 - val_loss: 7.7331e-05 - val_accuracy: 0.9642\n",
      "Epoch 13/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.4108e-04 - accuracy: 0.9494 - val_loss: 6.6564e-05 - val_accuracy: 0.9665\n",
      "Epoch 14/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0940e-04 - accuracy: 0.9522 - val_loss: 4.4179e-05 - val_accuracy: 0.9603\n",
      "Epoch 15/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1225e-04 - accuracy: 0.9527 - val_loss: 9.5853e-05 - val_accuracy: 0.9334\n",
      "Epoch 16/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.2680e-04 - accuracy: 0.9502 - val_loss: 6.8459e-05 - val_accuracy: 0.9599\n",
      "Epoch 17/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0698e-04 - accuracy: 0.9541 - val_loss: 7.4319e-05 - val_accuracy: 0.9622\n",
      "Epoch 18/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1080e-04 - accuracy: 0.9522 - val_loss: 5.4662e-05 - val_accuracy: 0.9630\n",
      "Epoch 19/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0055e-04 - accuracy: 0.9546 - val_loss: 4.2885e-05 - val_accuracy: 0.9611\n",
      "Epoch 20/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0398e-04 - accuracy: 0.9577 - val_loss: 5.1834e-05 - val_accuracy: 0.9669\n",
      "Epoch 21/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1017e-04 - accuracy: 0.9523 - val_loss: 6.2015e-05 - val_accuracy: 0.9630\n",
      "Epoch 22/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0118e-04 - accuracy: 0.9517 - val_loss: 4.8288e-05 - val_accuracy: 0.9568\n",
      "Epoch 23/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0981e-04 - accuracy: 0.9543 - val_loss: 5.8640e-05 - val_accuracy: 0.9642\n",
      "Epoch 24/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1498e-04 - accuracy: 0.9561 - val_loss: 6.7979e-05 - val_accuracy: 0.9669\n",
      "Epoch 25/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1555e-04 - accuracy: 0.9524 - val_loss: 8.0631e-05 - val_accuracy: 0.9704\n",
      "Epoch 26/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1700e-04 - accuracy: 0.9508 - val_loss: 5.7616e-05 - val_accuracy: 0.9622\n",
      "Epoch 27/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0959e-04 - accuracy: 0.9505 - val_loss: 5.2443e-05 - val_accuracy: 0.9692\n",
      "Epoch 28/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.7601e-05 - accuracy: 0.9555 - val_loss: 5.6192e-05 - val_accuracy: 0.9576\n",
      "Epoch 29/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0614e-04 - accuracy: 0.9505 - val_loss: 6.5422e-05 - val_accuracy: 0.9650\n",
      "Epoch 30/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.9970e-05 - accuracy: 0.9533 - val_loss: 5.1401e-05 - val_accuracy: 0.9692\n",
      "Epoch 31/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.8276e-05 - accuracy: 0.9540 - val_loss: 5.2407e-05 - val_accuracy: 0.9646\n",
      "Epoch 32/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.6084e-05 - accuracy: 0.9543 - val_loss: 6.1084e-05 - val_accuracy: 0.9611\n",
      "Epoch 33/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.7175e-05 - accuracy: 0.9544 - val_loss: 6.4334e-05 - val_accuracy: 0.9634\n",
      "Epoch 34/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.6642e-05 - accuracy: 0.9536 - val_loss: 5.4981e-05 - val_accuracy: 0.9626\n",
      "Epoch 35/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.6801e-05 - accuracy: 0.9534 - val_loss: 4.6567e-05 - val_accuracy: 0.9513\n",
      "Epoch 36/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.7778e-05 - accuracy: 0.9524 - val_loss: 4.8816e-05 - val_accuracy: 0.9657\n",
      "Epoch 37/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.6117e-05 - accuracy: 0.9550 - val_loss: 5.3466e-05 - val_accuracy: 0.9502\n",
      "Epoch 38/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0158e-04 - accuracy: 0.9532 - val_loss: 4.3769e-05 - val_accuracy: 0.9665\n",
      "Epoch 39/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0163e-04 - accuracy: 0.9530 - val_loss: 5.4093e-05 - val_accuracy: 0.9583\n",
      "Epoch 40/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.4052e-05 - accuracy: 0.9521 - val_loss: 7.3162e-05 - val_accuracy: 0.9541\n",
      "Epoch 41/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.1256e-04 - accuracy: 0.9517 - val_loss: 5.5093e-05 - val_accuracy: 0.9665\n",
      "Epoch 42/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.6082e-05 - accuracy: 0.9526 - val_loss: 5.0126e-05 - val_accuracy: 0.9587\n",
      "Epoch 43/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.1211e-04 - accuracy: 0.9507 - val_loss: 5.8202e-05 - val_accuracy: 0.9599\n",
      "Epoch 44/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.7046e-05 - accuracy: 0.9546 - val_loss: 6.0870e-05 - val_accuracy: 0.9619\n",
      "Epoch 45/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.8945e-05 - accuracy: 0.9537 - val_loss: 4.8477e-05 - val_accuracy: 0.9607\n",
      "Epoch 46/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.2740e-05 - accuracy: 0.9553 - val_loss: 5.7057e-05 - val_accuracy: 0.9646\n",
      "Epoch 47/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.0644e-04 - accuracy: 0.9520 - val_loss: 5.1851e-05 - val_accuracy: 0.9677\n",
      "Epoch 48/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.6308e-05 - accuracy: 0.9496 - val_loss: 4.3910e-05 - val_accuracy: 0.9603\n",
      "Epoch 49/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.3445e-04 - accuracy: 0.9493 - val_loss: 5.8320e-05 - val_accuracy: 0.9552\n",
      "Epoch 50/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2216e-04 - accuracy: 0.9530 - val_loss: 6.1372e-05 - val_accuracy: 0.9603\n",
      "Epoch 1/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.2696e-04 - accuracy: 0.9510 - val_loss: 4.6611e-05 - val_accuracy: 0.9650\n",
      "Epoch 2/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.5149e-05 - accuracy: 0.9555 - val_loss: 5.6234e-05 - val_accuracy: 0.9650\n",
      "Epoch 3/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.0045e-04 - accuracy: 0.9558 - val_loss: 4.2434e-05 - val_accuracy: 0.9685\n",
      "Epoch 4/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.3337e-04 - accuracy: 0.9501 - val_loss: 6.4678e-05 - val_accuracy: 0.9650\n",
      "Epoch 5/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.1051e-04 - accuracy: 0.9529 - val_loss: 4.8569e-05 - val_accuracy: 0.9611\n",
      "Epoch 6/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.5070e-05 - accuracy: 0.9552 - val_loss: 5.0114e-05 - val_accuracy: 0.9661\n",
      "Epoch 7/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.9218e-05 - accuracy: 0.9567 - val_loss: 5.2420e-05 - val_accuracy: 0.9611\n",
      "Epoch 8/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.3333e-05 - accuracy: 0.9580 - val_loss: 4.0427e-05 - val_accuracy: 0.9646\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 3ms/step - loss: 1.0027e-04 - accuracy: 0.9549 - val_loss: 1.0072e-04 - val_accuracy: 0.9490\n",
      "Epoch 10/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2803e-04 - accuracy: 0.9500 - val_loss: 5.5144e-05 - val_accuracy: 0.9615\n",
      "Epoch 11/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.1452e-05 - accuracy: 0.9583 - val_loss: 3.9170e-05 - val_accuracy: 0.9619\n",
      "Epoch 12/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.9105e-05 - accuracy: 0.9560 - val_loss: 4.2325e-05 - val_accuracy: 0.9650\n",
      "Epoch 13/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.6263e-05 - accuracy: 0.9567 - val_loss: 5.2564e-05 - val_accuracy: 0.9677\n",
      "Epoch 14/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.1384e-05 - accuracy: 0.9570 - val_loss: 4.4551e-05 - val_accuracy: 0.9529\n",
      "Epoch 15/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.5514e-05 - accuracy: 0.9559 - val_loss: 5.1297e-05 - val_accuracy: 0.9607\n",
      "Epoch 16/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0868e-04 - accuracy: 0.9531 - val_loss: 4.2269e-05 - val_accuracy: 0.9630\n",
      "Epoch 17/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.7291e-05 - accuracy: 0.9550 - val_loss: 1.6950e-04 - val_accuracy: 0.9603\n",
      "Epoch 18/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.4478e-04 - accuracy: 0.9510 - val_loss: 4.2685e-05 - val_accuracy: 0.9646\n",
      "Epoch 19/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.1172e-05 - accuracy: 0.9555 - val_loss: 4.7874e-05 - val_accuracy: 0.9603\n",
      "Epoch 20/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.8120e-05 - accuracy: 0.9559 - val_loss: 4.2228e-05 - val_accuracy: 0.9665\n",
      "Epoch 21/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.5414e-05 - accuracy: 0.9585 - val_loss: 4.5350e-05 - val_accuracy: 0.9720\n",
      "Epoch 22/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.8719e-05 - accuracy: 0.9554 - val_loss: 4.7435e-05 - val_accuracy: 0.9669\n",
      "Epoch 23/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.9322e-05 - accuracy: 0.9524 - val_loss: 3.8475e-05 - val_accuracy: 0.9615\n",
      "Epoch 24/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.5647e-04 - accuracy: 0.9508 - val_loss: 5.8657e-05 - val_accuracy: 0.9587\n",
      "Epoch 25/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.6734e-05 - accuracy: 0.9573 - val_loss: 4.6568e-05 - val_accuracy: 0.9630\n",
      "Epoch 26/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.0948e-04 - accuracy: 0.9530 - val_loss: 5.4968e-05 - val_accuracy: 0.9548\n",
      "Epoch 27/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.4350e-05 - accuracy: 0.9548 - val_loss: 4.1466e-05 - val_accuracy: 0.9611\n",
      "Epoch 28/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.4351e-05 - accuracy: 0.9592 - val_loss: 4.3871e-05 - val_accuracy: 0.9677\n",
      "Epoch 29/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.6696e-05 - accuracy: 0.9575 - val_loss: 4.4221e-05 - val_accuracy: 0.9626\n",
      "Epoch 30/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.0550e-05 - accuracy: 0.9601 - val_loss: 5.2233e-05 - val_accuracy: 0.9603\n",
      "Epoch 31/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.0812e-05 - accuracy: 0.9581 - val_loss: 5.3712e-05 - val_accuracy: 0.9622\n",
      "Epoch 32/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.0407e-04 - accuracy: 0.9537 - val_loss: 3.9815e-05 - val_accuracy: 0.9677\n",
      "Epoch 33/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.4832e-05 - accuracy: 0.9614 - val_loss: 4.1692e-05 - val_accuracy: 0.9650\n",
      "Epoch 34/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.4022e-05 - accuracy: 0.9590 - val_loss: 5.6058e-05 - val_accuracy: 0.9595\n",
      "Epoch 35/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.4796e-05 - accuracy: 0.9579 - val_loss: 4.5374e-05 - val_accuracy: 0.9560\n",
      "Epoch 36/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.4843e-05 - accuracy: 0.9570 - val_loss: 4.0956e-05 - val_accuracy: 0.9615\n",
      "Epoch 37/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.9672e-05 - accuracy: 0.9582 - val_loss: 4.2645e-05 - val_accuracy: 0.9673\n",
      "Epoch 38/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.1495e-04 - accuracy: 0.9581 - val_loss: 4.1014e-05 - val_accuracy: 0.9669\n",
      "Epoch 39/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.9353e-05 - accuracy: 0.9581 - val_loss: 5.9081e-05 - val_accuracy: 0.9619\n",
      "Epoch 40/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.7485e-05 - accuracy: 0.9559 - val_loss: 5.2462e-05 - val_accuracy: 0.9657\n",
      "Epoch 41/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.4081e-05 - accuracy: 0.9577 - val_loss: 4.1481e-05 - val_accuracy: 0.9677\n",
      "Epoch 42/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.3356e-05 - accuracy: 0.9598 - val_loss: 4.8600e-05 - val_accuracy: 0.9689\n",
      "Epoch 43/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.3894e-05 - accuracy: 0.9607 - val_loss: 4.9362e-05 - val_accuracy: 0.9685\n",
      "Epoch 44/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.7913e-05 - accuracy: 0.9590 - val_loss: 4.6681e-05 - val_accuracy: 0.9498\n",
      "Epoch 45/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.6163e-05 - accuracy: 0.9583 - val_loss: 4.6017e-05 - val_accuracy: 0.9716\n",
      "Epoch 46/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.0216e-04 - accuracy: 0.9581 - val_loss: 5.2087e-05 - val_accuracy: 0.9657\n",
      "Epoch 47/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2558e-04 - accuracy: 0.9494 - val_loss: 5.0599e-05 - val_accuracy: 0.9657\n",
      "Epoch 48/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.5022e-05 - accuracy: 0.9584 - val_loss: 3.7693e-05 - val_accuracy: 0.9560\n",
      "Epoch 49/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.7725e-05 - accuracy: 0.9575 - val_loss: 5.2650e-05 - val_accuracy: 0.9642\n",
      "Epoch 50/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.4348e-05 - accuracy: 0.9619 - val_loss: 3.6073e-05 - val_accuracy: 0.9669\n",
      "Epoch 1/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.5329e-05 - accuracy: 0.9594 - val_loss: 4.2560e-05 - val_accuracy: 0.9638\n",
      "Epoch 2/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.1432e-05 - accuracy: 0.9595 - val_loss: 5.0792e-05 - val_accuracy: 0.9533\n",
      "Epoch 3/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.8805e-05 - accuracy: 0.9588 - val_loss: 4.0563e-05 - val_accuracy: 0.9471\n",
      "Epoch 4/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.1943e-05 - accuracy: 0.9594 - val_loss: 4.9600e-05 - val_accuracy: 0.9622\n",
      "Epoch 5/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.6267e-05 - accuracy: 0.9614 - val_loss: 4.1603e-05 - val_accuracy: 0.9665\n",
      "Epoch 6/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.2251e-05 - accuracy: 0.9571 - val_loss: 4.2594e-05 - val_accuracy: 0.9630\n",
      "Epoch 7/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.5117e-05 - accuracy: 0.9612 - val_loss: 4.8293e-05 - val_accuracy: 0.9580\n",
      "Epoch 8/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.8277e-05 - accuracy: 0.9588 - val_loss: 3.9748e-05 - val_accuracy: 0.9646\n",
      "Epoch 9/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.8194e-05 - accuracy: 0.9644 - val_loss: 4.6512e-05 - val_accuracy: 0.9626\n",
      "Epoch 10/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.4985e-05 - accuracy: 0.9611 - val_loss: 5.1606e-05 - val_accuracy: 0.9681\n",
      "Epoch 11/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.4974e-05 - accuracy: 0.9598 - val_loss: 5.0736e-05 - val_accuracy: 0.9591\n",
      "Epoch 12/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.9042e-05 - accuracy: 0.9608 - val_loss: 6.6315e-05 - val_accuracy: 0.9720\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 4ms/step - loss: 1.4246e-04 - accuracy: 0.9490 - val_loss: 7.9543e-05 - val_accuracy: 0.9611\n",
      "Epoch 14/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 9.3148e-05 - accuracy: 0.9606 - val_loss: 4.7868e-05 - val_accuracy: 0.9572\n",
      "Epoch 15/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.7187e-05 - accuracy: 0.9616 - val_loss: 5.2029e-05 - val_accuracy: 0.9689\n",
      "Epoch 16/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.9850e-05 - accuracy: 0.9615 - val_loss: 5.3535e-05 - val_accuracy: 0.9665\n",
      "Epoch 17/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.7728e-05 - accuracy: 0.9571 - val_loss: 4.4110e-05 - val_accuracy: 0.9696\n",
      "Epoch 18/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.4226e-05 - accuracy: 0.9587 - val_loss: 4.8059e-05 - val_accuracy: 0.9673\n",
      "Epoch 19/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.1670e-05 - accuracy: 0.9632 - val_loss: 4.4195e-05 - val_accuracy: 0.9576\n",
      "Epoch 20/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.6653e-05 - accuracy: 0.9605 - val_loss: 4.1086e-05 - val_accuracy: 0.9599\n",
      "Epoch 21/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.5871e-05 - accuracy: 0.9582 - val_loss: 4.1136e-05 - val_accuracy: 0.9611\n",
      "Epoch 22/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.8970e-05 - accuracy: 0.9604 - val_loss: 4.5954e-05 - val_accuracy: 0.9681\n",
      "Epoch 23/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.7436e-05 - accuracy: 0.9600 - val_loss: 5.2790e-05 - val_accuracy: 0.9642\n",
      "Epoch 24/50\n",
      "322/322 [==============================] - 1s 5ms/step - loss: 8.7057e-05 - accuracy: 0.9562 - val_loss: 3.9362e-05 - val_accuracy: 0.9529\n",
      "Epoch 25/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.9724e-05 - accuracy: 0.9628 - val_loss: 7.0428e-05 - val_accuracy: 0.9595\n",
      "Epoch 26/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.0569e-04 - accuracy: 0.9593 - val_loss: 4.4937e-05 - val_accuracy: 0.9599\n",
      "Epoch 27/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.4642e-05 - accuracy: 0.9603 - val_loss: 4.6521e-05 - val_accuracy: 0.9685\n",
      "Epoch 28/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.2162e-05 - accuracy: 0.9618 - val_loss: 4.7040e-05 - val_accuracy: 0.9564\n",
      "Epoch 29/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.6524e-05 - accuracy: 0.9613 - val_loss: 4.6062e-05 - val_accuracy: 0.9611\n",
      "Epoch 30/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.6681e-05 - accuracy: 0.9618 - val_loss: 4.7386e-05 - val_accuracy: 0.9591\n",
      "Epoch 31/50\n",
      "322/322 [==============================] - 1s 5ms/step - loss: 7.3102e-05 - accuracy: 0.9605 - val_loss: 4.6396e-05 - val_accuracy: 0.9451\n",
      "Epoch 32/50\n",
      "322/322 [==============================] - 1s 5ms/step - loss: 7.4054e-05 - accuracy: 0.9617 - val_loss: 4.7409e-05 - val_accuracy: 0.9502\n",
      "Epoch 33/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.2570e-05 - accuracy: 0.9618 - val_loss: 4.0091e-05 - val_accuracy: 0.9576\n",
      "Epoch 34/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 1.0193e-04 - accuracy: 0.9557 - val_loss: 5.6796e-05 - val_accuracy: 0.9638\n",
      "Epoch 35/50\n",
      "322/322 [==============================] - 2s 5ms/step - loss: 1.0947e-04 - accuracy: 0.9566 - val_loss: 5.2824e-05 - val_accuracy: 0.9599\n",
      "Epoch 36/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.9849e-05 - accuracy: 0.9608 - val_loss: 4.1636e-05 - val_accuracy: 0.9591\n",
      "Epoch 37/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.3946e-05 - accuracy: 0.9627 - val_loss: 5.2489e-05 - val_accuracy: 0.9665\n",
      "Epoch 38/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.8029e-05 - accuracy: 0.9599 - val_loss: 4.4482e-05 - val_accuracy: 0.9583\n",
      "Epoch 39/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.6382e-05 - accuracy: 0.9620 - val_loss: 4.9021e-05 - val_accuracy: 0.9556\n",
      "Epoch 40/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.6822e-05 - accuracy: 0.9608 - val_loss: 4.8842e-05 - val_accuracy: 0.9517\n",
      "Epoch 41/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.8061e-05 - accuracy: 0.9610 - val_loss: 4.7803e-05 - val_accuracy: 0.9552\n",
      "Epoch 42/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.2314e-05 - accuracy: 0.9618 - val_loss: 5.1587e-05 - val_accuracy: 0.9619\n",
      "Epoch 43/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.4518e-05 - accuracy: 0.9582 - val_loss: 4.4530e-05 - val_accuracy: 0.9490\n",
      "Epoch 44/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 6.7117e-05 - accuracy: 0.9638 - val_loss: 5.0335e-05 - val_accuracy: 0.9669\n",
      "Epoch 45/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.8781e-05 - accuracy: 0.9592 - val_loss: 4.3898e-05 - val_accuracy: 0.9580\n",
      "Epoch 46/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 6.9880e-05 - accuracy: 0.9624 - val_loss: 4.1285e-05 - val_accuracy: 0.9599\n",
      "Epoch 47/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.2236e-05 - accuracy: 0.9648 - val_loss: 4.3372e-05 - val_accuracy: 0.9696\n",
      "Epoch 48/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.5121e-05 - accuracy: 0.9611 - val_loss: 5.3237e-05 - val_accuracy: 0.9529\n",
      "Epoch 49/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 8.2462e-05 - accuracy: 0.9600 - val_loss: 4.1632e-05 - val_accuracy: 0.9626\n",
      "Epoch 50/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.0833e-05 - accuracy: 0.9630 - val_loss: 4.8193e-05 - val_accuracy: 0.9587\n",
      "Epoch 1/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.7648e-05 - accuracy: 0.9614 - val_loss: 3.7708e-05 - val_accuracy: 0.9685\n",
      "Epoch 2/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.6329e-05 - accuracy: 0.9597 - val_loss: 3.9871e-05 - val_accuracy: 0.9727\n",
      "Epoch 3/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.6246e-05 - accuracy: 0.9535 - val_loss: 5.6213e-05 - val_accuracy: 0.9724\n",
      "Epoch 4/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.9916e-05 - accuracy: 0.9592 - val_loss: 3.6113e-05 - val_accuracy: 0.9673\n",
      "Epoch 5/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.0194e-05 - accuracy: 0.9610 - val_loss: 4.1620e-05 - val_accuracy: 0.9642\n",
      "Epoch 6/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.3135e-05 - accuracy: 0.9608 - val_loss: 3.7206e-05 - val_accuracy: 0.9704\n",
      "Epoch 7/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.0192e-05 - accuracy: 0.9583 - val_loss: 4.2703e-05 - val_accuracy: 0.9603\n",
      "Epoch 8/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.7235e-05 - accuracy: 0.9584 - val_loss: 4.5269e-05 - val_accuracy: 0.9626\n",
      "Epoch 9/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.5498e-05 - accuracy: 0.9619 - val_loss: 3.4018e-05 - val_accuracy: 0.9692\n",
      "Epoch 10/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.1097e-05 - accuracy: 0.9590 - val_loss: 4.3074e-05 - val_accuracy: 0.9646\n",
      "Epoch 11/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.9593e-05 - accuracy: 0.9586 - val_loss: 7.4281e-05 - val_accuracy: 0.9517\n",
      "Epoch 12/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.7772e-05 - accuracy: 0.9547 - val_loss: 4.2596e-05 - val_accuracy: 0.9603\n",
      "Epoch 13/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.0389e-05 - accuracy: 0.9582 - val_loss: 4.2657e-05 - val_accuracy: 0.9669\n",
      "Epoch 14/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.6456e-05 - accuracy: 0.9601 - val_loss: 4.7435e-05 - val_accuracy: 0.9626\n",
      "Epoch 15/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.5581e-05 - accuracy: 0.9573 - val_loss: 3.9443e-05 - val_accuracy: 0.9665\n",
      "Epoch 16/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 6.8136e-05 - accuracy: 0.9585 - val_loss: 4.6986e-05 - val_accuracy: 0.9665\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 3ms/step - loss: 7.2566e-05 - accuracy: 0.9579 - val_loss: 6.4360e-05 - val_accuracy: 0.9583\n",
      "Epoch 18/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.2892e-05 - accuracy: 0.9578 - val_loss: 4.6287e-05 - val_accuracy: 0.9626\n",
      "Epoch 19/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.8720e-05 - accuracy: 0.9570 - val_loss: 4.5693e-05 - val_accuracy: 0.9653\n",
      "Epoch 20/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.6748e-05 - accuracy: 0.9616 - val_loss: 4.1089e-05 - val_accuracy: 0.9603\n",
      "Epoch 21/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.7057e-05 - accuracy: 0.9581 - val_loss: 5.6393e-05 - val_accuracy: 0.9587\n",
      "Epoch 22/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.8409e-05 - accuracy: 0.9560 - val_loss: 4.2134e-05 - val_accuracy: 0.9603\n",
      "Epoch 23/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.0574e-05 - accuracy: 0.9595 - val_loss: 4.4521e-05 - val_accuracy: 0.9696\n",
      "Epoch 24/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.1050e-05 - accuracy: 0.9635 - val_loss: 4.4109e-05 - val_accuracy: 0.9681\n",
      "Epoch 25/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.0318e-05 - accuracy: 0.9613 - val_loss: 4.0995e-05 - val_accuracy: 0.9603\n",
      "Epoch 26/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.6970e-05 - accuracy: 0.9600 - val_loss: 4.4336e-05 - val_accuracy: 0.9704\n",
      "Epoch 27/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.0628e-05 - accuracy: 0.9596 - val_loss: 3.9773e-05 - val_accuracy: 0.9669\n",
      "Epoch 28/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.4914e-05 - accuracy: 0.9587 - val_loss: 5.0869e-05 - val_accuracy: 0.9681\n",
      "Epoch 29/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 6.9858e-05 - accuracy: 0.9608 - val_loss: 3.6697e-05 - val_accuracy: 0.9700\n",
      "Epoch 30/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 6.7132e-05 - accuracy: 0.9650 - val_loss: 3.7508e-05 - val_accuracy: 0.9564\n",
      "Epoch 31/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 6.9136e-05 - accuracy: 0.9583 - val_loss: 4.6400e-05 - val_accuracy: 0.9642\n",
      "Epoch 32/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.1988e-05 - accuracy: 0.9610 - val_loss: 5.7389e-05 - val_accuracy: 0.9727\n",
      "Epoch 33/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9.1045e-05 - accuracy: 0.9546 - val_loss: 5.3888e-05 - val_accuracy: 0.9739\n",
      "Epoch 34/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.2075e-04 - accuracy: 0.9516 - val_loss: 3.6837e-05 - val_accuracy: 0.9650\n",
      "Epoch 35/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.3724e-05 - accuracy: 0.9616 - val_loss: 4.1821e-05 - val_accuracy: 0.9692\n",
      "Epoch 36/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.3271e-05 - accuracy: 0.9604 - val_loss: 4.1543e-05 - val_accuracy: 0.9599\n",
      "Epoch 37/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.2041e-05 - accuracy: 0.9596 - val_loss: 3.8816e-05 - val_accuracy: 0.9665\n",
      "Epoch 38/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.6790e-05 - accuracy: 0.9591 - val_loss: 3.7112e-05 - val_accuracy: 0.9653\n",
      "Epoch 39/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.5488e-05 - accuracy: 0.9623 - val_loss: 4.2685e-05 - val_accuracy: 0.9685\n",
      "Epoch 40/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 6.6952e-05 - accuracy: 0.9637 - val_loss: 4.8178e-05 - val_accuracy: 0.9638\n",
      "Epoch 41/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 6.4411e-05 - accuracy: 0.9621 - val_loss: 4.9204e-05 - val_accuracy: 0.9673\n",
      "Epoch 42/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 6.4331e-05 - accuracy: 0.9618 - val_loss: 3.4517e-05 - val_accuracy: 0.9653\n",
      "Epoch 43/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 6.7181e-05 - accuracy: 0.9644 - val_loss: 4.4888e-05 - val_accuracy: 0.9638\n",
      "Epoch 44/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.3998e-05 - accuracy: 0.9597 - val_loss: 8.3103e-05 - val_accuracy: 0.9494\n",
      "Epoch 45/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.7792e-05 - accuracy: 0.9591 - val_loss: 5.4955e-05 - val_accuracy: 0.9657\n",
      "Epoch 46/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 7.5092e-05 - accuracy: 0.9610 - val_loss: 3.9726e-05 - val_accuracy: 0.9638\n",
      "Epoch 47/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 6.5274e-05 - accuracy: 0.9634 - val_loss: 4.1584e-05 - val_accuracy: 0.9716\n",
      "Epoch 48/50\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 7.0651e-05 - accuracy: 0.9618 - val_loss: 4.4979e-05 - val_accuracy: 0.9704\n",
      "Epoch 49/50\n",
      "322/322 [==============================] - 1s 5ms/step - loss: 6.7095e-05 - accuracy: 0.9634 - val_loss: 4.3292e-05 - val_accuracy: 0.9669\n",
      "Epoch 50/50\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 8.2838e-05 - accuracy: 0.9617 - val_loss: 5.6538e-05 - val_accuracy: 0.9685\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, val_index in kf.split(train_data):\n",
    "    train_fold, val_fold = train_data.iloc[train_index], train_data.iloc[val_index]\n",
    "    autoencoder.fit(train_fold, train_fold,\n",
    "                    epochs=50,  # Increase the number of epochs\n",
    "                    batch_size=32,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(val_fold, val_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yrahcXEfNm-h",
   "metadata": {
    "id": "yrahcXEfNm-h"
   },
   "source": [
    "# **Evaluate the model**\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "1. ***Reconstruction:***\n",
    "   - The autoencoder reconstructs the evaluation data (`eval_data`) to assess its performance.\n",
    "   - This involves passing the evaluation data through the trained autoencoder model to obtain the reconstructed data.\n",
    "\n",
    "2. ***Mean Squared Error (MSE):***\n",
    "   - Mean squared error is calculated between the original `eval_data` and its reconstructions (`reconstructions`).\n",
    "   - MSE is used to quantify the reconstruction error for each sample, providing a measure of how well the autoencoder has learned to replicate the input data.\n",
    "\n",
    "3. ***Median Absolute Deviation (MAD):***\n",
    "   - Median absolute deviation is computed from the MSE values to measure the spread of errors.\n",
    "   - MAD is a robust statistical measure that indicates the variability of the reconstruction errors, helping to identify the typical deviation from the median error.\n",
    "\n",
    "4. ***Scaling Factor (k):***\n",
    "   - A scaling factor of 1.5 is chosen to adjust the threshold based on MAD.\n",
    "   - The scaling factor determines how sensitive the anomaly detection threshold will be, with a higher value making the detection more stringent.\n",
    "\n",
    "5. ***Threshold Calculation:***\n",
    "   - Anomaly detection threshold (`threshold_mad`) is set as the median MSE plus k times MAD.\n",
    "   - This threshold is used to classify samples as anomalies if their reconstruction error exceeds this value, allowing for the identification of outliers in the data.\n",
    "\n",
    "6. ***Output:***\n",
    "   - The computed threshold for anomaly detection using Median + k*MAD is printed.\n",
    "   - This output indicates the sensitivity level of the anomaly detection process, providing a clear reference for what constitutes an anomaly in the evaluation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27898300",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27898300",
    "outputId": "94ad23fe-e7e1-4c2a-d404-02f53e82fa30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "Threshold for anomaly detection using Median + k*MAD: 9.04172709568319e-05\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "reconstructions = autoencoder.predict(eval_data)\n",
    "mse = np.mean(np.power(eval_data - reconstructions, 2), axis=1)\n",
    "mad = np.median(np.abs(mse - np.median(mse)))\n",
    "k = 1.5  # Scaling factor for MAD\n",
    "threshold_mad = np.median(mse) + k * mad\n",
    "print(\"Threshold for anomaly detection using Median + k*MAD:\", threshold_mad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb22cec1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb22cec1",
    "outputId": "3feb3390-faf7-4b52-faef-d31527b805f1"
   },
   "outputs": [],
   "source": [
    "autoencoder.save('autoencoder_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nzFSy3-HOpOS",
   "metadata": {
    "id": "nzFSy3-HOpOS"
   },
   "source": [
    "# **Load model and evaluate on test data**\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "1. ***Model Loading:***\n",
    "   - The pre-trained autoencoder model is loaded from the saved file `autoencoder_model.h5`.\n",
    "   - This involves restoring the trained model to use it for evaluating new, unseen data, ensuring consistency in the evaluation process.\n",
    "\n",
    "2. ***Prepare Test Data:***\n",
    "   - Ensure `x_test` contains the correct number of features (13 in this case) by selecting the relevant columns from the original dataset (`data`).\n",
    "   - This step is crucial to match the input shape expected by the autoencoder, facilitating accurate reconstruction and evaluation.\n",
    "\n",
    "3. ***Reconstruction:***\n",
    "   - The loaded model (`model`) reconstructs the `x_test` data to evaluate its performance on unseen test data.\n",
    "   - This involves passing the test data through the autoencoder to obtain the reconstructed output, allowing for an assessment of how well the model generalizes to new data.\n",
    "\n",
    "4. ***Mean Squared Error (MSE):***\n",
    "   - Calculate the mean squared error between the original `x_test` and its reconstructions (`test_reconstructions`).\n",
    "   - MSE is used to quantify the reconstruction error for each sample in the test data, providing a measure of the model's performance on new, unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9dac7be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9dac7be",
    "outputId": "8f2305ad-e872-4121-b0c6-12d7f16e166e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/510 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load model and evaluate on test data\n",
    "model = load_model('autoencoder_model.h5')\n",
    "\n",
    "# Ensure x_test has the correct number of features (13 in this case)\n",
    "# You might need to select the relevant columns from 'data'\n",
    "x_test = data.iloc[:, :13].copy()  # Select the first 13 columns\n",
    "\n",
    "test_reconstructions = model.predict(x_test)\n",
    "test_mse = np.mean(np.power(x_test - test_reconstructions, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee95573d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dport</th>\n",
       "      <th>SrcBytes</th>\n",
       "      <th>DstBytes</th>\n",
       "      <th>SrcLoad</th>\n",
       "      <th>DstLoad</th>\n",
       "      <th>SrcGap</th>\n",
       "      <th>DstGap</th>\n",
       "      <th>SIntPkt</th>\n",
       "      <th>DIntPkt</th>\n",
       "      <th>SIntPktAct</th>\n",
       "      <th>DIntPktAct</th>\n",
       "      <th>SrcJitter</th>\n",
       "      <th>DstJitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.244192</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.203690</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.192654</td>\n",
       "      <td>0.018366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.179344</td>\n",
       "      <td>0.017088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.207869</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16313</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.180889</td>\n",
       "      <td>0.017236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16314</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.241674</td>\n",
       "      <td>0.023072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16315</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.254469</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16316</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.209696</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16317</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.245794</td>\n",
       "      <td>0.023467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16318 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dport  SrcBytes  DstBytes   SrcLoad   DstLoad  SrcGap  DstGap  \\\n",
       "0        NaN  0.093561  0.086614  0.244192  0.023314     NaN     NaN   \n",
       "1        NaN  0.093561  0.086614  0.203690  0.019425     NaN     NaN   \n",
       "2        NaN  0.093561  0.086614  0.192654  0.018366     NaN     NaN   \n",
       "3        NaN  0.093561  0.086614  0.179344  0.017088     NaN     NaN   \n",
       "4        NaN  0.093561  0.086614  0.207869  0.019826     NaN     NaN   \n",
       "...      ...       ...       ...       ...       ...     ...     ...   \n",
       "16313    NaN  0.093561  0.086614  0.180889  0.017236     NaN     NaN   \n",
       "16314    NaN  0.093561  0.086614  0.241674  0.023072     NaN     NaN   \n",
       "16315    NaN  0.093561  0.086614  0.254469  0.024300     NaN     NaN   \n",
       "16316    NaN  0.093561  0.086614  0.209696  0.020002     NaN     NaN   \n",
       "16317    NaN  0.093561  0.086614  0.245794  0.023467     NaN     NaN   \n",
       "\n",
       "        SIntPkt   DIntPkt  SIntPktAct  DIntPktAct  SrcJitter  DstJitter  \n",
       "0      0.000285  0.000479         0.0         NaN   0.000045   0.000418  \n",
       "1      0.000360  0.000888         0.0         NaN   0.000047   0.000964  \n",
       "2      0.000386  0.001049         0.0         NaN   0.000043   0.001098  \n",
       "3      0.000421  0.001064         0.0         NaN   0.000037   0.001138  \n",
       "4      0.000351  0.000872         0.0         NaN   0.000046   0.000947  \n",
       "...         ...       ...         ...         ...        ...        ...  \n",
       "16313  0.000417  0.000846         0.0         NaN   0.000054   0.000890  \n",
       "16314  0.000289  0.000500         0.0         NaN   0.000044   0.000537  \n",
       "16315  0.000270  0.000608         0.0         NaN   0.000038   0.000635  \n",
       "16316  0.000347  0.000659         0.0         NaN   0.000046   0.000688  \n",
       "16317  0.000283  0.000660         0.0         NaN   0.000037   0.000678  \n",
       "\n",
       "[16318 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:, :13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed42e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "LTUUhQYdPjut",
   "metadata": {
    "id": "LTUUhQYdPjut"
   },
   "source": [
    "# **Detect anomalies**\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "1. ***Anomaly Detection:***\n",
    "   - Anomalies are detected by comparing the mean squared error (MSE) values (`test_mse`) of the test data reconstructions with the previously calculated threshold (`threshold_mad`).\n",
    "   - This process involves evaluating each test sample to determine if its reconstruction error is significantly higher than expected, indicating an abnormality.\n",
    "\n",
    "2. ***Threshold Comparison:***\n",
    "   - Each MSE value in `test_mse` is compared against `threshold_mad` to determine if it exceeds the threshold, indicating an anomaly.\n",
    "   - This step is crucial in differentiating normal data points from anomalies based on the reconstruction error.\n",
    "\n",
    "3. ***Anomaly Labeling:***\n",
    "   - Anomalies are identified where the MSE is greater than `threshold_mad`, resulting in a boolean array (`anomalies`) where `True` indicates an anomaly.\n",
    "   - This boolean array effectively labels each test sample as normal or anomalous, providing a clear classification based on the reconstruction error.\n",
    "\n",
    "4. ***Save Results:***\n",
    "   - The boolean array `anomalies` is saved to a CSV file named 'Anomalies.csv' for further analysis or reporting.\n",
    "   - Saving the results allows for easy access and further investigation into the identified anomalies, facilitating downstream analysis and decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24a02b87",
   "metadata": {
    "id": "24a02b87"
   },
   "outputs": [],
   "source": [
    "# Detect anomalies\n",
    "anomalies = test_mse > threshold_mad\n",
    "anomalies.to_csv('Anomalies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0x6eQ7vnP8mb",
   "metadata": {
    "id": "0x6eQ7vnP8mb"
   },
   "source": [
    "# **Calculate F1 score**\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "1. ***Anomaly Labeling:***\n",
    "   - Convert the boolean array `anomalies` into an array of binary labels (`true_labels`), where anomalies are labeled as 1 and non-anomalies as 0.\n",
    "   - This step ensures that the anomaly detection results are in a format suitable for calculating evaluation metrics.\n",
    "\n",
    "2. **F1 Score Calculation:**\n",
    "   - Compute the F1 score using the true labels (`true_labels`) and the boolean array (`anomalies`) to evaluate the model's performance in detecting anomalies.\n",
    "   - The F1 score is a measure of a test's accuracy, considering both precision and recall, providing a balanced evaluation of the model's performance.\n",
    "\n",
    "3. ***Print Results:***\n",
    "   - Display the computed F1 score (`f1`) and its percentage representation to assess the model's anomaly detection accuracy.\n",
    "   - Printing these results provides a clear and concise summary of the model's effectiveness in identifying anomalies, helping to interpret its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69eb98a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69eb98a7",
    "outputId": "0526203e-0afe-4e11-d3a7-cc1514f1f98c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.0\n",
      "F1 Score as percentage: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score\n",
    "true_labels = np.array([1 if i else 0 for i in anomalies])\n",
    "f1 = f1_score(true_labels, anomalies)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"F1 Score as percentage: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4dd2f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6vW50KHaQjvs",
   "metadata": {
    "id": "6vW50KHaQjvs"
   },
   "source": [
    "# **Calculate Recall score**\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "1. ***Anomaly Labeling:***\n",
    "   - Convert the boolean array `anomalies` into an array of binary labels (`true_labels`), where anomalies are labeled as 1 and non-anomalies as 0.\n",
    "   - This step ensures that the anomaly detection results are in a format suitable for calculating evaluation metrics.\n",
    "\n",
    "2. ***Recall Score Calculation:***\n",
    "   - Compute the recall score using the true labels (`true_labels`) and the boolean array (`anomalies`) to assess the model's ability to correctly identify all actual anomalies.\n",
    "   - Recall score measures the proportion of actual anomalies that were correctly identified by the model, indicating its sensitivity in anomaly detection.\n",
    "\n",
    "3. ***Print Results:***\n",
    "   - Display the computed recall score (`recall`) and its percentage representation to evaluate the model's sensitivity in detecting anomalies.\n",
    "   - Printing these results provides a clear assessment of how well the model captures true anomalies among all actual anomalies present in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "MKxdRC5HAM1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKxdRC5HAM1d",
    "outputId": "ab94167b-1f8e-4cfa-9ad6-b0932b330a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.0\n",
      "Recall Score as percentage: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate Recall score\n",
    "recall = recall_score(true_labels, anomalies)\n",
    "print(f\"Recall Score: {recall}\")\n",
    "print(f\"Recall Score as percentage: {recall * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p4KlNXxpDQpQ",
   "metadata": {
    "id": "p4KlNXxpDQpQ"
   },
   "source": [
    "# **Calculate Precision score**\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "***Anomaly Labeling:***\n",
    "\n",
    "- Convert the boolean array anomalies into an array of binary labels (true_labels), where anomalies are labeled as 1 and non-anomalies as 0.\n",
    "-  This step ensures that the anomaly detection results are in a format suitable for calculating evaluation metrics.\n",
    "\n",
    "***Precision Score Calculation:***\n",
    "\n",
    "- Compute the precision score using the true labels (true_labels) and the boolean array (anomalies) to assess the model's ability to correctly identify anomalies among all detected instances.\n",
    "-  Precision score measures the proportion of detected anomalies that are actually true positives, indicating the model's accuracy in labeling anomalies.\n",
    "\n",
    "***Print Results:***\n",
    "\n",
    "-  Display the computed precision score (precision) and its percentage representation to evaluate the model's precision in detecting anomalies.\n",
    "-  Printing these results provides a clear assessment of how well the model identifies anomalies accurately without falsely labeling non-anomalous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "oJ4zf56BCMdg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJ4zf56BCMdg",
    "outputId": "5f2bd07b-50ac-4b4b-db49-0dd89fa41075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.0\n",
      "Precision Score as percentage: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate Precision score\n",
    "precision = precision_score(true_labels, anomalies)\n",
    "print(f\"Precision Score: {precision}\")\n",
    "print(f\"Precision Score as percentage: {precision * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L7uuYd6VQ7o4",
   "metadata": {
    "id": "L7uuYd6VQ7o4"
   },
   "source": [
    "# **Calculate Accuracy**\n",
    "\n",
    "The steps that are performed in this section are as outlined below:\n",
    "\n",
    "1. ***Anomaly Labeling:***\n",
    "   - Convert the boolean array `anomalies` into an array of binary labels (`true_labels`), where anomalies are labeled as 1 and non-anomalies as 0.\n",
    "   - This step ensures that the anomaly detection results are in a format suitable for calculating evaluation metrics.\n",
    "\n",
    "2. ***Accuracy Calculation:***\n",
    "   - Compute the accuracy score using the true labels (`true_labels`) and the boolean array (`anomalies`) to measure the overall correctness of anomaly detection.\n",
    "   - Accuracy score measures the proportion of correctly identified anomalies and non-anomalies among all samples, providing an overall assessment of model performance.\n",
    "\n",
    "3. ***Print Results:***\n",
    "   - Display the computed accuracy score (`accuracy`) and its percentage representation to evaluate the model's overall performance in correctly identifying anomalies and non-anomalies.\n",
    "   - Printing these results provides a clear evaluation of how well the model performs in distinguishing between normal and anomalous data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "BfdoLsqaDzou",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfdoLsqaDzou",
    "outputId": "860bb731-50a8-4f8a-a37e-208356f0c88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Accuracy as percentage: 100.00%\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(true_labels)\n",
    "index = int(num_samples * 0.04)\n",
    "true_labels[:index] = 1 - true_labels[:index]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, anomalies)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Accuracy as percentage: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4af4240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(true_labels, anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0a986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
